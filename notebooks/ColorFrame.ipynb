{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "28614a9d-3d61-4494-8a67-521ced249395",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "# Getting started with deep learning in Databricks: an end-to-end example using TensorFlow Keras, Hyperopt, and MLflow\n",
    "\n",
    "This tutorial uses a small dataset to show how to use TensorFlow Keras, Hyperopt, and MLflow to develop a deep learning model in Databricks. \n",
    "\n",
    "It includes the following steps:\n",
    "- Load and preprocess data\n",
    "- Part 1. Create a neural network model with TensorFlow Keras and view training with inline TensorBoard\n",
    "- Part 2. Perform automated hyperparameter tuning with Hyperopt and MLflow and use autologging to save results\n",
    "- Part 3. Use the best set of hyperparameters to build a final model \n",
    "- Part 4. Register the model in MLflow and use the model to make predictions\n",
    "\n",
    "### Setup\n",
    "- Databricks Runtime for Machine Learning 7.0 or above. This notebook uses TensorBoard to display the results of neural network training. Depending on the version of Databricks Runtime you are using, you use different methods to start TensorBoard."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "78a19de7-50e0-4c11-bdc6-840882a27a93",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "\n",
    "import mlflow\n",
    "import mlflow.keras\n",
    "import mlflow.tensorflow\n",
    "\n",
    "from math import sqrt\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "import os, PIL, time, cv2, json, shutil\n",
    "\n",
    "import evalml\n",
    "from evalml.preprocessing import load_data\n",
    "from evalml.preprocessing import drop_nan_target_rows\n",
    "\n",
    "from text_to_image.utilities import check_filename\n",
    "from text_to_image.utilities import convert_char_to_int\n",
    "from text_to_image.utilities import get_image_size\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "0591a7e2-d404-42e1-82c0-406309097568",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Load and preprocess data\n",
    "This example uses the California Housing dataset from `scikit-learn`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "18b09747-5f0e-48c7-b539-8b32de5aa85a",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>Beds</th>\n",
       "      <th>Baths</th>\n",
       "      <th>Area</th>\n",
       "      <th>Noise</th>\n",
       "      <th>PropertyType</th>\n",
       "      <th>DaysOnRealtor.com</th>\n",
       "      <th>YearBuilt</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>City_x</th>\n",
       "      <th>County</th>\n",
       "      <th>FemaInfo</th>\n",
       "      <th>FloodFactorInfo</th>\n",
       "      <th>LastSoldYear</th>\n",
       "      <th>SizeRank</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>622</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>1640.0</td>\n",
       "      <td>Medium</td>\n",
       "      <td>Townhome</td>\n",
       "      <td>104.0</td>\n",
       "      <td>1973.0</td>\n",
       "      <td>25.937100</td>\n",
       "      <td>-80.133733</td>\n",
       "      <td>North Miami Beach</td>\n",
       "      <td>Miami-Dade County</td>\n",
       "      <td>AE   ()</td>\n",
       "      <td>flood_factor_high</td>\n",
       "      <td>2009.0</td>\n",
       "      <td>79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>811</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1862.0</td>\n",
       "      <td>Medium</td>\n",
       "      <td>Condo</td>\n",
       "      <td>1021.0</td>\n",
       "      <td>2004.0</td>\n",
       "      <td>25.842794</td>\n",
       "      <td>-80.122788</td>\n",
       "      <td>Miami Beach</td>\n",
       "      <td>Miami-Dade County</td>\n",
       "      <td>AE   ()</td>\n",
       "      <td>flood_factor_high</td>\n",
       "      <td>2010.0</td>\n",
       "      <td>636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>734</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1932.0</td>\n",
       "      <td>Medium</td>\n",
       "      <td>Single Family Home</td>\n",
       "      <td>51.0</td>\n",
       "      <td>1987.0</td>\n",
       "      <td>28.044072</td>\n",
       "      <td>-82.401205</td>\n",
       "      <td>Tampa</td>\n",
       "      <td>Hillsborough County</td>\n",
       "      <td>X   ()</td>\n",
       "      <td>flood_factor_low</td>\n",
       "      <td>2004.0</td>\n",
       "      <td>1023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>387</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1750.0</td>\n",
       "      <td>Medium</td>\n",
       "      <td>Townhome</td>\n",
       "      <td>33.0</td>\n",
       "      <td>2005.0</td>\n",
       "      <td>27.752627</td>\n",
       "      <td>-82.414638</td>\n",
       "      <td>Apollo Beach</td>\n",
       "      <td>Hillsborough County</td>\n",
       "      <td>AE   ()</td>\n",
       "      <td>flood_factor_high</td>\n",
       "      <td>2012.0</td>\n",
       "      <td>5376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>364</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1732.0</td>\n",
       "      <td>Low</td>\n",
       "      <td>Single Family Home</td>\n",
       "      <td>17.0</td>\n",
       "      <td>1985.0</td>\n",
       "      <td>26.716497</td>\n",
       "      <td>-80.216349</td>\n",
       "      <td>Royal Palm Beach</td>\n",
       "      <td>Palm Beach County</td>\n",
       "      <td>X   ()</td>\n",
       "      <td>flood_factor_low</td>\n",
       "      <td>2017.0</td>\n",
       "      <td>90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>745</th>\n",
       "      <td>840</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1060.0</td>\n",
       "      <td>Medium</td>\n",
       "      <td>Condo</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1979.0</td>\n",
       "      <td>26.204291</td>\n",
       "      <td>-80.272675</td>\n",
       "      <td>Fort Lauderdale</td>\n",
       "      <td>Broward County</td>\n",
       "      <td>X500   ()</td>\n",
       "      <td>flood_factor_low</td>\n",
       "      <td>2004.0</td>\n",
       "      <td>401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>746</th>\n",
       "      <td>102</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2421.0</td>\n",
       "      <td>Medium</td>\n",
       "      <td>Single Family Home</td>\n",
       "      <td>29.0</td>\n",
       "      <td>1986.0</td>\n",
       "      <td>28.053214</td>\n",
       "      <td>-82.380432</td>\n",
       "      <td>Temple Terrace</td>\n",
       "      <td>Hillsborough County</td>\n",
       "      <td>X   ()</td>\n",
       "      <td>flood_factor_low</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>1023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>747</th>\n",
       "      <td>827</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3392.0</td>\n",
       "      <td>Medium</td>\n",
       "      <td>Condo</td>\n",
       "      <td>41.0</td>\n",
       "      <td>2020.0</td>\n",
       "      <td>26.422176</td>\n",
       "      <td>-81.905178</td>\n",
       "      <td>Fort Myers Beach</td>\n",
       "      <td>Lee County</td>\n",
       "      <td>VE   ()</td>\n",
       "      <td>flood_factor_high</td>\n",
       "      <td>2017.0</td>\n",
       "      <td>5839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>748</th>\n",
       "      <td>715</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2137.0</td>\n",
       "      <td>Low</td>\n",
       "      <td>Condo</td>\n",
       "      <td>71.0</td>\n",
       "      <td>1992.0</td>\n",
       "      <td>26.439186</td>\n",
       "      <td>-81.920834</td>\n",
       "      <td>Fort Myers Beach</td>\n",
       "      <td>Lee County</td>\n",
       "      <td>AE   ()</td>\n",
       "      <td>flood_factor_high</td>\n",
       "      <td>2004.0</td>\n",
       "      <td>5839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>749</th>\n",
       "      <td>1005</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>2550.0</td>\n",
       "      <td>Low</td>\n",
       "      <td>Single Family Home</td>\n",
       "      <td>81.0</td>\n",
       "      <td>1989.0</td>\n",
       "      <td>27.136977</td>\n",
       "      <td>-80.266876</td>\n",
       "      <td>Palm City</td>\n",
       "      <td>Martin County</td>\n",
       "      <td>X   ()</td>\n",
       "      <td>flood_factor_low</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>2950</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>750 rows × 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     index  Beds  Baths    Area    Noise        PropertyType  \\\n",
       "0      622   3.0    2.5  1640.0   Medium            Townhome   \n",
       "1      811   3.0    3.5  1862.0   Medium               Condo   \n",
       "2      734   4.0    3.0  1932.0   Medium  Single Family Home   \n",
       "3      387   3.0    2.0  1750.0   Medium            Townhome   \n",
       "4      364   3.0    2.0  1732.0      Low  Single Family Home   \n",
       "..     ...   ...    ...     ...      ...                 ...   \n",
       "745    840   2.0    2.0  1060.0   Medium               Condo   \n",
       "746    102   4.0    3.0  2421.0   Medium  Single Family Home   \n",
       "747    827   4.0    3.5  3392.0   Medium               Condo   \n",
       "748    715   3.0    3.0  2137.0      Low               Condo   \n",
       "749   1005   4.0    3.5  2550.0      Low  Single Family Home   \n",
       "\n",
       "     DaysOnRealtor.com  YearBuilt   Latitude  Longitude             City_x  \\\n",
       "0                104.0     1973.0  25.937100 -80.133733  North Miami Beach   \n",
       "1               1021.0     2004.0  25.842794 -80.122788        Miami Beach   \n",
       "2                 51.0     1987.0  28.044072 -82.401205              Tampa   \n",
       "3                 33.0     2005.0  27.752627 -82.414638       Apollo Beach   \n",
       "4                 17.0     1985.0  26.716497 -80.216349   Royal Palm Beach   \n",
       "..                 ...        ...        ...        ...                ...   \n",
       "745                8.0     1979.0  26.204291 -80.272675    Fort Lauderdale   \n",
       "746               29.0     1986.0  28.053214 -82.380432     Temple Terrace   \n",
       "747               41.0     2020.0  26.422176 -81.905178   Fort Myers Beach   \n",
       "748               71.0     1992.0  26.439186 -81.920834   Fort Myers Beach   \n",
       "749               81.0     1989.0  27.136977 -80.266876          Palm City   \n",
       "\n",
       "                  County   FemaInfo    FloodFactorInfo  LastSoldYear  SizeRank  \n",
       "0      Miami-Dade County    AE   ()  flood_factor_high        2009.0        79  \n",
       "1      Miami-Dade County    AE   ()  flood_factor_high        2010.0       636  \n",
       "2    Hillsborough County     X   ()   flood_factor_low        2004.0      1023  \n",
       "3    Hillsborough County    AE   ()  flood_factor_high        2012.0      5376  \n",
       "4      Palm Beach County     X   ()   flood_factor_low        2017.0        90  \n",
       "..                   ...        ...                ...           ...       ...  \n",
       "745       Broward County  X500   ()   flood_factor_low        2004.0       401  \n",
       "746  Hillsborough County     X   ()   flood_factor_low        2019.0      1023  \n",
       "747           Lee County    VE   ()  flood_factor_high        2017.0      5839  \n",
       "748           Lee County    AE   ()  flood_factor_high        2004.0      5839  \n",
       "749        Martin County     X   ()   flood_factor_low        2019.0      2950  \n",
       "\n",
       "[750 rows x 16 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train = pd.read_csv('../data/processed/y_train.csv')\n",
    "X_train = pd.read_csv('../data/processed/X_train.csv')\n",
    "\n",
    "y_test = pd.read_csv('../data/processed/y_test.csv')\n",
    "X_test = pd.read_csv('../data/processed/X_test.csv')\n",
    "\n",
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "cb3f5c5b-00b1-4b74-8541-e4f7001b5f62",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.0"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from math import sqrt\n",
    "\n",
    "def nearest_square(num):\n",
    "    num1 = round(sqrt(num))**2\n",
    "    return sqrt(num1)\n",
    "        \n",
    "nearest_square = nearest_square(len(X_train.columns))\n",
    "nearest_square"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "61b78e0f-0375-48b8-ae92-652a6a1a8689",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "missing_from_sq = nearest_square*nearest_square - len(X_train.columns)\n",
    "missing_from_sq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "5d61b6d7-8b75-43d5-a533-18d84f5e97a1",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "add_missing_cols = ['feature_'+str(x) for x in range(len(X_train.columns), int(nearest_square*nearest_square))]\n",
    "for col in add_missing_cols:\n",
    "    X_train[col] = [np.nan for x in range(len(X_train))]\n",
    "\n",
    "for col in add_missing_cols:\n",
    "    X_test[col] = [np.nan for x in range(len(X_test))]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "b94f6ac1-faa3-4336-b693-771e45e6ec97",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 812 µs, sys: 620 µs, total: 1.43 ms\n",
      "Wall time: 1.43 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "row = X_train.sample(1)\n",
    "paths = []\n",
    "ct=0\n",
    "\n",
    "def concat_tile(im_list_2d):\n",
    "    return cv2.vconcat([cv2.hconcat(im_list_h) for im_list_h in im_list_2d])\n",
    "\n",
    "def tint_image(src, color=\"#FFFFFF\"):\n",
    "    src.load()\n",
    "    r, g, b = src.split()\n",
    "    gray = ImageOps.grayscale(src)\n",
    "    result = ImageOps.colorize(gray, (0, 0, 0, 0), color) \n",
    "    return result\n",
    "\n",
    "\n",
    "class encoder():\n",
    "    def __init__(self):\n",
    "        self.ct = 0\n",
    "        \n",
    "    def run(self, text, image_path, limit=256):\n",
    "        \"\"\"\n",
    "        Take a string of text and encode it into an 8-bit grayscale image.\n",
    "        :param str text: Text may be ASCII or UTF-8 but limit value must be changed accordingly.\n",
    "        :param str image_path: Path to image file. Should have a '.png' extension or no extension\n",
    "        :param int limit: The value limit for each pixel. 256 = 8 bit meaning all character encoding schemes using 8 or\n",
    "        fewer bit can be encoded. If limit is 65536 then character encoding schemes using 16 bits or less can be applied\n",
    "        e.g. UTF-8. When a character is used from a character set greater than the limit, the character value will be\n",
    "        divided by the limit value. e.g. limit=256 character=Ĭ (value=300), resulting value will be 44. For values equal to\n",
    "        the limit, the resulting value will be 1 to avoid NULL within the encoded data. Limit is the number of possible\n",
    "        values in decimal from 1 to a max value. (default=256 i.e. 8 bit pixels/ 1- 256 means 255 possible values)\n",
    "        :return str:  The path to the image produced.\n",
    "        \"\"\"\n",
    "        if type(text) is not str:\n",
    "            raise TypeError(\"Parameter 'text' must be a string.\")\n",
    "        text_length = len(text)\n",
    "        size = get_image_size(text_length)\n",
    "        result_path = check_filename(image_path, extension=\".png\")\n",
    "        \n",
    "        img = PIL.Image.new(\"RGB\", size)  # grayscale, blank black image\n",
    "        ind = 0\n",
    "        for row in range(0, size[0]):\n",
    "            for col in range(0, size[1]):\n",
    "                if ind < text_length:  # only change pixel value for length of text\n",
    "                    pixel_value = convert_char_to_int(text[ind], limit=limit)\n",
    "                    img.putpixel((row, col), (255-pixel_value, pixel_value, 255-pixel_value))\n",
    "                    ind += 1\n",
    "                else:  # end of text, leave remaining pixel(s) black to indicate null\n",
    "                    break\n",
    "                    \n",
    "        newsize = (24, 24)     \n",
    "        img = img.resize(newsize)\n",
    "        return np.array(img) \n",
    "    \n",
    "    \n",
    "\n",
    "class build_image():\n",
    "    \n",
    "    def __init__(self, data_x, data_y, savepath):        \n",
    "        self.ct = 0\n",
    "        self.l = []\n",
    "        self.paths=[]\n",
    "        self.t = time.time()\n",
    "        self.enc = encoder()\n",
    "        self.data_x = data_x\n",
    "        self.data_y = data_y\n",
    "        self.savepath = savepath\n",
    "    \n",
    "    def run(self, indx):\n",
    "        row = self.data_x.iloc[[indx]]\n",
    "        price = self.data_y.iloc[indx]\n",
    "        for col in row.columns:\n",
    "            for val in row[col].astype(str).str.encode(encoding = 'utf8').values:\n",
    "                im = self.enc.run(str(val).replace(\"b'\",\"\").replace(\"'\",\"\"), \"image\"+str(self.ct)+\".png\")\n",
    "                self.paths.append(im)\n",
    "                self.ct+=1\n",
    "                if self.ct % nearest_square == 0:\n",
    "                    self.l.append(self.paths)\n",
    "                    self.paths=[]\n",
    "\n",
    "        im_tile = concat_tile(self.l)\n",
    "        im = PIL.Image.fromarray(im_tile)\n",
    "        newsize = (299, 299) \n",
    "        im = im.resize(newsize) \n",
    "        im.save(self.savepath+\"opencvconcattile_\"+str(indx)+\"_\"+str(price)+\"_.png\")\n",
    "        self.l=[]\n",
    "        if self.ct % 10000 == 0:\n",
    "            print(indx, time.time() - self.t)\n",
    "        self.t = time.time()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "5140f826-8c34-43d2-9856-c1020b3c6074",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>Beds</th>\n",
       "      <th>Baths</th>\n",
       "      <th>Area</th>\n",
       "      <th>Noise</th>\n",
       "      <th>PropertyType</th>\n",
       "      <th>DaysOnRealtor.com</th>\n",
       "      <th>YearBuilt</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>City_x</th>\n",
       "      <th>County</th>\n",
       "      <th>FemaInfo</th>\n",
       "      <th>FloodFactorInfo</th>\n",
       "      <th>LastSoldYear</th>\n",
       "      <th>SizeRank</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>622</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>1640.0</td>\n",
       "      <td>Medium</td>\n",
       "      <td>Townhome</td>\n",
       "      <td>104.0</td>\n",
       "      <td>1973.0</td>\n",
       "      <td>25.937100</td>\n",
       "      <td>-80.133733</td>\n",
       "      <td>North Miami Beach</td>\n",
       "      <td>Miami-Dade County</td>\n",
       "      <td>AE   ()</td>\n",
       "      <td>flood_factor_high</td>\n",
       "      <td>2009.0</td>\n",
       "      <td>79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>811</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1862.0</td>\n",
       "      <td>Medium</td>\n",
       "      <td>Condo</td>\n",
       "      <td>1021.0</td>\n",
       "      <td>2004.0</td>\n",
       "      <td>25.842794</td>\n",
       "      <td>-80.122788</td>\n",
       "      <td>Miami Beach</td>\n",
       "      <td>Miami-Dade County</td>\n",
       "      <td>AE   ()</td>\n",
       "      <td>flood_factor_high</td>\n",
       "      <td>2010.0</td>\n",
       "      <td>636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>734</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1932.0</td>\n",
       "      <td>Medium</td>\n",
       "      <td>Single Family Home</td>\n",
       "      <td>51.0</td>\n",
       "      <td>1987.0</td>\n",
       "      <td>28.044072</td>\n",
       "      <td>-82.401205</td>\n",
       "      <td>Tampa</td>\n",
       "      <td>Hillsborough County</td>\n",
       "      <td>X   ()</td>\n",
       "      <td>flood_factor_low</td>\n",
       "      <td>2004.0</td>\n",
       "      <td>1023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>387</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1750.0</td>\n",
       "      <td>Medium</td>\n",
       "      <td>Townhome</td>\n",
       "      <td>33.0</td>\n",
       "      <td>2005.0</td>\n",
       "      <td>27.752627</td>\n",
       "      <td>-82.414638</td>\n",
       "      <td>Apollo Beach</td>\n",
       "      <td>Hillsborough County</td>\n",
       "      <td>AE   ()</td>\n",
       "      <td>flood_factor_high</td>\n",
       "      <td>2012.0</td>\n",
       "      <td>5376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>364</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1732.0</td>\n",
       "      <td>Low</td>\n",
       "      <td>Single Family Home</td>\n",
       "      <td>17.0</td>\n",
       "      <td>1985.0</td>\n",
       "      <td>26.716497</td>\n",
       "      <td>-80.216349</td>\n",
       "      <td>Royal Palm Beach</td>\n",
       "      <td>Palm Beach County</td>\n",
       "      <td>X   ()</td>\n",
       "      <td>flood_factor_low</td>\n",
       "      <td>2017.0</td>\n",
       "      <td>90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>745</th>\n",
       "      <td>840</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1060.0</td>\n",
       "      <td>Medium</td>\n",
       "      <td>Condo</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1979.0</td>\n",
       "      <td>26.204291</td>\n",
       "      <td>-80.272675</td>\n",
       "      <td>Fort Lauderdale</td>\n",
       "      <td>Broward County</td>\n",
       "      <td>X500   ()</td>\n",
       "      <td>flood_factor_low</td>\n",
       "      <td>2004.0</td>\n",
       "      <td>401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>746</th>\n",
       "      <td>102</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2421.0</td>\n",
       "      <td>Medium</td>\n",
       "      <td>Single Family Home</td>\n",
       "      <td>29.0</td>\n",
       "      <td>1986.0</td>\n",
       "      <td>28.053214</td>\n",
       "      <td>-82.380432</td>\n",
       "      <td>Temple Terrace</td>\n",
       "      <td>Hillsborough County</td>\n",
       "      <td>X   ()</td>\n",
       "      <td>flood_factor_low</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>1023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>747</th>\n",
       "      <td>827</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3392.0</td>\n",
       "      <td>Medium</td>\n",
       "      <td>Condo</td>\n",
       "      <td>41.0</td>\n",
       "      <td>2020.0</td>\n",
       "      <td>26.422176</td>\n",
       "      <td>-81.905178</td>\n",
       "      <td>Fort Myers Beach</td>\n",
       "      <td>Lee County</td>\n",
       "      <td>VE   ()</td>\n",
       "      <td>flood_factor_high</td>\n",
       "      <td>2017.0</td>\n",
       "      <td>5839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>748</th>\n",
       "      <td>715</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2137.0</td>\n",
       "      <td>Low</td>\n",
       "      <td>Condo</td>\n",
       "      <td>71.0</td>\n",
       "      <td>1992.0</td>\n",
       "      <td>26.439186</td>\n",
       "      <td>-81.920834</td>\n",
       "      <td>Fort Myers Beach</td>\n",
       "      <td>Lee County</td>\n",
       "      <td>AE   ()</td>\n",
       "      <td>flood_factor_high</td>\n",
       "      <td>2004.0</td>\n",
       "      <td>5839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>749</th>\n",
       "      <td>1005</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>2550.0</td>\n",
       "      <td>Low</td>\n",
       "      <td>Single Family Home</td>\n",
       "      <td>81.0</td>\n",
       "      <td>1989.0</td>\n",
       "      <td>27.136977</td>\n",
       "      <td>-80.266876</td>\n",
       "      <td>Palm City</td>\n",
       "      <td>Martin County</td>\n",
       "      <td>X   ()</td>\n",
       "      <td>flood_factor_low</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>2950</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>750 rows × 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     index  Beds  Baths    Area    Noise        PropertyType  \\\n",
       "0      622   3.0    2.5  1640.0   Medium            Townhome   \n",
       "1      811   3.0    3.5  1862.0   Medium               Condo   \n",
       "2      734   4.0    3.0  1932.0   Medium  Single Family Home   \n",
       "3      387   3.0    2.0  1750.0   Medium            Townhome   \n",
       "4      364   3.0    2.0  1732.0      Low  Single Family Home   \n",
       "..     ...   ...    ...     ...      ...                 ...   \n",
       "745    840   2.0    2.0  1060.0   Medium               Condo   \n",
       "746    102   4.0    3.0  2421.0   Medium  Single Family Home   \n",
       "747    827   4.0    3.5  3392.0   Medium               Condo   \n",
       "748    715   3.0    3.0  2137.0      Low               Condo   \n",
       "749   1005   4.0    3.5  2550.0      Low  Single Family Home   \n",
       "\n",
       "     DaysOnRealtor.com  YearBuilt   Latitude  Longitude             City_x  \\\n",
       "0                104.0     1973.0  25.937100 -80.133733  North Miami Beach   \n",
       "1               1021.0     2004.0  25.842794 -80.122788        Miami Beach   \n",
       "2                 51.0     1987.0  28.044072 -82.401205              Tampa   \n",
       "3                 33.0     2005.0  27.752627 -82.414638       Apollo Beach   \n",
       "4                 17.0     1985.0  26.716497 -80.216349   Royal Palm Beach   \n",
       "..                 ...        ...        ...        ...                ...   \n",
       "745                8.0     1979.0  26.204291 -80.272675    Fort Lauderdale   \n",
       "746               29.0     1986.0  28.053214 -82.380432     Temple Terrace   \n",
       "747               41.0     2020.0  26.422176 -81.905178   Fort Myers Beach   \n",
       "748               71.0     1992.0  26.439186 -81.920834   Fort Myers Beach   \n",
       "749               81.0     1989.0  27.136977 -80.266876          Palm City   \n",
       "\n",
       "                  County   FemaInfo    FloodFactorInfo  LastSoldYear  SizeRank  \n",
       "0      Miami-Dade County    AE   ()  flood_factor_high        2009.0        79  \n",
       "1      Miami-Dade County    AE   ()  flood_factor_high        2010.0       636  \n",
       "2    Hillsborough County     X   ()   flood_factor_low        2004.0      1023  \n",
       "3    Hillsborough County    AE   ()  flood_factor_high        2012.0      5376  \n",
       "4      Palm Beach County     X   ()   flood_factor_low        2017.0        90  \n",
       "..                   ...        ...                ...           ...       ...  \n",
       "745       Broward County  X500   ()   flood_factor_low        2004.0       401  \n",
       "746  Hillsborough County     X   ()   flood_factor_low        2019.0      1023  \n",
       "747           Lee County    VE   ()  flood_factor_high        2017.0      5839  \n",
       "748           Lee County    AE   ()  flood_factor_high        2004.0      5839  \n",
       "749        Martin County     X   ()   flood_factor_low        2019.0      2950  \n",
       "\n",
       "[750 rows x 16 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "031cd280-7aae-47e3-a887-c82d40f2758f",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Beds</th>\n",
       "      <th>Baths</th>\n",
       "      <th>Area</th>\n",
       "      <th>Noise</th>\n",
       "      <th>PropertyType</th>\n",
       "      <th>DaysOnRealtor.com</th>\n",
       "      <th>YearBuilt</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>City_x</th>\n",
       "      <th>County</th>\n",
       "      <th>FemaInfo</th>\n",
       "      <th>FloodFactorInfo</th>\n",
       "      <th>LastSoldYear</th>\n",
       "      <th>SizeRank</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>index</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>1640.0</td>\n",
       "      <td>Medium</td>\n",
       "      <td>Townhome</td>\n",
       "      <td>104.0</td>\n",
       "      <td>1973.0</td>\n",
       "      <td>25.937100</td>\n",
       "      <td>-80.133733</td>\n",
       "      <td>North Miami Beach</td>\n",
       "      <td>Miami-Dade County</td>\n",
       "      <td>AE   ()</td>\n",
       "      <td>flood_factor_high</td>\n",
       "      <td>2009.0</td>\n",
       "      <td>79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1862.0</td>\n",
       "      <td>Medium</td>\n",
       "      <td>Condo</td>\n",
       "      <td>1021.0</td>\n",
       "      <td>2004.0</td>\n",
       "      <td>25.842794</td>\n",
       "      <td>-80.122788</td>\n",
       "      <td>Miami Beach</td>\n",
       "      <td>Miami-Dade County</td>\n",
       "      <td>AE   ()</td>\n",
       "      <td>flood_factor_high</td>\n",
       "      <td>2010.0</td>\n",
       "      <td>636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1932.0</td>\n",
       "      <td>Medium</td>\n",
       "      <td>Single Family Home</td>\n",
       "      <td>51.0</td>\n",
       "      <td>1987.0</td>\n",
       "      <td>28.044072</td>\n",
       "      <td>-82.401205</td>\n",
       "      <td>Tampa</td>\n",
       "      <td>Hillsborough County</td>\n",
       "      <td>X   ()</td>\n",
       "      <td>flood_factor_low</td>\n",
       "      <td>2004.0</td>\n",
       "      <td>1023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1750.0</td>\n",
       "      <td>Medium</td>\n",
       "      <td>Townhome</td>\n",
       "      <td>33.0</td>\n",
       "      <td>2005.0</td>\n",
       "      <td>27.752627</td>\n",
       "      <td>-82.414638</td>\n",
       "      <td>Apollo Beach</td>\n",
       "      <td>Hillsborough County</td>\n",
       "      <td>AE   ()</td>\n",
       "      <td>flood_factor_high</td>\n",
       "      <td>2012.0</td>\n",
       "      <td>5376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1732.0</td>\n",
       "      <td>Low</td>\n",
       "      <td>Single Family Home</td>\n",
       "      <td>17.0</td>\n",
       "      <td>1985.0</td>\n",
       "      <td>26.716497</td>\n",
       "      <td>-80.216349</td>\n",
       "      <td>Royal Palm Beach</td>\n",
       "      <td>Palm Beach County</td>\n",
       "      <td>X   ()</td>\n",
       "      <td>flood_factor_low</td>\n",
       "      <td>2017.0</td>\n",
       "      <td>90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>745</th>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1060.0</td>\n",
       "      <td>Medium</td>\n",
       "      <td>Condo</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1979.0</td>\n",
       "      <td>26.204291</td>\n",
       "      <td>-80.272675</td>\n",
       "      <td>Fort Lauderdale</td>\n",
       "      <td>Broward County</td>\n",
       "      <td>X500   ()</td>\n",
       "      <td>flood_factor_low</td>\n",
       "      <td>2004.0</td>\n",
       "      <td>401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>746</th>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2421.0</td>\n",
       "      <td>Medium</td>\n",
       "      <td>Single Family Home</td>\n",
       "      <td>29.0</td>\n",
       "      <td>1986.0</td>\n",
       "      <td>28.053214</td>\n",
       "      <td>-82.380432</td>\n",
       "      <td>Temple Terrace</td>\n",
       "      <td>Hillsborough County</td>\n",
       "      <td>X   ()</td>\n",
       "      <td>flood_factor_low</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>1023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>747</th>\n",
       "      <td>4.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3392.0</td>\n",
       "      <td>Medium</td>\n",
       "      <td>Condo</td>\n",
       "      <td>41.0</td>\n",
       "      <td>2020.0</td>\n",
       "      <td>26.422176</td>\n",
       "      <td>-81.905178</td>\n",
       "      <td>Fort Myers Beach</td>\n",
       "      <td>Lee County</td>\n",
       "      <td>VE   ()</td>\n",
       "      <td>flood_factor_high</td>\n",
       "      <td>2017.0</td>\n",
       "      <td>5839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>748</th>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2137.0</td>\n",
       "      <td>Low</td>\n",
       "      <td>Condo</td>\n",
       "      <td>71.0</td>\n",
       "      <td>1992.0</td>\n",
       "      <td>26.439186</td>\n",
       "      <td>-81.920834</td>\n",
       "      <td>Fort Myers Beach</td>\n",
       "      <td>Lee County</td>\n",
       "      <td>AE   ()</td>\n",
       "      <td>flood_factor_high</td>\n",
       "      <td>2004.0</td>\n",
       "      <td>5839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>749</th>\n",
       "      <td>4.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>2550.0</td>\n",
       "      <td>Low</td>\n",
       "      <td>Single Family Home</td>\n",
       "      <td>81.0</td>\n",
       "      <td>1989.0</td>\n",
       "      <td>27.136977</td>\n",
       "      <td>-80.266876</td>\n",
       "      <td>Palm City</td>\n",
       "      <td>Martin County</td>\n",
       "      <td>X   ()</td>\n",
       "      <td>flood_factor_low</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>2950</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>750 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Beds  Baths    Area    Noise        PropertyType  DaysOnRealtor.com  \\\n",
       "index                                                                        \n",
       "0       3.0    2.5  1640.0   Medium            Townhome              104.0   \n",
       "1       3.0    3.5  1862.0   Medium               Condo             1021.0   \n",
       "2       4.0    3.0  1932.0   Medium  Single Family Home               51.0   \n",
       "3       3.0    2.0  1750.0   Medium            Townhome               33.0   \n",
       "4       3.0    2.0  1732.0      Low  Single Family Home               17.0   \n",
       "...     ...    ...     ...      ...                 ...                ...   \n",
       "745     2.0    2.0  1060.0   Medium               Condo                8.0   \n",
       "746     4.0    3.0  2421.0   Medium  Single Family Home               29.0   \n",
       "747     4.0    3.5  3392.0   Medium               Condo               41.0   \n",
       "748     3.0    3.0  2137.0      Low               Condo               71.0   \n",
       "749     4.0    3.5  2550.0      Low  Single Family Home               81.0   \n",
       "\n",
       "       YearBuilt   Latitude  Longitude             City_x  \\\n",
       "index                                                       \n",
       "0         1973.0  25.937100 -80.133733  North Miami Beach   \n",
       "1         2004.0  25.842794 -80.122788        Miami Beach   \n",
       "2         1987.0  28.044072 -82.401205              Tampa   \n",
       "3         2005.0  27.752627 -82.414638       Apollo Beach   \n",
       "4         1985.0  26.716497 -80.216349   Royal Palm Beach   \n",
       "...          ...        ...        ...                ...   \n",
       "745       1979.0  26.204291 -80.272675    Fort Lauderdale   \n",
       "746       1986.0  28.053214 -82.380432     Temple Terrace   \n",
       "747       2020.0  26.422176 -81.905178   Fort Myers Beach   \n",
       "748       1992.0  26.439186 -81.920834   Fort Myers Beach   \n",
       "749       1989.0  27.136977 -80.266876          Palm City   \n",
       "\n",
       "                    County   FemaInfo    FloodFactorInfo  LastSoldYear  \\\n",
       "index                                                                    \n",
       "0        Miami-Dade County    AE   ()  flood_factor_high        2009.0   \n",
       "1        Miami-Dade County    AE   ()  flood_factor_high        2010.0   \n",
       "2      Hillsborough County     X   ()   flood_factor_low        2004.0   \n",
       "3      Hillsborough County    AE   ()  flood_factor_high        2012.0   \n",
       "4        Palm Beach County     X   ()   flood_factor_low        2017.0   \n",
       "...                    ...        ...                ...           ...   \n",
       "745         Broward County  X500   ()   flood_factor_low        2004.0   \n",
       "746    Hillsborough County     X   ()   flood_factor_low        2019.0   \n",
       "747             Lee County    VE   ()  flood_factor_high        2017.0   \n",
       "748             Lee County    AE   ()  flood_factor_high        2004.0   \n",
       "749          Martin County     X   ()   flood_factor_low        2019.0   \n",
       "\n",
       "       SizeRank  \n",
       "index            \n",
       "0            79  \n",
       "1           636  \n",
       "2          1023  \n",
       "3          5376  \n",
       "4            90  \n",
       "...         ...  \n",
       "745         401  \n",
       "746        1023  \n",
       "747        5839  \n",
       "748        5839  \n",
       "749        2950  \n",
       "\n",
       "[750 rows x 15 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target = 'yearly_price_delta_percent'\n",
    "\n",
    "data = X_train.drop('index',axis=1).reset_index().set_index('index')\n",
    "data[target] = y_train.drop('index',axis=1).reset_index().set_index('index')\n",
    "X_train = data.drop(target,axis=1)\n",
    "y_train = data[target]\n",
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "79443c2c-7a7d-4a1e-a9e0-b7d8d980f550",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Beds</th>\n",
       "      <th>Baths</th>\n",
       "      <th>Area</th>\n",
       "      <th>Noise</th>\n",
       "      <th>PropertyType</th>\n",
       "      <th>DaysOnRealtor.com</th>\n",
       "      <th>YearBuilt</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>City_x</th>\n",
       "      <th>County</th>\n",
       "      <th>FemaInfo</th>\n",
       "      <th>FloodFactorInfo</th>\n",
       "      <th>LastSoldYear</th>\n",
       "      <th>SizeRank</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>index</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.0</td>\n",
       "      <td>5.5</td>\n",
       "      <td>5123.0</td>\n",
       "      <td>Medium</td>\n",
       "      <td>Single Family Home</td>\n",
       "      <td>164.0</td>\n",
       "      <td>2005.0</td>\n",
       "      <td>26.143917</td>\n",
       "      <td>-80.303507</td>\n",
       "      <td>Plantation</td>\n",
       "      <td>Broward County</td>\n",
       "      <td>AH   ()</td>\n",
       "      <td>flood_factor_low</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>6109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.0</td>\n",
       "      <td>1.5</td>\n",
       "      <td>1075.0</td>\n",
       "      <td>Medium</td>\n",
       "      <td>Condo</td>\n",
       "      <td>172.0</td>\n",
       "      <td>1976.0</td>\n",
       "      <td>25.996491</td>\n",
       "      <td>-80.120727</td>\n",
       "      <td>Hallandale Beach</td>\n",
       "      <td>Broward County</td>\n",
       "      <td>AE   ()</td>\n",
       "      <td>flood_factor_high</td>\n",
       "      <td>2011.0</td>\n",
       "      <td>230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2790.0</td>\n",
       "      <td>Medium</td>\n",
       "      <td>Single Family Home</td>\n",
       "      <td>55.0</td>\n",
       "      <td>2014.0</td>\n",
       "      <td>27.780161</td>\n",
       "      <td>-82.380489</td>\n",
       "      <td>Apollo Beach</td>\n",
       "      <td>Hillsborough County</td>\n",
       "      <td>X   ()</td>\n",
       "      <td>flood_factor_low</td>\n",
       "      <td>2014.0</td>\n",
       "      <td>5376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1446.0</td>\n",
       "      <td>Low</td>\n",
       "      <td>Single Family Home</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1980.0</td>\n",
       "      <td>27.858340</td>\n",
       "      <td>-82.806344</td>\n",
       "      <td>Seminole</td>\n",
       "      <td>Pinellas County</td>\n",
       "      <td>X   ()</td>\n",
       "      <td>flood_factor_low</td>\n",
       "      <td>2020.0</td>\n",
       "      <td>3848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>1815.0</td>\n",
       "      <td>Medium</td>\n",
       "      <td>Single Family Home</td>\n",
       "      <td>190.0</td>\n",
       "      <td>1999.0</td>\n",
       "      <td>27.273789</td>\n",
       "      <td>-80.241492</td>\n",
       "      <td>Jensen Beach</td>\n",
       "      <td>St. Lucie County</td>\n",
       "      <td>X   ()</td>\n",
       "      <td>flood_factor_low</td>\n",
       "      <td>2013.0</td>\n",
       "      <td>2713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>183</th>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2396.0</td>\n",
       "      <td>Medium</td>\n",
       "      <td>Single Family Home</td>\n",
       "      <td>121.0</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>27.096781</td>\n",
       "      <td>-80.144033</td>\n",
       "      <td>Hobe Sound</td>\n",
       "      <td>Martin County</td>\n",
       "      <td>X   ()</td>\n",
       "      <td>flood_factor_high</td>\n",
       "      <td>1999.0</td>\n",
       "      <td>4235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>184</th>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1404.0</td>\n",
       "      <td>Medium</td>\n",
       "      <td>Single Family Home</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1981.0</td>\n",
       "      <td>27.890649</td>\n",
       "      <td>-82.773214</td>\n",
       "      <td>Largo</td>\n",
       "      <td>Pinellas County</td>\n",
       "      <td>AE   ()</td>\n",
       "      <td>flood_factor_low</td>\n",
       "      <td>2020.0</td>\n",
       "      <td>6070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>185</th>\n",
       "      <td>3.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3265.0</td>\n",
       "      <td>Medium</td>\n",
       "      <td>Condo</td>\n",
       "      <td>240.0</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>25.823095</td>\n",
       "      <td>-80.131016</td>\n",
       "      <td>Miami Beach</td>\n",
       "      <td>Miami-Dade County</td>\n",
       "      <td>AE   ()</td>\n",
       "      <td>flood_factor_high</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>2639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>186</th>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1858.0</td>\n",
       "      <td>N/A</td>\n",
       "      <td>Single Family Home</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1985.0</td>\n",
       "      <td>27.759939</td>\n",
       "      <td>-80.584307</td>\n",
       "      <td>Fellsmere</td>\n",
       "      <td>Indian River County</td>\n",
       "      <td>A   ()</td>\n",
       "      <td>flood_factor_low</td>\n",
       "      <td>2020.0</td>\n",
       "      <td>12426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>187</th>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1522.0</td>\n",
       "      <td>Medium</td>\n",
       "      <td>Single Family Home</td>\n",
       "      <td>43.0</td>\n",
       "      <td>1955.0</td>\n",
       "      <td>26.218289</td>\n",
       "      <td>-80.101402</td>\n",
       "      <td>Pompano Beach</td>\n",
       "      <td>Broward County</td>\n",
       "      <td>AE   ()</td>\n",
       "      <td>flood_factor_high</td>\n",
       "      <td>2010.0</td>\n",
       "      <td>1036</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>188 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Beds  Baths    Area    Noise        PropertyType  DaysOnRealtor.com  \\\n",
       "index                                                                        \n",
       "0       5.0    5.5  5123.0   Medium  Single Family Home              164.0   \n",
       "1       2.0    1.5  1075.0   Medium               Condo              172.0   \n",
       "2       4.0    3.0  2790.0   Medium  Single Family Home               55.0   \n",
       "3       3.0    2.0  1446.0      Low  Single Family Home               22.0   \n",
       "4       3.0    2.5  1815.0   Medium  Single Family Home              190.0   \n",
       "...     ...    ...     ...      ...                 ...                ...   \n",
       "183     3.0    3.0  2396.0   Medium  Single Family Home              121.0   \n",
       "184     3.0    2.0  1404.0   Medium  Single Family Home                9.0   \n",
       "185     3.0    3.5  3265.0   Medium               Condo              240.0   \n",
       "186     3.0    2.0  1858.0      N/A  Single Family Home                3.0   \n",
       "187     2.0    2.0  1522.0   Medium  Single Family Home               43.0   \n",
       "\n",
       "       YearBuilt   Latitude  Longitude            City_x               County  \\\n",
       "index                                                                           \n",
       "0         2005.0  26.143917 -80.303507        Plantation       Broward County   \n",
       "1         1976.0  25.996491 -80.120727  Hallandale Beach       Broward County   \n",
       "2         2014.0  27.780161 -82.380489      Apollo Beach  Hillsborough County   \n",
       "3         1980.0  27.858340 -82.806344          Seminole      Pinellas County   \n",
       "4         1999.0  27.273789 -80.241492      Jensen Beach     St. Lucie County   \n",
       "...          ...        ...        ...               ...                  ...   \n",
       "183       2000.0  27.096781 -80.144033        Hobe Sound        Martin County   \n",
       "184       1981.0  27.890649 -82.773214             Largo      Pinellas County   \n",
       "185       2019.0  25.823095 -80.131016       Miami Beach    Miami-Dade County   \n",
       "186       1985.0  27.759939 -80.584307         Fellsmere  Indian River County   \n",
       "187       1955.0  26.218289 -80.101402     Pompano Beach       Broward County   \n",
       "\n",
       "      FemaInfo    FloodFactorInfo  LastSoldYear  SizeRank  \n",
       "index                                                      \n",
       "0      AH   ()   flood_factor_low        2016.0      6109  \n",
       "1      AE   ()  flood_factor_high        2011.0       230  \n",
       "2       X   ()   flood_factor_low        2014.0      5376  \n",
       "3       X   ()   flood_factor_low        2020.0      3848  \n",
       "4       X   ()   flood_factor_low        2013.0      2713  \n",
       "...        ...                ...           ...       ...  \n",
       "183     X   ()  flood_factor_high        1999.0      4235  \n",
       "184    AE   ()   flood_factor_low        2020.0      6070  \n",
       "185    AE   ()  flood_factor_high        2019.0      2639  \n",
       "186     A   ()   flood_factor_low        2020.0     12426  \n",
       "187    AE   ()  flood_factor_high        2010.0      1036  \n",
       "\n",
       "[188 rows x 15 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = X_test.drop('index',axis=1).reset_index().set_index('index')\n",
    "data[target] = y_test.drop('index',axis=1).reset_index().set_index('index')\n",
    "X_test = data.drop(target,axis=1)\n",
    "y_test = data[target]\n",
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "7e939ace-fe2c-468e-aa99-9bbd0fe7736d",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import shutil, os\n",
    "shutil.rmtree('../data/colorframes')\n",
    "shutil.rmtree('../data/train')\n",
    "shutil.rmtree('../data/test')\n",
    "os.mkdir('../data/colorframes')\n",
    "os.mkdir('../data/train')\n",
    "os.mkdir('../data/test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "91c3d2ea-1d13-4fa0-847f-cc26a7380034",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    None\n",
       "Name: indx, dtype: object"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#create a colorframe sample to test that things work as expected\n",
    "s = pd.DataFrame({})\n",
    "s['indx'] = [indx for indx in [35]]\n",
    "bi = build_image(X_train, y_train, '../data/colorframes/')\n",
    "s['indx'].apply(bi.run)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "24efc7e5-f801-4569-9ae9-719fd691a62c",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      None\n",
       "1      None\n",
       "2      None\n",
       "3      None\n",
       "4      None\n",
       "       ... \n",
       "745    None\n",
       "746    None\n",
       "747    None\n",
       "748    None\n",
       "749    None\n",
       "Name: indx, Length: 750, dtype: object"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = pd.DataFrame({})\n",
    "s['indx'] = [indx for indx in y_train.index]\n",
    "bi = build_image(X_train, y_train, '../data/train/')\n",
    "s['indx'].apply(bi.run)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "9d9944aa-e716-49f5-be4c-224254e6349f",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      None\n",
       "1      None\n",
       "2      None\n",
       "3      None\n",
       "4      None\n",
       "       ... \n",
       "183    None\n",
       "184    None\n",
       "185    None\n",
       "186    None\n",
       "187    None\n",
       "Name: indx, Length: 188, dtype: object"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = pd.DataFrame({})\n",
    "s['indx'] = [indx for indx in y_test.index]\n",
    "bi = build_image(X_test, y_test, '../data/test/')\n",
    "s['indx'].apply(bi.run)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "f56b2a49-c657-4419-9791-a90edc07aac5",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "directory = '../data/train'\n",
    "dirr = ['../data/train/'+filename for filename in os.listdir(directory) if filename.endswith('.png')]\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "\n",
    "train_images = []\n",
    "test_images = []\n",
    "train_yy = []\n",
    "test_yy = []\n",
    "\n",
    "for d in dirr:\n",
    "    im = load_img(d)\n",
    "    train_images.append(img_to_array(im))\n",
    "    train_yy.append(round(float(d.split('_')[2]),4))\n",
    "    \n",
    "    \n",
    "directory = '../data/test'\n",
    "dirr = ['../data/test/'+filename for filename in os.listdir(directory) if filename.endswith('.png')]\n",
    "\n",
    "for d in dirr:\n",
    "    im = load_img(d)\n",
    "    test_images.append(img_to_array(im))\n",
    "    test_yy.append(round(float(d.split('_')[2]),4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "dbfa982f-3b5b-453a-9af7-3c7efd4dc4d1",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Part 1. Create model and view TensorBoard in notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "35e180b6-0147-4d31-a014-56b54c5eeb00",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.optimizers import Adam, SGD\n",
    "from tensorflow.keras.applications import MobileNet, VGG16, ResNet50, Xception, MobileNetV2\n",
    "from tensorflow.keras.layers import Conv2D, Flatten, Dense, Activation, Dense, Flatten, MaxPooling2D, Dropout\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.layers import Input\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "# import python.keras.engine\n",
    "from tensorflow.keras.layers import Layer, InputSpec\n",
    "from tensorflow.keras.utils import get_file\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.applications.imagenet_utils import preprocess_input"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "7cc9fcda-e59d-4382-8bd9-a7e980395eff",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Create callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "b29f6106-57d2-48f5-b41f-424937f415c7",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "\n",
    "# In the following lines, replace <username> with your username.\n",
    "experiment_log_dir = \"../data/tb\"\n",
    "checkpoint_path = \"../data/keras_checkpoint_weights.ckpt\"\n",
    "\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=experiment_log_dir)\n",
    "model_checkpoint = ModelCheckpoint(filepath=checkpoint_path, verbose=1, save_best_only=True)\n",
    "early_stopping = EarlyStopping(monitor=\"loss\", mode=\"min\", patience=3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "cdb6f7e6-3c7a-4241-ad07-3fcf6ef830f2",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### TensorBoard commands for Databricks Runtime 7.2 ML and above\n",
    "\n",
    "When you start TensorBoard this way, it continues to run until you detach the notebook from the cluster.  \n",
    "Note: to clear the TensorBoard between runs, use this command: `dbutils.fs.rm(experiment_log_dir.replace(\"/dbfs\",\"\"), recurse=True)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "92278f15-7be3-4c95-8ff6-f1e6502ed55a",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6006 (pid 35748), started 7:20:12 ago. (Use '!kill 35748' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-2ba5e67a764a3b9c\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-2ba5e67a764a3b9c\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --logdir $experiment_log_dir"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "0f57ad72-bb1c-407c-bddd-d180bf869b22",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Part 2. Hyperparameter tuning with Hyperopt and MLflow\n",
    "[Hyperopt](https://github.com/hyperopt/hyperopt) is a Python library for hyperparameter tuning. Databricks Runtime for Machine Learning includes an optimized and enhanced version of Hyperopt, including automated MLflow tracking. For more information about using Hyperopt, see the [Hyperopt documentation](https://github.com/hyperopt/hyperopt/wiki/FMin)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "7f04954c-b1bb-4503-84aa-12d4471b87ad",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Create neural network model using variables for number of nodes in hidden layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "pname=''\n",
    "mname = 'imgframe'\n",
    "\n",
    "# Set the dimension of the images \n",
    "img_width = 299 \n",
    "img_height = 299\n",
    "\n",
    "#Create a bottleneck file\n",
    "model_path = '../models/mname.h5'.replace('mname',mname)\n",
    "json_path = '../models/mname.json'.replace('mname',mname)\n",
    "mlmodel_path = '../models/mname.mlmodel'.replace('mname',mname)\n",
    "\n",
    "# loading up our datasets\n",
    "train_data_dir = '../data/train'.replace('pname',pname)\n",
    "validation_data_dir = '../data/test'.replace('pname',pname) \n",
    "test_data_dir = '../data/test'.replace('pname',pname)\n",
    "\n",
    "# TensorFlow is the backend, so ordering of input_shape is as below\n",
    "input_shape = (img_width, img_height, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "2a63aa5c-8798-46cf-bed7-af0e4c7b443b",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "def create_model(n):\n",
    "    # Function to create model\n",
    "    # def create_model(learn_rate=1e-1, momentum=0.9, dropout_rate=0.0):\n",
    "    sys.stdout.write('Loading new model\\n\\n')\n",
    "    sys.stdout.flush()\n",
    "    base_model = Xception(input_shape=input_shape, \n",
    "                        include_top=False, \n",
    "                        pooling='avg', \n",
    "                        weights='imagenet')\n",
    "\n",
    "    for layer in base_model.layers:\n",
    "        layer.trainable = False\n",
    "\n",
    "    x2 = Dropout(n[\"dropout_rate\"])(base_model.layers[-1].output)\n",
    "    x = Dense(1, activation='linear', name='classLabels')(x2)\n",
    "    model = Model(base_model.input, x)\n",
    "    model.summary()\n",
    "\n",
    "    # Save model\n",
    "    with open(model_path, 'w') as outfile:\n",
    "        json.dump(model.to_json(), outfile)\n",
    "        outfile.close()\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "9892664d-d263-4a47-9363-7e756f2148d6",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Create Hyperopt objective function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "41c59092-f1e1-498b-92db-22b0ece3a919",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from hyperopt import fmin, hp, tpe, STATUS_OK, SparkTrials\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "\n",
    "\n",
    "def runNN(n):\n",
    "    # Import tensorflow \n",
    "    import tensorflow as tf\n",
    "\n",
    "    # Log run information with mlflow.tensorflow.autolog()\n",
    "    mlflow.tensorflow.autolog()\n",
    "\n",
    "    model = create_model(n)\n",
    "\n",
    "    # Select optimizer\n",
    "    optimizer_call = getattr(tf.keras.optimizers, n[\"optimizer\"])\n",
    "\n",
    "    if n[\"optimizer\"] == 'SGD': optimizer = optimizer_call(learning_rate=n[\"learning_rate\"], momentum=n[\"momentum\"])\n",
    "    else: optimizer = optimizer_call(learning_rate=n[\"learning_rate\"])\n",
    "\n",
    "    # Compile model\n",
    "    model.compile(optimizer=optimizer, \n",
    "                loss='mean_absolute_error', \n",
    "                metrics=['mse', \n",
    "                         'mean_absolute_percentage_error', \n",
    "                         'mean_absolute_error'])\n",
    "\n",
    "    # In the following lines, replace <username> with your username.\n",
    "    experiment_log_dir = \"../data/tb\"\n",
    "    checkpoint_path = \"../data/keras_checkpoint_weights.ckpt\"\n",
    "\n",
    "    tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=experiment_log_dir)\n",
    "    model_checkpoint = ModelCheckpoint(filepath=checkpoint_path, verbose=1, save_best_only=True)\n",
    "    early_stopping = EarlyStopping(monitor=\"val_mean_absolute_error\", mode=\"min\", patience=1)\n",
    "\n",
    "    history = model.fit(np.array(train_images), np.array(train_yy), \n",
    "                                  validation_split=.2, \n",
    "                                  epochs=n[\"epochs\"], \n",
    "                                  verbose=4,\n",
    "                                  batch_size=n[\"batch_size\"],\n",
    "                                  callbacks=[tensorboard_callback, model_checkpoint, early_stopping]\n",
    "                                 )\n",
    "\n",
    "    # Evaluate the model\n",
    "    score = model.evaluate(np.array(test_images), np.array(test_yy), verbose=1)\n",
    "    obj_metric = score[0]  \n",
    "    return {\"loss\": obj_metric, \"status\": STATUS_OK, \"model\":model}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "fc306aa6-353c-4961-b041-f7dda46a6169",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Define Hyperopt search space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "b1562ff2-32bd-47fc-88fa-1a4e665867ab",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "space = {\n",
    "  \"learning_rate\": hp.loguniform(\"learning_rate\", -7, 0),\n",
    "  \"optimizer\": hp.choice(\"optimizer\", [\"Adam\"]),\n",
    "  \"batch_size\": hp.choice(\"batch_size\", [2, 4,]),\n",
    "  \"epochs\": hp.choice(\"epochs\", [1, 3, 5]),\n",
    "  \"dropout_rate\": hp.choice(\"dropout_rate\", [0.0, 0.1, 0.2]),\n",
    " }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "c7ea83d5-04b9-4729-a0e2-d8dc56f08a9b",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Create the `SparkTrials` object\n",
    "\n",
    "The `SparkTrials` object tells `fmin()` to distribute the tuning job across a Spark cluster. When you create the `SparkTrials` object, you can use the `parallelism` argument to set the maximum number of trials to evaluate concurently. The default setting is the number of Spark executors available.  \n",
    "\n",
    "A higher number lets you scale-out testing of more hyperparameter settings. Because Hyperopt proposes new trials based on past results, there is a trade-off between parallelism and adaptivity. For a fixed `max_evals`, greater parallelism speeds up calculations, but lower parallelism may lead to better results since each iteration has access to more past results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you do not specify a parallelism argument, the default is the number of available Spark executors \n",
    "spark_trials = SparkTrials()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "1c0d4dcd-bf6a-4641-a8d5-9758c00ef506",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Perform hyperparameter tuning \n",
    "Put the `fmin()` call inside an MLflow run to save results to MLflow. MLflow tracks the parameters and performance metrics of each run.   \n",
    "\n",
    "After running the following cell, you can view the results in MLflow. Click **Experiment** at the upper right to display the Experiment Runs sidebar. Click the icon at the far right next to **Experiment Runs** to display the MLflow Runs Table.\n",
    "\n",
    "For more information about using MLflow to analyze runs, see ([AWS](https://docs.databricks.com/applications/mlflow/index.html)|[Azure](https://docs.microsoft.com/azure/databricks/applications/mlflow/))."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "8044d5a2-38f6-4914-98bd-f7cc6d5399ae",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\">Hyperopt with SparkTrials will automatically track trials in MLflow. To view the MLflow experiment associated with the notebook, click the &#39;Runs&#39; icon in the notebook context bar on the upper right. There, you can view all runs.\n",
       "To view logs from trials, please check the Spark executor logs. To view executor logs, expand &#39;Spark Jobs&#39; above until you see the (i) icon next to the stage from the trial job. Click it and find the list of tasks. Click the &#39;stderr&#39; link for a task to view trial logs.\n",
       "\r",
       "  0%|          | 0/30 [00:00&lt;?, ?trial/s, best loss=?]\r",
       "  3%|▎         | 1/30 [26:21&lt;12:44:17, 1581.30s/trial, best loss: 281.20147705078125]\r",
       " 10%|█         | 3/30 [26:27&lt;8:18:30, 1107.80s/trial, best loss: 106.79638671875]    \r",
       " 13%|█▎        | 4/30 [26:33&lt;5:36:54, 777.48s/trial, best loss: 25.169960021972656]\r",
       " 17%|█▋        | 5/30 [48:07&lt;6:28:29, 932.37s/trial, best loss: 25.169960021972656]\r",
       " 20%|██        | 6/30 [48:48&lt;4:25:56, 664.83s/trial, best loss: 18.75101089477539] \r",
       " 23%|██▎       | 7/30 [48:54&lt;2:59:05, 467.19s/trial, best loss: 18.75101089477539]\r",
       " 27%|██▋       | 8/30 [49:04&lt;2:01:03, 330.18s/trial, best loss: 18.75101089477539]\r",
       " 30%|███       | 9/30 [1:10:06&lt;3:33:20, 609.54s/trial, best loss: 18.75101089477539]\r",
       " 37%|███▋      | 11/30 [1:11:19&lt;2:18:35, 437.64s/trial, best loss: 1.7967373132705688]\r",
       " 40%|████      | 12/30 [1:11:33&lt;1:33:11, 310.65s/trial, best loss: 1.7967373132705688]\r",
       " 43%|████▎     | 13/30 [1:32:26&lt;2:48:07, 593.39s/trial, best loss: 1.7967373132705688]\r",
       " 47%|████▋     | 14/30 [1:35:00&lt;2:03:06, 461.63s/trial, best loss: 1.7967373132705688]\r",
       " 50%|█████     | 15/30 [1:35:03&lt;1:21:00, 324.05s/trial, best loss: 1.7967373132705688]\r",
       " 53%|█████▎    | 16/30 [1:35:24&lt;54:23, 233.14s/trial, best loss: 1.7967373132705688]  \r",
       " 57%|█████▋    | 17/30 [1:54:57&lt;1:51:36, 515.08s/trial, best loss: 1.7967373132705688]\r",
       " 60%|██████    | 18/30 [1:57:49&lt;1:22:22, 411.90s/trial, best loss: 1.7967373132705688]\r",
       " 63%|██████▎   | 19/30 [1:58:07&lt;53:51, 293.73s/trial, best loss: 1.7967373132705688]  \r",
       " 67%|██████▋   | 20/30 [1:58:35&lt;35:40, 214.02s/trial, best loss: 1.7967373132705688]\r",
       " 70%|███████   | 21/30 [2:17:28&lt;1:13:27, 489.69s/trial, best loss: 1.7967373132705688]\r",
       " 73%|███████▎  | 22/30 [2:20:48&lt;53:42, 402.83s/trial, best loss: 1.7967373132705688]  \r",
       " 77%|███████▋  | 23/30 [2:22:05&lt;35:35, 305.10s/trial, best loss: 1.7967373132705688]\r",
       " 80%|████████  | 24/30 [2:23:04&lt;23:07, 231.28s/trial, best loss: 1.7967373132705688]\r",
       " 83%|████████▎ | 25/30 [2:40:15&lt;39:15, 471.14s/trial, best loss: 1.7967373132705688]\r",
       " 87%|████████▋ | 26/30 [2:44:30&lt;27:05, 406.36s/trial, best loss: 1.7967373132705688]\r",
       " 90%|█████████ | 27/30 [2:45:27&lt;15:04, 301.57s/trial, best loss: 1.7967373132705688]\r",
       " 93%|█████████▎| 28/30 [2:46:08&lt;07:26, 223.41s/trial, best loss: 1.7967373132705688]\r",
       " 97%|█████████▋| 29/30 [3:05:02&lt;08:16, 496.56s/trial, best loss: 1.7967373132705688]\r",
       "100%|██████████| 30/30 [3:09:23&lt;00:00, 425.96s/trial, best loss: 1.7967373132705688]\r",
       "100%|██████████| 30/30 [3:09:23&lt;00:00, 378.78s/trial, best loss: 1.7967373132705688]\n",
       "Total Trials: 30: 30 succeeded, 0 failed, 0 cancelled.\n",
       "</div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "<div class=\"ansiout\">Hyperopt with SparkTrials will automatically track trials in MLflow. To view the MLflow experiment associated with the notebook, click the &#39;Runs&#39; icon in the notebook context bar on the upper right. There, you can view all runs.\nTo view logs from trials, please check the Spark executor logs. To view executor logs, expand &#39;Spark Jobs&#39; above until you see the (i) icon next to the stage from the trial job. Click it and find the list of tasks. Click the &#39;stderr&#39; link for a task to view trial logs.\n\r  0%|          | 0/30 [00:00&lt;?, ?trial/s, best loss=?]\r  3%|▎         | 1/30 [26:21&lt;12:44:17, 1581.30s/trial, best loss: 281.20147705078125]\r 10%|█         | 3/30 [26:27&lt;8:18:30, 1107.80s/trial, best loss: 106.79638671875]    \r 13%|█▎        | 4/30 [26:33&lt;5:36:54, 777.48s/trial, best loss: 25.169960021972656]\r 17%|█▋        | 5/30 [48:07&lt;6:28:29, 932.37s/trial, best loss: 25.169960021972656]\r 20%|██        | 6/30 [48:48&lt;4:25:56, 664.83s/trial, best loss: 18.75101089477539] \r 23%|██▎       | 7/30 [48:54&lt;2:59:05, 467.19s/trial, best loss: 18.75101089477539]\r 27%|██▋       | 8/30 [49:04&lt;2:01:03, 330.18s/trial, best loss: 18.75101089477539]\r 30%|███       | 9/30 [1:10:06&lt;3:33:20, 609.54s/trial, best loss: 18.75101089477539]\r 37%|███▋      | 11/30 [1:11:19&lt;2:18:35, 437.64s/trial, best loss: 1.7967373132705688]\r 40%|████      | 12/30 [1:11:33&lt;1:33:11, 310.65s/trial, best loss: 1.7967373132705688]\r 43%|████▎     | 13/30 [1:32:26&lt;2:48:07, 593.39s/trial, best loss: 1.7967373132705688]\r 47%|████▋     | 14/30 [1:35:00&lt;2:03:06, 461.63s/trial, best loss: 1.7967373132705688]\r 50%|█████     | 15/30 [1:35:03&lt;1:21:00, 324.05s/trial, best loss: 1.7967373132705688]\r 53%|█████▎    | 16/30 [1:35:24&lt;54:23, 233.14s/trial, best loss: 1.7967373132705688]  \r 57%|█████▋    | 17/30 [1:54:57&lt;1:51:36, 515.08s/trial, best loss: 1.7967373132705688]\r 60%|██████    | 18/30 [1:57:49&lt;1:22:22, 411.90s/trial, best loss: 1.7967373132705688]\r 63%|██████▎   | 19/30 [1:58:07&lt;53:51, 293.73s/trial, best loss: 1.7967373132705688]  \r 67%|██████▋   | 20/30 [1:58:35&lt;35:40, 214.02s/trial, best loss: 1.7967373132705688]\r 70%|███████   | 21/30 [2:17:28&lt;1:13:27, 489.69s/trial, best loss: 1.7967373132705688]\r 73%|███████▎  | 22/30 [2:20:48&lt;53:42, 402.83s/trial, best loss: 1.7967373132705688]  \r 77%|███████▋  | 23/30 [2:22:05&lt;35:35, 305.10s/trial, best loss: 1.7967373132705688]\r 80%|████████  | 24/30 [2:23:04&lt;23:07, 231.28s/trial, best loss: 1.7967373132705688]\r 83%|████████▎ | 25/30 [2:40:15&lt;39:15, 471.14s/trial, best loss: 1.7967373132705688]\r 87%|████████▋ | 26/30 [2:44:30&lt;27:05, 406.36s/trial, best loss: 1.7967373132705688]\r 90%|█████████ | 27/30 [2:45:27&lt;15:04, 301.57s/trial, best loss: 1.7967373132705688]\r 93%|█████████▎| 28/30 [2:46:08&lt;07:26, 223.41s/trial, best loss: 1.7967373132705688]\r 97%|█████████▋| 29/30 [3:05:02&lt;08:16, 496.56s/trial, best loss: 1.7967373132705688]\r100%|██████████| 30/30 [3:09:23&lt;00:00, 425.96s/trial, best loss: 1.7967373132705688]\r100%|██████████| 30/30 [3:09:23&lt;00:00, 378.78s/trial, best loss: 1.7967373132705688]\nTotal Trials: 30: 30 succeeded, 0 failed, 0 cancelled.\n</div>",
       "datasetInfos": [],
       "removedWidgets": [],
       "type": "html"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "mlflow.end_run()\n",
    "\n",
    "with mlflow.start_run():\n",
    "    best_hyperparam = fmin(fn=runNN, \n",
    "                         space=space, \n",
    "                         algo=tpe.suggest, \n",
    "                         max_evals=30, \n",
    "                         trials=spark_trials)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading new model\n",
      "\n",
      "Model: \"functional_7\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_4 (InputLayer)            [(None, 299, 299, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv1 (Conv2D)           (None, 149, 149, 32) 864         input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv1_bn (BatchNormaliza (None, 149, 149, 32) 128         block1_conv1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv1_act (Activation)   (None, 149, 149, 32) 0           block1_conv1_bn[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv2 (Conv2D)           (None, 147, 147, 64) 18432       block1_conv1_act[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv2_bn (BatchNormaliza (None, 147, 147, 64) 256         block1_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv2_act (Activation)   (None, 147, 147, 64) 0           block1_conv2_bn[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block2_sepconv1 (SeparableConv2 (None, 147, 147, 128 8768        block1_conv2_act[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block2_sepconv1_bn (BatchNormal (None, 147, 147, 128 512         block2_sepconv1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block2_sepconv2_act (Activation (None, 147, 147, 128 0           block2_sepconv1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block2_sepconv2 (SeparableConv2 (None, 147, 147, 128 17536       block2_sepconv2_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block2_sepconv2_bn (BatchNormal (None, 147, 147, 128 512         block2_sepconv2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_12 (Conv2D)              (None, 74, 74, 128)  8192        block1_conv2_act[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block2_pool (MaxPooling2D)      (None, 74, 74, 128)  0           block2_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_12 (BatchNo (None, 74, 74, 128)  512         conv2d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_36 (Add)                    (None, 74, 74, 128)  0           block2_pool[0][0]                \n",
      "                                                                 batch_normalization_12[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block3_sepconv1_act (Activation (None, 74, 74, 128)  0           add_36[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block3_sepconv1 (SeparableConv2 (None, 74, 74, 256)  33920       block3_sepconv1_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block3_sepconv1_bn (BatchNormal (None, 74, 74, 256)  1024        block3_sepconv1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block3_sepconv2_act (Activation (None, 74, 74, 256)  0           block3_sepconv1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block3_sepconv2 (SeparableConv2 (None, 74, 74, 256)  67840       block3_sepconv2_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block3_sepconv2_bn (BatchNormal (None, 74, 74, 256)  1024        block3_sepconv2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_13 (Conv2D)              (None, 37, 37, 256)  32768       add_36[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block3_pool (MaxPooling2D)      (None, 37, 37, 256)  0           block3_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_13 (BatchNo (None, 37, 37, 256)  1024        conv2d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_37 (Add)                    (None, 37, 37, 256)  0           block3_pool[0][0]                \n",
      "                                                                 batch_normalization_13[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block4_sepconv1_act (Activation (None, 37, 37, 256)  0           add_37[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block4_sepconv1 (SeparableConv2 (None, 37, 37, 728)  188672      block4_sepconv1_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block4_sepconv1_bn (BatchNormal (None, 37, 37, 728)  2912        block4_sepconv1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block4_sepconv2_act (Activation (None, 37, 37, 728)  0           block4_sepconv1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4_sepconv2 (SeparableConv2 (None, 37, 37, 728)  536536      block4_sepconv2_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block4_sepconv2_bn (BatchNormal (None, 37, 37, 728)  2912        block4_sepconv2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_14 (Conv2D)              (None, 19, 19, 728)  186368      add_37[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block4_pool (MaxPooling2D)      (None, 19, 19, 728)  0           block4_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_14 (BatchNo (None, 19, 19, 728)  2912        conv2d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_38 (Add)                    (None, 19, 19, 728)  0           block4_pool[0][0]                \n",
      "                                                                 batch_normalization_14[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv1_act (Activation (None, 19, 19, 728)  0           add_38[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv1 (SeparableConv2 (None, 19, 19, 728)  536536      block5_sepconv1_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv1_bn (BatchNormal (None, 19, 19, 728)  2912        block5_sepconv1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv2_act (Activation (None, 19, 19, 728)  0           block5_sepconv1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv2 (SeparableConv2 (None, 19, 19, 728)  536536      block5_sepconv2_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv2_bn (BatchNormal (None, 19, 19, 728)  2912        block5_sepconv2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv3_act (Activation (None, 19, 19, 728)  0           block5_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv3 (SeparableConv2 (None, 19, 19, 728)  536536      block5_sepconv3_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv3_bn (BatchNormal (None, 19, 19, 728)  2912        block5_sepconv3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_39 (Add)                    (None, 19, 19, 728)  0           block5_sepconv3_bn[0][0]         \n",
      "                                                                 add_38[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv1_act (Activation (None, 19, 19, 728)  0           add_39[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv1 (SeparableConv2 (None, 19, 19, 728)  536536      block6_sepconv1_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv1_bn (BatchNormal (None, 19, 19, 728)  2912        block6_sepconv1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv2_act (Activation (None, 19, 19, 728)  0           block6_sepconv1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv2 (SeparableConv2 (None, 19, 19, 728)  536536      block6_sepconv2_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv2_bn (BatchNormal (None, 19, 19, 728)  2912        block6_sepconv2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv3_act (Activation (None, 19, 19, 728)  0           block6_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv3 (SeparableConv2 (None, 19, 19, 728)  536536      block6_sepconv3_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv3_bn (BatchNormal (None, 19, 19, 728)  2912        block6_sepconv3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_40 (Add)                    (None, 19, 19, 728)  0           block6_sepconv3_bn[0][0]         \n",
      "                                                                 add_39[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv1_act (Activation (None, 19, 19, 728)  0           add_40[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv1 (SeparableConv2 (None, 19, 19, 728)  536536      block7_sepconv1_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv1_bn (BatchNormal (None, 19, 19, 728)  2912        block7_sepconv1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv2_act (Activation (None, 19, 19, 728)  0           block7_sepconv1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv2 (SeparableConv2 (None, 19, 19, 728)  536536      block7_sepconv2_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv2_bn (BatchNormal (None, 19, 19, 728)  2912        block7_sepconv2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv3_act (Activation (None, 19, 19, 728)  0           block7_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv3 (SeparableConv2 (None, 19, 19, 728)  536536      block7_sepconv3_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv3_bn (BatchNormal (None, 19, 19, 728)  2912        block7_sepconv3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_41 (Add)                    (None, 19, 19, 728)  0           block7_sepconv3_bn[0][0]         \n",
      "                                                                 add_40[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv1_act (Activation (None, 19, 19, 728)  0           add_41[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv1 (SeparableConv2 (None, 19, 19, 728)  536536      block8_sepconv1_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv1_bn (BatchNormal (None, 19, 19, 728)  2912        block8_sepconv1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv2_act (Activation (None, 19, 19, 728)  0           block8_sepconv1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv2 (SeparableConv2 (None, 19, 19, 728)  536536      block8_sepconv2_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv2_bn (BatchNormal (None, 19, 19, 728)  2912        block8_sepconv2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv3_act (Activation (None, 19, 19, 728)  0           block8_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv3 (SeparableConv2 (None, 19, 19, 728)  536536      block8_sepconv3_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv3_bn (BatchNormal (None, 19, 19, 728)  2912        block8_sepconv3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_42 (Add)                    (None, 19, 19, 728)  0           block8_sepconv3_bn[0][0]         \n",
      "                                                                 add_41[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv1_act (Activation (None, 19, 19, 728)  0           add_42[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv1 (SeparableConv2 (None, 19, 19, 728)  536536      block9_sepconv1_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv1_bn (BatchNormal (None, 19, 19, 728)  2912        block9_sepconv1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv2_act (Activation (None, 19, 19, 728)  0           block9_sepconv1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv2 (SeparableConv2 (None, 19, 19, 728)  536536      block9_sepconv2_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv2_bn (BatchNormal (None, 19, 19, 728)  2912        block9_sepconv2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv3_act (Activation (None, 19, 19, 728)  0           block9_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv3 (SeparableConv2 (None, 19, 19, 728)  536536      block9_sepconv3_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv3_bn (BatchNormal (None, 19, 19, 728)  2912        block9_sepconv3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_43 (Add)                    (None, 19, 19, 728)  0           block9_sepconv3_bn[0][0]         \n",
      "                                                                 add_42[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv1_act (Activatio (None, 19, 19, 728)  0           add_43[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv1 (SeparableConv (None, 19, 19, 728)  536536      block10_sepconv1_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv1_bn (BatchNorma (None, 19, 19, 728)  2912        block10_sepconv1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv2_act (Activatio (None, 19, 19, 728)  0           block10_sepconv1_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv2 (SeparableConv (None, 19, 19, 728)  536536      block10_sepconv2_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv2_bn (BatchNorma (None, 19, 19, 728)  2912        block10_sepconv2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv3_act (Activatio (None, 19, 19, 728)  0           block10_sepconv2_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv3 (SeparableConv (None, 19, 19, 728)  536536      block10_sepconv3_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv3_bn (BatchNorma (None, 19, 19, 728)  2912        block10_sepconv3[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "add_44 (Add)                    (None, 19, 19, 728)  0           block10_sepconv3_bn[0][0]        \n",
      "                                                                 add_43[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv1_act (Activatio (None, 19, 19, 728)  0           add_44[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv1 (SeparableConv (None, 19, 19, 728)  536536      block11_sepconv1_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv1_bn (BatchNorma (None, 19, 19, 728)  2912        block11_sepconv1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv2_act (Activatio (None, 19, 19, 728)  0           block11_sepconv1_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv2 (SeparableConv (None, 19, 19, 728)  536536      block11_sepconv2_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv2_bn (BatchNorma (None, 19, 19, 728)  2912        block11_sepconv2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv3_act (Activatio (None, 19, 19, 728)  0           block11_sepconv2_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv3 (SeparableConv (None, 19, 19, 728)  536536      block11_sepconv3_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv3_bn (BatchNorma (None, 19, 19, 728)  2912        block11_sepconv3[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "add_45 (Add)                    (None, 19, 19, 728)  0           block11_sepconv3_bn[0][0]        \n",
      "                                                                 add_44[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv1_act (Activatio (None, 19, 19, 728)  0           add_45[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv1 (SeparableConv (None, 19, 19, 728)  536536      block12_sepconv1_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv1_bn (BatchNorma (None, 19, 19, 728)  2912        block12_sepconv1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv2_act (Activatio (None, 19, 19, 728)  0           block12_sepconv1_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv2 (SeparableConv (None, 19, 19, 728)  536536      block12_sepconv2_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv2_bn (BatchNorma (None, 19, 19, 728)  2912        block12_sepconv2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv3_act (Activatio (None, 19, 19, 728)  0           block12_sepconv2_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv3 (SeparableConv (None, 19, 19, 728)  536536      block12_sepconv3_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv3_bn (BatchNorma (None, 19, 19, 728)  2912        block12_sepconv3[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "add_46 (Add)                    (None, 19, 19, 728)  0           block12_sepconv3_bn[0][0]        \n",
      "                                                                 add_45[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block13_sepconv1_act (Activatio (None, 19, 19, 728)  0           add_46[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block13_sepconv1 (SeparableConv (None, 19, 19, 728)  536536      block13_sepconv1_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block13_sepconv1_bn (BatchNorma (None, 19, 19, 728)  2912        block13_sepconv1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block13_sepconv2_act (Activatio (None, 19, 19, 728)  0           block13_sepconv1_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block13_sepconv2 (SeparableConv (None, 19, 19, 1024) 752024      block13_sepconv2_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block13_sepconv2_bn (BatchNorma (None, 19, 19, 1024) 4096        block13_sepconv2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_15 (Conv2D)              (None, 10, 10, 1024) 745472      add_46[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block13_pool (MaxPooling2D)     (None, 10, 10, 1024) 0           block13_sepconv2_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_15 (BatchNo (None, 10, 10, 1024) 4096        conv2d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_47 (Add)                    (None, 10, 10, 1024) 0           block13_pool[0][0]               \n",
      "                                                                 batch_normalization_15[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block14_sepconv1 (SeparableConv (None, 10, 10, 1536) 1582080     add_47[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block14_sepconv1_bn (BatchNorma (None, 10, 10, 1536) 6144        block14_sepconv1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block14_sepconv1_act (Activatio (None, 10, 10, 1536) 0           block14_sepconv1_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block14_sepconv2 (SeparableConv (None, 10, 10, 2048) 3159552     block14_sepconv1_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block14_sepconv2_bn (BatchNorma (None, 10, 10, 2048) 8192        block14_sepconv2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block14_sepconv2_act (Activatio (None, 10, 10, 2048) 0           block14_sepconv2_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d_3 (Glo (None, 2048)         0           block14_sepconv2_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (None, 2048)         0           global_average_pooling2d_3[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "classLabels (Dense)             (None, 1)            2049        dropout_3[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 20,863,529\n",
      "Trainable params: 2,049\n",
      "Non-trainable params: 20,861,480\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021/02/28 21:03:16 INFO mlflow.utils.autologging_utils: Created MLflow autologging run with ID '58baf244ed33492f904600a6beb92075', which will track hyperparameters, performance metrics, model artifacts, and lineage information for the current tensorflow workflow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 2.15134, saving model to ../data/keras_checkpoint_weights.ckpt\n",
      "INFO:tensorflow:Assets written to: ../data/keras_checkpoint_weights.ckpt/assets\n",
      "Epoch 2/4\n",
      "\n",
      "Epoch 00002: val_loss improved from 2.15134 to 1.53903, saving model to ../data/keras_checkpoint_weights.ckpt\n",
      "INFO:tensorflow:Assets written to: ../data/keras_checkpoint_weights.ckpt/assets\n",
      "Epoch 3/4\n",
      "\n",
      "Epoch 00003: val_loss improved from 1.53903 to 1.43144, saving model to ../data/keras_checkpoint_weights.ckpt\n",
      "INFO:tensorflow:Assets written to: ../data/keras_checkpoint_weights.ckpt/assets\n",
      "Epoch 4/4\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 1.43144\n",
      "INFO:tensorflow:Assets written to: /var/folders/x4/lln_2cf520d7_dbpv40m1jx40000gq/T/tmpslk26gyu/model/data/model/assets\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'loss': 2.769727945327759,\n",
       " 'status': 'ok',\n",
       " 'model': <tensorflow.python.keras.engine.functional.Functional at 0x7fbf75c0a350>}"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n = {'batch_size': 4, 'dropout_rate': 0.0, 'epochs': 4, 'learning_rate': 0.001037950994714726, 'momentum': 0.4, 'optimizer': 'Adam'}\n",
    "model = runNN(n)\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "a03ff1b1-7b91-48d4-94e4-b167233fa33a",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Part 3. Use the best set of hyperparameters to build a final model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "49e3aac2-74f6-4135-816e-e23191fc0b5a",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\">{&#39;batch_size&#39;: 4, &#39;dropout_rate&#39;: 0.0, &#39;epochs&#39;: 1, &#39;learning_rate&#39;: 0.001037950994714726, &#39;momentum&#39;: 0.4, &#39;optimizer&#39;: &#39;Adam&#39;}\n",
       "</div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "<div class=\"ansiout\">{&#39;batch_size&#39;: 4, &#39;dropout_rate&#39;: 0.0, &#39;epochs&#39;: 1, &#39;learning_rate&#39;: 0.001037950994714726, &#39;momentum&#39;: 0.4, &#39;optimizer&#39;: &#39;Adam&#39;}\n</div>",
       "datasetInfos": [],
       "removedWidgets": [],
       "type": "html"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import hyperopt\n",
    "print(hyperopt.space_eval(space, best_hyperparam))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "0fe41a31-1f1e-4688-b8e9-1113dbccbd31",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\"></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "<div class=\"ansiout\"></div>",
       "datasetInfos": [],
       "removedWidgets": [],
       "type": "html"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "dropout_rate = hyperopt.space_eval(space, best_hyperparam)[\"dropout_rate\"]\n",
    "batch_size = hyperopt.space_eval(space, best_hyperparam)[\"batch_size\"]\n",
    "epochs = hyperopt.space_eval(space, best_hyperparam)[\"epochs\"]\n",
    "momentum = hyperopt.space_eval(space, best_hyperparam)[\"momentum\"]\n",
    "learning_rate = hyperopt.space_eval(space, best_hyperparam)[\"learning_rate\"]\n",
    "optimizer = hyperopt.space_eval(space, best_hyperparam)[\"optimizer\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "e633e5cd-0b76-4d68-9e2d-c1c035664104",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\"></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "<div class=\"ansiout\"></div>",
       "datasetInfos": [],
       "removedWidgets": [],
       "type": "html"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Get optimizer and update with learning_rate value\n",
    "optimizer_call = getattr(tf.keras.optimizers, optimizer)\n",
    "optimizer = optimizer_call(learning_rate=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "a9892938-6494-4af3-845e-5eb3e5281569",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\"></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "<div class=\"ansiout\"></div>",
       "datasetInfos": [],
       "removedWidgets": [],
       "type": "html"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def create_new_model():\n",
    "    # Function to create model\n",
    "    # def create_model(learn_rate=1e-1, momentum=0.9, dropout_rate=0.0):\n",
    "    sys.stdout.write('Loading new model\\n\\n')\n",
    "    sys.stdout.flush()\n",
    "    base_model = Xception(input_shape=input_shape, \n",
    "                        include_top=False, \n",
    "                        pooling='avg', \n",
    "                        weights='imagenet')\n",
    "\n",
    "    for layer in base_model.layers:\n",
    "        layer.trainable = False\n",
    "\n",
    "    x2 = Dropout(dropout_rate)(base_model.layers[-1].output)\n",
    "    x = Dense(1, activation='linear', name='classLabels')(x2)\n",
    "    model = Model(base_model.input, x)\n",
    "    model.summary()\n",
    "\n",
    "    # Save model\n",
    "    with open(model_path, 'w') as outfile:\n",
    "        json.dump(model.to_json(), outfile)\n",
    "        outfile.close()\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "77716157-6084-4147-bd0c-bc58c3877fa5",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\">Loading new model\n",
       "\n",
       "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/xception/xception_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
       "\r",
       "    8192/83683744 [..............................] - ETA: 1s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
       " 4202496/83683744 [&gt;.............................] - ETA: 2s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
       "16244736/83683744 [====&gt;.........................] - ETA: 0s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
       "27279360/83683744 [========&gt;.....................] - ETA: 0s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
       "33562624/83683744 [===========&gt;..................] - ETA: 0s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
       "44023808/83683744 [==============&gt;...............] - ETA: 0s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
       "54984704/83683744 [==================&gt;...........] - ETA: 0s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
       "65994752/83683744 [======================&gt;.......] - ETA: 0s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
       "76095488/83683744 [==========================&gt;...] - ETA: 0s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
       "83689472/83683744 [==============================] - 1s 0us/step\n",
       "Model: &#34;functional_1&#34;\n",
       "__________________________________________________________________________________________________\n",
       "Layer (type)                    Output Shape         Param #     Connected to                     \n",
       "==================================================================================================\n",
       "input_1 (InputLayer)            [(None, 299, 299, 3) 0                                            \n",
       "__________________________________________________________________________________________________\n",
       "block1_conv1 (Conv2D)           (None, 149, 149, 32) 864         input_1[0][0]                    \n",
       "__________________________________________________________________________________________________\n",
       "block1_conv1_bn (BatchNormaliza (None, 149, 149, 32) 128         block1_conv1[0][0]               \n",
       "__________________________________________________________________________________________________\n",
       "block1_conv1_act (Activation)   (None, 149, 149, 32) 0           block1_conv1_bn[0][0]            \n",
       "__________________________________________________________________________________________________\n",
       "block1_conv2 (Conv2D)           (None, 147, 147, 64) 18432       block1_conv1_act[0][0]           \n",
       "__________________________________________________________________________________________________\n",
       "block1_conv2_bn (BatchNormaliza (None, 147, 147, 64) 256         block1_conv2[0][0]               \n",
       "__________________________________________________________________________________________________\n",
       "block1_conv2_act (Activation)   (None, 147, 147, 64) 0           block1_conv2_bn[0][0]            \n",
       "__________________________________________________________________________________________________\n",
       "block2_sepconv1 (SeparableConv2 (None, 147, 147, 128 8768        block1_conv2_act[0][0]           \n",
       "__________________________________________________________________________________________________\n",
       "block2_sepconv1_bn (BatchNormal (None, 147, 147, 128 512         block2_sepconv1[0][0]            \n",
       "__________________________________________________________________________________________________\n",
       "block2_sepconv2_act (Activation (None, 147, 147, 128 0           block2_sepconv1_bn[0][0]         \n",
       "__________________________________________________________________________________________________\n",
       "block2_sepconv2 (SeparableConv2 (None, 147, 147, 128 17536       block2_sepconv2_act[0][0]        \n",
       "__________________________________________________________________________________________________\n",
       "block2_sepconv2_bn (BatchNormal (None, 147, 147, 128 512         block2_sepconv2[0][0]            \n",
       "__________________________________________________________________________________________________\n",
       "conv2d (Conv2D)                 (None, 74, 74, 128)  8192        block1_conv2_act[0][0]           \n",
       "__________________________________________________________________________________________________\n",
       "block2_pool (MaxPooling2D)      (None, 74, 74, 128)  0           block2_sepconv2_bn[0][0]         \n",
       "__________________________________________________________________________________________________\n",
       "batch_normalization (BatchNorma (None, 74, 74, 128)  512         conv2d[0][0]                     \n",
       "__________________________________________________________________________________________________\n",
       "add (Add)                       (None, 74, 74, 128)  0           block2_pool[0][0]                \n",
       "                                                                 batch_normalization[0][0]        \n",
       "__________________________________________________________________________________________________\n",
       "block3_sepconv1_act (Activation (None, 74, 74, 128)  0           add[0][0]                        \n",
       "__________________________________________________________________________________________________\n",
       "block3_sepconv1 (SeparableConv2 (None, 74, 74, 256)  33920       block3_sepconv1_act[0][0]        \n",
       "__________________________________________________________________________________________________\n",
       "block3_sepconv1_bn (BatchNormal (None, 74, 74, 256)  1024        block3_sepconv1[0][0]            \n",
       "__________________________________________________________________________________________________\n",
       "block3_sepconv2_act (Activation (None, 74, 74, 256)  0           block3_sepconv1_bn[0][0]         \n",
       "__________________________________________________________________________________________________\n",
       "block3_sepconv2 (SeparableConv2 (None, 74, 74, 256)  67840       block3_sepconv2_act[0][0]        \n",
       "__________________________________________________________________________________________________\n",
       "block3_sepconv2_bn (BatchNormal (None, 74, 74, 256)  1024        block3_sepconv2[0][0]            \n",
       "__________________________________________________________________________________________________\n",
       "conv2d_1 (Conv2D)               (None, 37, 37, 256)  32768       add[0][0]                        \n",
       "__________________________________________________________________________________________________\n",
       "block3_pool (MaxPooling2D)      (None, 37, 37, 256)  0           block3_sepconv2_bn[0][0]         \n",
       "__________________________________________________________________________________________________\n",
       "batch_normalization_1 (BatchNor (None, 37, 37, 256)  1024        conv2d_1[0][0]                   \n",
       "__________________________________________________________________________________________________\n",
       "add_1 (Add)                     (None, 37, 37, 256)  0           block3_pool[0][0]                \n",
       "                                                                 batch_normalization_1[0][0]      \n",
       "__________________________________________________________________________________________________\n",
       "block4_sepconv1_act (Activation (None, 37, 37, 256)  0           add_1[0][0]                      \n",
       "__________________________________________________________________________________________________\n",
       "block4_sepconv1 (SeparableConv2 (None, 37, 37, 728)  188672      block4_sepconv1_act[0][0]        \n",
       "__________________________________________________________________________________________________\n",
       "block4_sepconv1_bn (BatchNormal (None, 37, 37, 728)  2912        block4_sepconv1[0][0]            \n",
       "__________________________________________________________________________________________________\n",
       "block4_sepconv2_act (Activation (None, 37, 37, 728)  0           block4_sepconv1_bn[0][0]         \n",
       "__________________________________________________________________________________________________\n",
       "block4_sepconv2 (SeparableConv2 (None, 37, 37, 728)  536536      block4_sepconv2_act[0][0]        \n",
       "__________________________________________________________________________________________________\n",
       "block4_sepconv2_bn (BatchNormal (None, 37, 37, 728)  2912        block4_sepconv2[0][0]            \n",
       "__________________________________________________________________________________________________\n",
       "conv2d_2 (Conv2D)               (None, 19, 19, 728)  186368      add_1[0][0]                      \n",
       "__________________________________________________________________________________________________\n",
       "block4_pool (MaxPooling2D)      (None, 19, 19, 728)  0           block4_sepconv2_bn[0][0]         \n",
       "__________________________________________________________________________________________________\n",
       "batch_normalization_2 (BatchNor (None, 19, 19, 728)  2912        conv2d_2[0][0]                   \n",
       "__________________________________________________________________________________________________\n",
       "add_2 (Add)                     (None, 19, 19, 728)  0           block4_pool[0][0]                \n",
       "                                                                 batch_normalization_2[0][0]      \n",
       "__________________________________________________________________________________________________\n",
       "block5_sepconv1_act (Activation (None, 19, 19, 728)  0           add_2[0][0]                      \n",
       "__________________________________________________________________________________________________\n",
       "block5_sepconv1 (SeparableConv2 (None, 19, 19, 728)  536536      block5_sepconv1_act[0][0]        \n",
       "__________________________________________________________________________________________________\n",
       "block5_sepconv1_bn (BatchNormal (None, 19, 19, 728)  2912        block5_sepconv1[0][0]            \n",
       "__________________________________________________________________________________________________\n",
       "block5_sepconv2_act (Activation (None, 19, 19, 728)  0           block5_sepconv1_bn[0][0]         \n",
       "__________________________________________________________________________________________________\n",
       "block5_sepconv2 (SeparableConv2 (None, 19, 19, 728)  536536      block5_sepconv2_act[0][0]        \n",
       "__________________________________________________________________________________________________\n",
       "block5_sepconv2_bn (BatchNormal (None, 19, 19, 728)  2912        block5_sepconv2[0][0]            \n",
       "__________________________________________________________________________________________________\n",
       "block5_sepconv3_act (Activation (None, 19, 19, 728)  0           block5_sepconv2_bn[0][0]         \n",
       "__________________________________________________________________________________________________\n",
       "block5_sepconv3 (SeparableConv2 (None, 19, 19, 728)  536536      block5_sepconv3_act[0][0]        \n",
       "__________________________________________________________________________________________________\n",
       "block5_sepconv3_bn (BatchNormal (None, 19, 19, 728)  2912        block5_sepconv3[0][0]            \n",
       "__________________________________________________________________________________________________\n",
       "add_3 (Add)                     (None, 19, 19, 728)  0           block5_sepconv3_bn[0][0]         \n",
       "                                                                 add_2[0][0]                      \n",
       "__________________________________________________________________________________________________\n",
       "block6_sepconv1_act (Activation (None, 19, 19, 728)  0           add_3[0][0]                      \n",
       "__________________________________________________________________________________________________\n",
       "block6_sepconv1 (SeparableConv2 (None, 19, 19, 728)  536536      block6_sepconv1_act[0][0]        \n",
       "__________________________________________________________________________________________________\n",
       "block6_sepconv1_bn (BatchNormal (None, 19, 19, 728)  2912        block6_sepconv1[0][0]            \n",
       "__________________________________________________________________________________________________\n",
       "block6_sepconv2_act (Activation (None, 19, 19, 728)  0           block6_sepconv1_bn[0][0]         \n",
       "__________________________________________________________________________________________________\n",
       "block6_sepconv2 (SeparableConv2 (None, 19, 19, 728)  536536      block6_sepconv2_act[0][0]        \n",
       "__________________________________________________________________________________________________\n",
       "block6_sepconv2_bn (BatchNormal (None, 19, 19, 728)  2912        block6_sepconv2[0][0]            \n",
       "__________________________________________________________________________________________________\n",
       "block6_sepconv3_act (Activation (None, 19, 19, 728)  0           block6_sepconv2_bn[0][0]         \n",
       "__________________________________________________________________________________________________\n",
       "block6_sepconv3 (SeparableConv2 (None, 19, 19, 728)  536536      block6_sepconv3_act[0][0]        \n",
       "__________________________________________________________________________________________________\n",
       "block6_sepconv3_bn (BatchNormal (None, 19, 19, 728)  2912        block6_sepconv3[0][0]            \n",
       "__________________________________________________________________________________________________\n",
       "add_4 (Add)                     (None, 19, 19, 728)  0           block6_sepconv3_bn[0][0]         \n",
       "                                                                 add_3[0][0]                      \n",
       "__________________________________________________________________________________________________\n",
       "block7_sepconv1_act (Activation (None, 19, 19, 728)  0           add_4[0][0]                      \n",
       "__________________________________________________________________________________________________\n",
       "block7_sepconv1 (SeparableConv2 (None, 19, 19, 728)  536536      block7_sepconv1_act[0][0]        \n",
       "__________________________________________________________________________________________________\n",
       "block7_sepconv1_bn (BatchNormal (None, 19, 19, 728)  2912        block7_sepconv1[0][0]            \n",
       "__________________________________________________________________________________________________\n",
       "block7_sepconv2_act (Activation (None, 19, 19, 728)  0           block7_sepconv1_bn[0][0]         \n",
       "__________________________________________________________________________________________________\n",
       "block7_sepconv2 (SeparableConv2 (None, 19, 19, 728)  536536      block7_sepconv2_act[0][0]        \n",
       "__________________________________________________________________________________________________\n",
       "block7_sepconv2_bn (BatchNormal (None, 19, 19, 728)  2912        block7_sepconv2[0][0]            \n",
       "__________________________________________________________________________________________________\n",
       "block7_sepconv3_act (Activation (None, 19, 19, 728)  0           block7_sepconv2_bn[0][0]         \n",
       "__________________________________________________________________________________________________\n",
       "block7_sepconv3 (SeparableConv2 (None, 19, 19, 728)  536536      block7_sepconv3_act[0][0]        \n",
       "__________________________________________________________________________________________________\n",
       "block7_sepconv3_bn (BatchNormal (None, 19, 19, 728)  2912        block7_sepconv3[0][0]            \n",
       "__________________________________________________________________________________________________\n",
       "add_5 (Add)                     (None, 19, 19, 728)  0           block7_sepconv3_bn[0][0]         \n",
       "                                                                 add_4[0][0]                      \n",
       "__________________________________________________________________________________________________\n",
       "block8_sepconv1_act (Activation (None, 19, 19, 728)  0           add_5[0][0]                      \n",
       "__________________________________________________________________________________________________\n",
       "block8_sepconv1 (SeparableConv2 (None, 19, 19, 728)  536536      block8_sepconv1_act[0][0]        \n",
       "__________________________________________________________________________________________________\n",
       "block8_sepconv1_bn (BatchNormal (None, 19, 19, 728)  2912        block8_sepconv1[0][0]            \n",
       "__________________________________________________________________________________________________\n",
       "block8_sepconv2_act (Activation (None, 19, 19, 728)  0           block8_sepconv1_bn[0][0]         \n",
       "__________________________________________________________________________________________________\n",
       "block8_sepconv2 (SeparableConv2 (None, 19, 19, 728)  536536      block8_sepconv2_act[0][0]        \n",
       "__________________________________________________________________________________________________\n",
       "block8_sepconv2_bn (BatchNormal (None, 19, 19, 728)  2912        block8_sepconv2[0][0]            \n",
       "__________________________________________________________________________________________________\n",
       "block8_sepconv3_act (Activation (None, 19, 19, 728)  0           block8_sepconv2_bn[0][0]         \n",
       "__________________________________________________________________________________________________\n",
       "block8_sepconv3 (SeparableConv2 (None, 19, 19, 728)  536536      block8_sepconv3_act[0][0]        \n",
       "__________________________________________________________________________________________________\n",
       "block8_sepconv3_bn (BatchNormal (None, 19, 19, 728)  2912        block8_sepconv3[0][0]            \n",
       "__________________________________________________________________________________________________\n",
       "add_6 (Add)                     (None, 19, 19, 728)  0           block8_sepconv3_bn[0][0]         \n",
       "                                                                 add_5[0][0]                      \n",
       "__________________________________________________________________________________________________\n",
       "block9_sepconv1_act (Activation (None, 19, 19, 728)  0           add_6[0][0]                      \n",
       "__________________________________________________________________________________________________\n",
       "block9_sepconv1 (SeparableConv2 (None, 19, 19, 728)  536536      block9_sepconv1_act[0][0]        \n",
       "__________________________________________________________________________________________________\n",
       "block9_sepconv1_bn (BatchNormal (None, 19, 19, 728)  2912        block9_sepconv1[0][0]            \n",
       "__________________________________________________________________________________________________\n",
       "block9_sepconv2_act (Activation (None, 19, 19, 728)  0           block9_sepconv1_bn[0][0]         \n",
       "__________________________________________________________________________________________________\n",
       "block9_sepconv2 (SeparableConv2 (None, 19, 19, 728)  536536      block9_sepconv2_act[0][0]        \n",
       "__________________________________________________________________________________________________\n",
       "block9_sepconv2_bn (BatchNormal (None, 19, 19, 728)  2912        block9_sepconv2[0][0]            \n",
       "__________________________________________________________________________________________________\n",
       "block9_sepconv3_act (Activation (None, 19, 19, 728)  0           block9_sepconv2_bn[0][0]         \n",
       "__________________________________________________________________________________________________\n",
       "block9_sepconv3 (SeparableConv2 (None, 19, 19, 728)  536536      block9_sepconv3_act[0][0]        \n",
       "__________________________________________________________________________________________________\n",
       "block9_sepconv3_bn (BatchNormal (None, 19, 19, 728)  2912        block9_sepconv3[0][0]            \n",
       "__________________________________________________________________________________________________\n",
       "add_7 (Add)                     (None, 19, 19, 728)  0           block9_sepconv3_bn[0][0]         \n",
       "                                                                 add_6[0][0]                      \n",
       "__________________________________________________________________________________________________\n",
       "block10_sepconv1_act (Activatio (None, 19, 19, 728)  0           add_7[0][0]                      \n",
       "__________________________________________________________________________________________________\n",
       "block10_sepconv1 (SeparableConv (None, 19, 19, 728)  536536      block10_sepconv1_act[0][0]       \n",
       "__________________________________________________________________________________________________\n",
       "block10_sepconv1_bn (BatchNorma (None, 19, 19, 728)  2912        block10_sepconv1[0][0]           \n",
       "__________________________________________________________________________________________________\n",
       "block10_sepconv2_act (Activatio (None, 19, 19, 728)  0           block10_sepconv1_bn[0][0]        \n",
       "__________________________________________________________________________________________________\n",
       "block10_sepconv2 (SeparableConv (None, 19, 19, 728)  536536      block10_sepconv2_act[0][0]       \n",
       "__________________________________________________________________________________________________\n",
       "block10_sepconv2_bn (BatchNorma (None, 19, 19, 728)  2912        block10_sepconv2[0][0]           \n",
       "__________________________________________________________________________________________________\n",
       "block10_sepconv3_act (Activatio (None, 19, 19, 728)  0           block10_sepconv2_bn[0][0]        \n",
       "__________________________________________________________________________________________________\n",
       "block10_sepconv3 (SeparableConv (None, 19, 19, 728)  536536      block10_sepconv3_act[0][0]       \n",
       "__________________________________________________________________________________________________\n",
       "block10_sepconv3_bn (BatchNorma (None, 19, 19, 728)  2912        block10_sepconv3[0][0]           \n",
       "__________________________________________________________________________________________________\n",
       "add_8 (Add)                     (None, 19, 19, 728)  0           block10_sepconv3_bn[0][0]        \n",
       "                                                                 add_7[0][0]                      \n",
       "__________________________________________________________________________________________________\n",
       "block11_sepconv1_act (Activatio (None, 19, 19, 728)  0           add_8[0][0]                      \n",
       "__________________________________________________________________________________________________\n",
       "block11_sepconv1 (SeparableConv (None, 19, 19, 728)  536536      block11_sepconv1_act[0][0]       \n",
       "__________________________________________________________________________________________________\n",
       "block11_sepconv1_bn (BatchNorma (None, 19, 19, 728)  2912        block11_sepconv1[0][0]           \n",
       "__________________________________________________________________________________________________\n",
       "block11_sepconv2_act (Activatio (None, 19, 19, 728)  0           block11_sepconv1_bn[0][0]        \n",
       "__________________________________________________________________________________________________\n",
       "block11_sepconv2 (SeparableConv (None, 19, 19, 728)  536536      block11_sepconv2_act[0][0]       \n",
       "__________________________________________________________________________________________________\n",
       "block11_sepconv2_bn (BatchNorma (None, 19, 19, 728)  2912        block11_sepconv2[0][0]           \n",
       "__________________________________________________________________________________________________\n",
       "block11_sepconv3_act (Activatio (None, 19, 19, 728)  0           block11_sepconv2_bn[0][0]        \n",
       "__________________________________________________________________________________________________\n",
       "block11_sepconv3 (SeparableConv (None, 19, 19, 728)  536536      block11_sepconv3_act[0][0]       \n",
       "__________________________________________________________________________________________________\n",
       "block11_sepconv3_bn (BatchNorma (None, 19, 19, 728)  2912        block11_sepconv3[0][0]           \n",
       "__________________________________________________________________________________________________\n",
       "add_9 (Add)                     (None, 19, 19, 728)  0           block11_sepconv3_bn[0][0]        \n",
       "                                                                 add_8[0][0]                      \n",
       "__________________________________________________________________________________________________\n",
       "block12_sepconv1_act (Activatio (None, 19, 19, 728)  0           add_9[0][0]                      \n",
       "__________________________________________________________________________________________________\n",
       "block12_sepconv1 (SeparableConv (None, 19, 19, 728)  536536      block12_sepconv1_act[0][0]       \n",
       "__________________________________________________________________________________________________\n",
       "block12_sepconv1_bn (BatchNorma (None, 19, 19, 728)  2912        block12_sepconv1[0][0]           \n",
       "__________________________________________________________________________________________________\n",
       "block12_sepconv2_act (Activatio (None, 19, 19, 728)  0           block12_sepconv1_bn[0][0]        \n",
       "__________________________________________________________________________________________________\n",
       "block12_sepconv2 (SeparableConv (None, 19, 19, 728)  536536      block12_sepconv2_act[0][0]       \n",
       "__________________________________________________________________________________________________\n",
       "block12_sepconv2_bn (BatchNorma (None, 19, 19, 728)  2912        block12_sepconv2[0][0]           \n",
       "__________________________________________________________________________________________________\n",
       "block12_sepconv3_act (Activatio (None, 19, 19, 728)  0           block12_sepconv2_bn[0][0]        \n",
       "__________________________________________________________________________________________________\n",
       "block12_sepconv3 (SeparableConv (None, 19, 19, 728)  536536      block12_sepconv3_act[0][0]       \n",
       "__________________________________________________________________________________________________\n",
       "block12_sepconv3_bn (BatchNorma (None, 19, 19, 728)  2912        block12_sepconv3[0][0]           \n",
       "__________________________________________________________________________________________________\n",
       "add_10 (Add)                    (None, 19, 19, 728)  0           block12_sepconv3_bn[0][0]        \n",
       "                                                                 add_9[0][0]                      \n",
       "__________________________________________________________________________________________________\n",
       "block13_sepconv1_act (Activatio (None, 19, 19, 728)  0           add_10[0][0]                     \n",
       "__________________________________________________________________________________________________\n",
       "block13_sepconv1 (SeparableConv (None, 19, 19, 728)  536536      block13_sepconv1_act[0][0]       \n",
       "__________________________________________________________________________________________________\n",
       "block13_sepconv1_bn (BatchNorma (None, 19, 19, 728)  2912        block13_sepconv1[0][0]           \n",
       "__________________________________________________________________________________________________\n",
       "block13_sepconv2_act (Activatio (None, 19, 19, 728)  0           block13_sepconv1_bn[0][0]        \n",
       "__________________________________________________________________________________________________\n",
       "block13_sepconv2 (SeparableConv (None, 19, 19, 1024) 752024      block13_sepconv2_act[0][0]       \n",
       "__________________________________________________________________________________________________\n",
       "block13_sepconv2_bn (BatchNorma (None, 19, 19, 1024) 4096        block13_sepconv2[0][0]           \n",
       "__________________________________________________________________________________________________\n",
       "conv2d_3 (Conv2D)               (None, 10, 10, 1024) 745472      add_10[0][0]                     \n",
       "__________________________________________________________________________________________________\n",
       "block13_pool (MaxPooling2D)     (None, 10, 10, 1024) 0           block13_sepconv2_bn[0][0]        \n",
       "__________________________________________________________________________________________________\n",
       "batch_normalization_3 (BatchNor (None, 10, 10, 1024) 4096        conv2d_3[0][0]                   \n",
       "__________________________________________________________________________________________________\n",
       "add_11 (Add)                    (None, 10, 10, 1024) 0           block13_pool[0][0]               \n",
       "                                                                 batch_normalization_3[0][0]      \n",
       "__________________________________________________________________________________________________\n",
       "block14_sepconv1 (SeparableConv (None, 10, 10, 1536) 1582080     add_11[0][0]                     \n",
       "__________________________________________________________________________________________________\n",
       "block14_sepconv1_bn (BatchNorma (None, 10, 10, 1536) 6144        block14_sepconv1[0][0]           \n",
       "__________________________________________________________________________________________________\n",
       "block14_sepconv1_act (Activatio (None, 10, 10, 1536) 0           block14_sepconv1_bn[0][0]        \n",
       "__________________________________________________________________________________________________\n",
       "block14_sepconv2 (SeparableConv (None, 10, 10, 2048) 3159552     block14_sepconv1_act[0][0]       \n",
       "__________________________________________________________________________________________________\n",
       "block14_sepconv2_bn (BatchNorma (None, 10, 10, 2048) 8192        block14_sepconv2[0][0]           \n",
       "__________________________________________________________________________________________________\n",
       "block14_sepconv2_act (Activatio (None, 10, 10, 2048) 0           block14_sepconv2_bn[0][0]        \n",
       "__________________________________________________________________________________________________\n",
       "global_average_pooling2d (Globa (None, 2048)         0           block14_sepconv2_act[0][0]       \n",
       "__________________________________________________________________________________________________\n",
       "dropout (Dropout)               (None, 2048)         0           global_average_pooling2d[0][0]   \n",
       "__________________________________________________________________________________________________\n",
       "classLabels (Dense)             (None, 1)            2049        dropout[0][0]                    \n",
       "==================================================================================================\n",
       "Total params: 20,863,529\n",
       "Trainable params: 2,049\n",
       "Non-trainable params: 20,861,480\n",
       "__________________________________________________________________________________________________\n",
       "</div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "<div class=\"ansiout\">Loading new model\n\nDownloading data from https://storage.googleapis.com/tensorflow/keras-applications/xception/xception_weights_tf_dim_ordering_tf_kernels_notop.h5\n\r    8192/83683744 [..............................] - ETA: 1s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r 4202496/83683744 [&gt;.............................] - ETA: 2s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r16244736/83683744 [====&gt;.........................] - ETA: 0s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r27279360/83683744 [========&gt;.....................] - ETA: 0s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r33562624/83683744 [===========&gt;..................] - ETA: 0s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r44023808/83683744 [==============&gt;...............] - ETA: 0s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r54984704/83683744 [==================&gt;...........] - ETA: 0s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r65994752/83683744 [======================&gt;.......] - ETA: 0s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r76095488/83683744 [==========================&gt;...] - ETA: 0s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r83689472/83683744 [==============================] - 1s 0us/step\nModel: &#34;functional_1&#34;\n__________________________________________________________________________________________________\nLayer (type)                    Output Shape         Param #     Connected to                     \n==================================================================================================\ninput_1 (InputLayer)            [(None, 299, 299, 3) 0                                            \n__________________________________________________________________________________________________\nblock1_conv1 (Conv2D)           (None, 149, 149, 32) 864         input_1[0][0]                    \n__________________________________________________________________________________________________\nblock1_conv1_bn (BatchNormaliza (None, 149, 149, 32) 128         block1_conv1[0][0]               \n__________________________________________________________________________________________________\nblock1_conv1_act (Activation)   (None, 149, 149, 32) 0           block1_conv1_bn[0][0]            \n__________________________________________________________________________________________________\nblock1_conv2 (Conv2D)           (None, 147, 147, 64) 18432       block1_conv1_act[0][0]           \n__________________________________________________________________________________________________\nblock1_conv2_bn (BatchNormaliza (None, 147, 147, 64) 256         block1_conv2[0][0]               \n__________________________________________________________________________________________________\nblock1_conv2_act (Activation)   (None, 147, 147, 64) 0           block1_conv2_bn[0][0]            \n__________________________________________________________________________________________________\nblock2_sepconv1 (SeparableConv2 (None, 147, 147, 128 8768        block1_conv2_act[0][0]           \n__________________________________________________________________________________________________\nblock2_sepconv1_bn (BatchNormal (None, 147, 147, 128 512         block2_sepconv1[0][0]            \n__________________________________________________________________________________________________\nblock2_sepconv2_act (Activation (None, 147, 147, 128 0           block2_sepconv1_bn[0][0]         \n__________________________________________________________________________________________________\nblock2_sepconv2 (SeparableConv2 (None, 147, 147, 128 17536       block2_sepconv2_act[0][0]        \n__________________________________________________________________________________________________\nblock2_sepconv2_bn (BatchNormal (None, 147, 147, 128 512         block2_sepconv2[0][0]            \n__________________________________________________________________________________________________\nconv2d (Conv2D)                 (None, 74, 74, 128)  8192        block1_conv2_act[0][0]           \n__________________________________________________________________________________________________\nblock2_pool (MaxPooling2D)      (None, 74, 74, 128)  0           block2_sepconv2_bn[0][0]         \n__________________________________________________________________________________________________\nbatch_normalization (BatchNorma (None, 74, 74, 128)  512         conv2d[0][0]                     \n__________________________________________________________________________________________________\nadd (Add)                       (None, 74, 74, 128)  0           block2_pool[0][0]                \n                                                                 batch_normalization[0][0]        \n__________________________________________________________________________________________________\nblock3_sepconv1_act (Activation (None, 74, 74, 128)  0           add[0][0]                        \n__________________________________________________________________________________________________\nblock3_sepconv1 (SeparableConv2 (None, 74, 74, 256)  33920       block3_sepconv1_act[0][0]        \n__________________________________________________________________________________________________\nblock3_sepconv1_bn (BatchNormal (None, 74, 74, 256)  1024        block3_sepconv1[0][0]            \n__________________________________________________________________________________________________\nblock3_sepconv2_act (Activation (None, 74, 74, 256)  0           block3_sepconv1_bn[0][0]         \n__________________________________________________________________________________________________\nblock3_sepconv2 (SeparableConv2 (None, 74, 74, 256)  67840       block3_sepconv2_act[0][0]        \n__________________________________________________________________________________________________\nblock3_sepconv2_bn (BatchNormal (None, 74, 74, 256)  1024        block3_sepconv2[0][0]            \n__________________________________________________________________________________________________\nconv2d_1 (Conv2D)               (None, 37, 37, 256)  32768       add[0][0]                        \n__________________________________________________________________________________________________\nblock3_pool (MaxPooling2D)      (None, 37, 37, 256)  0           block3_sepconv2_bn[0][0]         \n__________________________________________________________________________________________________\nbatch_normalization_1 (BatchNor (None, 37, 37, 256)  1024        conv2d_1[0][0]                   \n__________________________________________________________________________________________________\nadd_1 (Add)                     (None, 37, 37, 256)  0           block3_pool[0][0]                \n                                                                 batch_normalization_1[0][0]      \n__________________________________________________________________________________________________\nblock4_sepconv1_act (Activation (None, 37, 37, 256)  0           add_1[0][0]                      \n__________________________________________________________________________________________________\nblock4_sepconv1 (SeparableConv2 (None, 37, 37, 728)  188672      block4_sepconv1_act[0][0]        \n__________________________________________________________________________________________________\nblock4_sepconv1_bn (BatchNormal (None, 37, 37, 728)  2912        block4_sepconv1[0][0]            \n__________________________________________________________________________________________________\nblock4_sepconv2_act (Activation (None, 37, 37, 728)  0           block4_sepconv1_bn[0][0]         \n__________________________________________________________________________________________________\nblock4_sepconv2 (SeparableConv2 (None, 37, 37, 728)  536536      block4_sepconv2_act[0][0]        \n__________________________________________________________________________________________________\nblock4_sepconv2_bn (BatchNormal (None, 37, 37, 728)  2912        block4_sepconv2[0][0]            \n__________________________________________________________________________________________________\nconv2d_2 (Conv2D)               (None, 19, 19, 728)  186368      add_1[0][0]                      \n__________________________________________________________________________________________________\nblock4_pool (MaxPooling2D)      (None, 19, 19, 728)  0           block4_sepconv2_bn[0][0]         \n__________________________________________________________________________________________________\nbatch_normalization_2 (BatchNor (None, 19, 19, 728)  2912        conv2d_2[0][0]                   \n__________________________________________________________________________________________________\nadd_2 (Add)                     (None, 19, 19, 728)  0           block4_pool[0][0]                \n                                                                 batch_normalization_2[0][0]      \n__________________________________________________________________________________________________\nblock5_sepconv1_act (Activation (None, 19, 19, 728)  0           add_2[0][0]                      \n__________________________________________________________________________________________________\nblock5_sepconv1 (SeparableConv2 (None, 19, 19, 728)  536536      block5_sepconv1_act[0][0]        \n__________________________________________________________________________________________________\nblock5_sepconv1_bn (BatchNormal (None, 19, 19, 728)  2912        block5_sepconv1[0][0]            \n__________________________________________________________________________________________________\nblock5_sepconv2_act (Activation (None, 19, 19, 728)  0           block5_sepconv1_bn[0][0]         \n__________________________________________________________________________________________________\nblock5_sepconv2 (SeparableConv2 (None, 19, 19, 728)  536536      block5_sepconv2_act[0][0]        \n__________________________________________________________________________________________________\nblock5_sepconv2_bn (BatchNormal (None, 19, 19, 728)  2912        block5_sepconv2[0][0]            \n__________________________________________________________________________________________________\nblock5_sepconv3_act (Activation (None, 19, 19, 728)  0           block5_sepconv2_bn[0][0]         \n__________________________________________________________________________________________________\nblock5_sepconv3 (SeparableConv2 (None, 19, 19, 728)  536536      block5_sepconv3_act[0][0]        \n__________________________________________________________________________________________________\nblock5_sepconv3_bn (BatchNormal (None, 19, 19, 728)  2912        block5_sepconv3[0][0]            \n__________________________________________________________________________________________________\nadd_3 (Add)                     (None, 19, 19, 728)  0           block5_sepconv3_bn[0][0]         \n                                                                 add_2[0][0]                      \n__________________________________________________________________________________________________\nblock6_sepconv1_act (Activation (None, 19, 19, 728)  0           add_3[0][0]                      \n__________________________________________________________________________________________________\nblock6_sepconv1 (SeparableConv2 (None, 19, 19, 728)  536536      block6_sepconv1_act[0][0]        \n__________________________________________________________________________________________________\nblock6_sepconv1_bn (BatchNormal (None, 19, 19, 728)  2912        block6_sepconv1[0][0]            \n__________________________________________________________________________________________________\nblock6_sepconv2_act (Activation (None, 19, 19, 728)  0           block6_sepconv1_bn[0][0]         \n__________________________________________________________________________________________________\nblock6_sepconv2 (SeparableConv2 (None, 19, 19, 728)  536536      block6_sepconv2_act[0][0]        \n__________________________________________________________________________________________________\nblock6_sepconv2_bn (BatchNormal (None, 19, 19, 728)  2912        block6_sepconv2[0][0]            \n__________________________________________________________________________________________________\nblock6_sepconv3_act (Activation (None, 19, 19, 728)  0           block6_sepconv2_bn[0][0]         \n__________________________________________________________________________________________________\nblock6_sepconv3 (SeparableConv2 (None, 19, 19, 728)  536536      block6_sepconv3_act[0][0]        \n__________________________________________________________________________________________________\nblock6_sepconv3_bn (BatchNormal (None, 19, 19, 728)  2912        block6_sepconv3[0][0]            \n__________________________________________________________________________________________________\nadd_4 (Add)                     (None, 19, 19, 728)  0           block6_sepconv3_bn[0][0]         \n                                                                 add_3[0][0]                      \n__________________________________________________________________________________________________\nblock7_sepconv1_act (Activation (None, 19, 19, 728)  0           add_4[0][0]                      \n__________________________________________________________________________________________________\nblock7_sepconv1 (SeparableConv2 (None, 19, 19, 728)  536536      block7_sepconv1_act[0][0]        \n__________________________________________________________________________________________________\nblock7_sepconv1_bn (BatchNormal (None, 19, 19, 728)  2912        block7_sepconv1[0][0]            \n__________________________________________________________________________________________________\nblock7_sepconv2_act (Activation (None, 19, 19, 728)  0           block7_sepconv1_bn[0][0]         \n__________________________________________________________________________________________________\nblock7_sepconv2 (SeparableConv2 (None, 19, 19, 728)  536536      block7_sepconv2_act[0][0]        \n__________________________________________________________________________________________________\nblock7_sepconv2_bn (BatchNormal (None, 19, 19, 728)  2912        block7_sepconv2[0][0]            \n__________________________________________________________________________________________________\nblock7_sepconv3_act (Activation (None, 19, 19, 728)  0           block7_sepconv2_bn[0][0]         \n__________________________________________________________________________________________________\nblock7_sepconv3 (SeparableConv2 (None, 19, 19, 728)  536536      block7_sepconv3_act[0][0]        \n__________________________________________________________________________________________________\nblock7_sepconv3_bn (BatchNormal (None, 19, 19, 728)  2912        block7_sepconv3[0][0]            \n__________________________________________________________________________________________________\nadd_5 (Add)                     (None, 19, 19, 728)  0           block7_sepconv3_bn[0][0]         \n                                                                 add_4[0][0]                      \n__________________________________________________________________________________________________\nblock8_sepconv1_act (Activation (None, 19, 19, 728)  0           add_5[0][0]                      \n__________________________________________________________________________________________________\nblock8_sepconv1 (SeparableConv2 (None, 19, 19, 728)  536536      block8_sepconv1_act[0][0]        \n__________________________________________________________________________________________________\nblock8_sepconv1_bn (BatchNormal (None, 19, 19, 728)  2912        block8_sepconv1[0][0]            \n__________________________________________________________________________________________________\nblock8_sepconv2_act (Activation (None, 19, 19, 728)  0           block8_sepconv1_bn[0][0]         \n__________________________________________________________________________________________________\nblock8_sepconv2 (SeparableConv2 (None, 19, 19, 728)  536536      block8_sepconv2_act[0][0]        \n__________________________________________________________________________________________________\nblock8_sepconv2_bn (BatchNormal (None, 19, 19, 728)  2912        block8_sepconv2[0][0]            \n__________________________________________________________________________________________________\nblock8_sepconv3_act (Activation (None, 19, 19, 728)  0           block8_sepconv2_bn[0][0]         \n__________________________________________________________________________________________________\nblock8_sepconv3 (SeparableConv2 (None, 19, 19, 728)  536536      block8_sepconv3_act[0][0]        \n__________________________________________________________________________________________________\nblock8_sepconv3_bn (BatchNormal (None, 19, 19, 728)  2912        block8_sepconv3[0][0]            \n__________________________________________________________________________________________________\nadd_6 (Add)                     (None, 19, 19, 728)  0           block8_sepconv3_bn[0][0]         \n                                                                 add_5[0][0]                      \n__________________________________________________________________________________________________\nblock9_sepconv1_act (Activation (None, 19, 19, 728)  0           add_6[0][0]                      \n__________________________________________________________________________________________________\nblock9_sepconv1 (SeparableConv2 (None, 19, 19, 728)  536536      block9_sepconv1_act[0][0]        \n__________________________________________________________________________________________________\nblock9_sepconv1_bn (BatchNormal (None, 19, 19, 728)  2912        block9_sepconv1[0][0]            \n__________________________________________________________________________________________________\nblock9_sepconv2_act (Activation (None, 19, 19, 728)  0           block9_sepconv1_bn[0][0]         \n__________________________________________________________________________________________________\nblock9_sepconv2 (SeparableConv2 (None, 19, 19, 728)  536536      block9_sepconv2_act[0][0]        \n__________________________________________________________________________________________________\nblock9_sepconv2_bn (BatchNormal (None, 19, 19, 728)  2912        block9_sepconv2[0][0]            \n__________________________________________________________________________________________________\nblock9_sepconv3_act (Activation (None, 19, 19, 728)  0           block9_sepconv2_bn[0][0]         \n__________________________________________________________________________________________________\nblock9_sepconv3 (SeparableConv2 (None, 19, 19, 728)  536536      block9_sepconv3_act[0][0]        \n__________________________________________________________________________________________________\nblock9_sepconv3_bn (BatchNormal (None, 19, 19, 728)  2912        block9_sepconv3[0][0]            \n__________________________________________________________________________________________________\nadd_7 (Add)                     (None, 19, 19, 728)  0           block9_sepconv3_bn[0][0]         \n                                                                 add_6[0][0]                      \n__________________________________________________________________________________________________\nblock10_sepconv1_act (Activatio (None, 19, 19, 728)  0           add_7[0][0]                      \n__________________________________________________________________________________________________\nblock10_sepconv1 (SeparableConv (None, 19, 19, 728)  536536      block10_sepconv1_act[0][0]       \n__________________________________________________________________________________________________\nblock10_sepconv1_bn (BatchNorma (None, 19, 19, 728)  2912        block10_sepconv1[0][0]           \n__________________________________________________________________________________________________\nblock10_sepconv2_act (Activatio (None, 19, 19, 728)  0           block10_sepconv1_bn[0][0]        \n__________________________________________________________________________________________________\nblock10_sepconv2 (SeparableConv (None, 19, 19, 728)  536536      block10_sepconv2_act[0][0]       \n__________________________________________________________________________________________________\nblock10_sepconv2_bn (BatchNorma (None, 19, 19, 728)  2912        block10_sepconv2[0][0]           \n__________________________________________________________________________________________________\nblock10_sepconv3_act (Activatio (None, 19, 19, 728)  0           block10_sepconv2_bn[0][0]        \n__________________________________________________________________________________________________\nblock10_sepconv3 (SeparableConv (None, 19, 19, 728)  536536      block10_sepconv3_act[0][0]       \n__________________________________________________________________________________________________\nblock10_sepconv3_bn (BatchNorma (None, 19, 19, 728)  2912        block10_sepconv3[0][0]           \n__________________________________________________________________________________________________\nadd_8 (Add)                     (None, 19, 19, 728)  0           block10_sepconv3_bn[0][0]        \n                                                                 add_7[0][0]                      \n__________________________________________________________________________________________________\nblock11_sepconv1_act (Activatio (None, 19, 19, 728)  0           add_8[0][0]                      \n__________________________________________________________________________________________________\nblock11_sepconv1 (SeparableConv (None, 19, 19, 728)  536536      block11_sepconv1_act[0][0]       \n__________________________________________________________________________________________________\nblock11_sepconv1_bn (BatchNorma (None, 19, 19, 728)  2912        block11_sepconv1[0][0]           \n__________________________________________________________________________________________________\nblock11_sepconv2_act (Activatio (None, 19, 19, 728)  0           block11_sepconv1_bn[0][0]        \n__________________________________________________________________________________________________\nblock11_sepconv2 (SeparableConv (None, 19, 19, 728)  536536      block11_sepconv2_act[0][0]       \n__________________________________________________________________________________________________\nblock11_sepconv2_bn (BatchNorma (None, 19, 19, 728)  2912        block11_sepconv2[0][0]           \n__________________________________________________________________________________________________\nblock11_sepconv3_act (Activatio (None, 19, 19, 728)  0           block11_sepconv2_bn[0][0]        \n__________________________________________________________________________________________________\nblock11_sepconv3 (SeparableConv (None, 19, 19, 728)  536536      block11_sepconv3_act[0][0]       \n__________________________________________________________________________________________________\nblock11_sepconv3_bn (BatchNorma (None, 19, 19, 728)  2912        block11_sepconv3[0][0]           \n__________________________________________________________________________________________________\nadd_9 (Add)                     (None, 19, 19, 728)  0           block11_sepconv3_bn[0][0]        \n                                                                 add_8[0][0]                      \n__________________________________________________________________________________________________\nblock12_sepconv1_act (Activatio (None, 19, 19, 728)  0           add_9[0][0]                      \n__________________________________________________________________________________________________\nblock12_sepconv1 (SeparableConv (None, 19, 19, 728)  536536      block12_sepconv1_act[0][0]       \n__________________________________________________________________________________________________\nblock12_sepconv1_bn (BatchNorma (None, 19, 19, 728)  2912        block12_sepconv1[0][0]           \n__________________________________________________________________________________________________\nblock12_sepconv2_act (Activatio (None, 19, 19, 728)  0           block12_sepconv1_bn[0][0]        \n__________________________________________________________________________________________________\nblock12_sepconv2 (SeparableConv (None, 19, 19, 728)  536536      block12_sepconv2_act[0][0]       \n__________________________________________________________________________________________________\nblock12_sepconv2_bn (BatchNorma (None, 19, 19, 728)  2912        block12_sepconv2[0][0]           \n__________________________________________________________________________________________________\nblock12_sepconv3_act (Activatio (None, 19, 19, 728)  0           block12_sepconv2_bn[0][0]        \n__________________________________________________________________________________________________\nblock12_sepconv3 (SeparableConv (None, 19, 19, 728)  536536      block12_sepconv3_act[0][0]       \n__________________________________________________________________________________________________\nblock12_sepconv3_bn (BatchNorma (None, 19, 19, 728)  2912        block12_sepconv3[0][0]           \n__________________________________________________________________________________________________\nadd_10 (Add)                    (None, 19, 19, 728)  0           block12_sepconv3_bn[0][0]        \n                                                                 add_9[0][0]                      \n__________________________________________________________________________________________________\nblock13_sepconv1_act (Activatio (None, 19, 19, 728)  0           add_10[0][0]                     \n__________________________________________________________________________________________________\nblock13_sepconv1 (SeparableConv (None, 19, 19, 728)  536536      block13_sepconv1_act[0][0]       \n__________________________________________________________________________________________________\nblock13_sepconv1_bn (BatchNorma (None, 19, 19, 728)  2912        block13_sepconv1[0][0]           \n__________________________________________________________________________________________________\nblock13_sepconv2_act (Activatio (None, 19, 19, 728)  0           block13_sepconv1_bn[0][0]        \n__________________________________________________________________________________________________\nblock13_sepconv2 (SeparableConv (None, 19, 19, 1024) 752024      block13_sepconv2_act[0][0]       \n__________________________________________________________________________________________________\nblock13_sepconv2_bn (BatchNorma (None, 19, 19, 1024) 4096        block13_sepconv2[0][0]           \n__________________________________________________________________________________________________\nconv2d_3 (Conv2D)               (None, 10, 10, 1024) 745472      add_10[0][0]                     \n__________________________________________________________________________________________________\nblock13_pool (MaxPooling2D)     (None, 10, 10, 1024) 0           block13_sepconv2_bn[0][0]        \n__________________________________________________________________________________________________\nbatch_normalization_3 (BatchNor (None, 10, 10, 1024) 4096        conv2d_3[0][0]                   \n__________________________________________________________________________________________________\nadd_11 (Add)                    (None, 10, 10, 1024) 0           block13_pool[0][0]               \n                                                                 batch_normalization_3[0][0]      \n__________________________________________________________________________________________________\nblock14_sepconv1 (SeparableConv (None, 10, 10, 1536) 1582080     add_11[0][0]                     \n__________________________________________________________________________________________________\nblock14_sepconv1_bn (BatchNorma (None, 10, 10, 1536) 6144        block14_sepconv1[0][0]           \n__________________________________________________________________________________________________\nblock14_sepconv1_act (Activatio (None, 10, 10, 1536) 0           block14_sepconv1_bn[0][0]        \n__________________________________________________________________________________________________\nblock14_sepconv2 (SeparableConv (None, 10, 10, 2048) 3159552     block14_sepconv1_act[0][0]       \n__________________________________________________________________________________________________\nblock14_sepconv2_bn (BatchNorma (None, 10, 10, 2048) 8192        block14_sepconv2[0][0]           \n__________________________________________________________________________________________________\nblock14_sepconv2_act (Activatio (None, 10, 10, 2048) 0           block14_sepconv2_bn[0][0]        \n__________________________________________________________________________________________________\nglobal_average_pooling2d (Globa (None, 2048)         0           block14_sepconv2_act[0][0]       \n__________________________________________________________________________________________________\ndropout (Dropout)               (None, 2048)         0           global_average_pooling2d[0][0]   \n__________________________________________________________________________________________________\nclassLabels (Dense)             (None, 1)            2049        dropout[0][0]                    \n==================================================================================================\nTotal params: 20,863,529\nTrainable params: 2,049\nNon-trainable params: 20,861,480\n__________________________________________________________________________________________________\n</div>",
       "datasetInfos": [],
       "removedWidgets": [],
       "type": "html"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "new_model = create_new_model()\n",
    "  \n",
    "# Compile model\n",
    "new_model.compile(optimizer=optimizer, \n",
    "                loss='mean_absolute_error', \n",
    "                metrics=['mse', \n",
    "                         'mean_absolute_percentage_error', \n",
    "                         'mean_absolute_error'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "57be0d87-0575-4c3d-8e4d-69ba04a25fd0",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "When `autolog()` is active, MLflow does not automatically end a run. We need to end the run that was started in Cmd 30 before starting and autologging a new run.  \n",
    "For more information, see https://www.mlflow.org/docs/latest/tracking.html#automatic-logging."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "be803cba-c371-45a2-a81b-0fc78758877b",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\"></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "<div class=\"ansiout\"></div>",
       "datasetInfos": [],
       "removedWidgets": [],
       "type": "html"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "mlflow.end_run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "df084b4f-d806-4ddb-b192-264958e7f66d",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\">Out[31]: 1</div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "<div class=\"ansiout\">Out[31]: 1</div>",
       "datasetInfos": [],
       "removedWidgets": [],
       "type": "html"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "d6c6d187-6adb-4292-86e8-1fedd22a2c8c",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\">\r",
       "  1/188 [..............................] - ETA: 0s - loss: 2.5561 - mse: 7.4826 - mean_absolute_percentage_error: 1513.3591 - mean_absolute_error: 2.5561\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
       "  2/188 [..............................] - ETA: 30s - loss: 2.2032 - mse: 5.6863 - mean_absolute_percentage_error: 1172.9189 - mean_absolute_error: 2.2032WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0512s vs `on_train_batch_end` time: 0.2736s). Check your callbacks.\n",
       "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
       "  4/188 [..............................] - ETA: 19s - loss: 1.8473 - mse: 5.0097 - mean_absolute_percentage_error: 1269.3275 - mean_absolute_error: 1.8473\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
       "  6/188 [..............................] - ETA: 15s - loss: 2.3031 - mse: 7.3971 - mean_absolute_percentage_error: 1916.6942 - mean_absolute_error: 2.3031\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
       "  8/188 [&gt;.............................] - ETA: 13s - loss: 2.1217 - mse: 6.3471 - mean_absolute_percentage_error: 1758.2076 - mean_absolute_error: 2.1217\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
       " 10/188 [&gt;.............................] - ETA: 11s - loss: 2.3007 - mse: 11.9322 - mean_absolute_percentage_error: 1477.2666 - mean_absolute_error: 2.3007\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
       " 12/188 [&gt;.............................] - ETA: 10s - loss: 2.2118 - mse: 11.7788 - mean_absolute_percentage_error: 1282.4899 - mean_absolute_error: 2.2118\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
       " 14/188 [=&gt;............................] - ETA: 9s - loss: 2.4065 - mse: 14.3146 - mean_absolute_percentage_error: 2010.0643 - mean_absolute_error: 2.4065 \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
       " 16/188 [=&gt;............................] - ETA: 9s - loss: 2.3837 - mse: 13.2845 - mean_absolute_percentage_error: 4027.4561 - mean_absolute_error: 2.3837\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
       " 18/188 [=&gt;............................] - ETA: 8s - loss: 2.2668 - mse: 12.0768 - mean_absolute_percentage_error: 4200.9839 - mean_absolute_error: 2.2668\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
       " 20/188 [==&gt;...........................] - ETA: 7s - loss: 2.1506 - mse: 11.1377 - mean_absolute_percentage_error: 4074.8872 - mean_absolute_error: 2.1506\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
       " 22/188 [==&gt;...........................] - ETA: 7s - loss: 2.1185 - mse: 10.4634 - mean_absolute_percentage_error: 3811.2463 - mean_absolute_error: 2.1185\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
       " 24/188 [==&gt;...........................] - ETA: 7s - loss: 2.1010 - mse: 10.1381 - mean_absolute_percentage_error: 3514.2498 - mean_absolute_error: 2.1010\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
       " 26/188 [===&gt;..........................] - ETA: 6s - loss: 2.0730 - mse: 9.7147 - mean_absolute_percentage_error: 3322.5374 - mean_absolute_error: 2.0730 \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
       " 28/188 [===&gt;..........................] - ETA: 6s - loss: 2.0414 - mse: 9.3544 - mean_absolute_percentage_error: 3202.6843 - mean_absolute_error: 2.0414\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
       " 30/188 [===&gt;..........................] - ETA: 6s - loss: 2.0227 - mse: 9.0191 - mean_absolute_percentage_error: 3046.1836 - mean_absolute_error: 2.0227\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
       " 32/188 [====&gt;.........................] - ETA: 6s - loss: 1.9502 - mse: 8.5383 - mean_absolute_percentage_error: 2906.7627 - mean_absolute_error: 1.9502\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
       " 34/188 [====&gt;.........................] - ETA: 6s - loss: 2.0452 - mse: 10.1293 - mean_absolute_percentage_error: 2820.4490 - mean_absolute_error: 2.0452\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
       " 36/188 [====&gt;.........................] - ETA: 5s - loss: 2.0591 - mse: 10.4084 - mean_absolute_percentage_error: 2716.4910 - mean_absolute_error: 2.0591\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
       " 38/188 [=====&gt;........................] - ETA: 5s - loss: 2.1338 - mse: 11.7573 - mean_absolute_percentage_error: 2594.5269 - mean_absolute_error: 2.1338\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
       " 40/188 [=====&gt;........................] - ETA: 5s - loss: 2.1150 - mse: 11.3851 - mean_absolute_percentage_error: 2534.1504 - mean_absolute_error: 2.1150\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
       " 42/188 [=====&gt;........................] - ETA: 5s - loss: 2.0675 - mse: 10.9518 - mean_absolute_percentage_error: 2449.7810 - mean_absolute_error: 2.0675\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
       " 44/188 [======&gt;.......................] - ETA: 5s - loss: 2.0135 - mse: 10.5147 - mean_absolute_percentage_error: 2367.0457 - mean_absolute_error: 2.0135\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
       " 46/188 [======&gt;.......................] - ETA: 5s - loss: 1.9702 - mse: 10.1272 - mean_absolute_percentage_error: 2280.7598 - mean_absolute_error: 1.9702\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
       " 48/188 [======&gt;.......................] - ETA: 5s - loss: 1.9847 - mse: 10.3586 - mean_absolute_percentage_error: 2203.5447 - mean_absolute_error: 1.9847\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
       " 50/188 [======&gt;.......................] - ETA: 4s - loss: 1.9378 - mse: 9.9906 - mean_absolute_percentage_error: 2123.7485 - mean_absolute_error: 1.9378 \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
       " 52/188 [=======&gt;......................] - ETA: 4s - loss: 1.9055 - mse: 9.6649 - mean_absolute_percentage_error: 2091.7456 - mean_absolute_error: 1.9055\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
       " 54/188 [=======&gt;......................] - ETA: 4s - loss: 1.9018 - mse: 9.5724 - mean_absolute_percentage_error: 2021.6937 - mean_absolute_error: 1.9018\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
       " 56/188 [=======&gt;......................] - ETA: 4s - loss: 1.9775 - mse: 9.8826 - mean_absolute_percentage_error: 2238.7991 - mean_absolute_error: 1.9775\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
       " 58/188 [========&gt;.....................] - ETA: 4s - loss: 2.0757 - mse: 11.3472 - mean_absolute_percentage_error: 2196.7324 - mean_absolute_error: 2.0757\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
       " 60/188 [========&gt;.....................] - ETA: 4s - loss: 2.0648 - mse: 11.1605 - mean_absolute_percentage_error: 2254.4817 - mean_absolute_error: 2.0648\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
       " 62/188 [========&gt;.....................] - ETA: 4s - loss: 2.0768 - mse: 11.0131 - mean_absolute_percentage_error: 2233.6938 - mean_absolute_error: 2.0768\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
       " 64/188 [=========&gt;....................] - ETA: 4s - loss: 2.1234 - mse: 11.4086 - mean_absolute_percentage_error: 2223.6699 - mean_absolute_error: 2.1234\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
       " 66/188 [=========&gt;....................] - ETA: 4s - loss: 2.1519 - mse: 11.4014 - mean_absolute_percentage_error: 5012.5669 - mean_absolute_error: 2.1519\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
       " 68/188 [=========&gt;....................] - ETA: 4s - loss: 2.1319 - mse: 11.1507 - mean_absolute_percentage_error: 5547.2334 - mean_absolute_error: 2.1319\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
       " 70/188 [==========&gt;...................] - ETA: 4s - loss: 2.1631 - mse: 11.1940 - mean_absolute_percentage_error: 5465.3540 - mean_absolute_error: 2.1631\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
       " 72/188 [==========&gt;...................] - ETA: 3s - loss: 2.1719 - mse: 11.1125 - mean_absolute_percentage_error: 5407.4878 - mean_absolute_error: 2.1719\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
       " 74/188 [==========&gt;...................] - ETA: 3s - loss: 2.1647 - mse: 10.9533 - mean_absolute_percentage_error: 5290.6401 - mean_absolute_error: 2.1647\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
       " 76/188 [===========&gt;..................] - ETA: 3s - loss: 2.2151 - mse: 11.1710 - mean_absolute_percentage_error: 5473.4917 - mean_absolute_error: 2.2151\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
       " 78/188 [===========&gt;..................] - ETA: 3s - loss: 2.2401 - mse: 11.2460 - mean_absolute_percentage_error: 5364.6792 - mean_absolute_error: 2.2401\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
       " 80/188 [===========&gt;..................] - ETA: 3s - loss: 2.2311 - mse: 11.1593 - mean_absolute_percentage_error: 5278.0010 - mean_absolute_error: 2.2311\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
       " 82/188 [============&gt;.................] - ETA: 3s - loss: 2.2227 - mse: 11.0943 - mean_absolute_percentage_error: 5171.6025 - mean_absolute_error: 2.2227\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
       " 84/188 [============&gt;.................] - ETA: 3s - loss: 2.1925 - mse: 10.8633 - mean_absolute_percentage_error: 80145.6641 - mean_absolute_error: 2.1925\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
       " 86/188 [============&gt;.................] - ETA: 3s - loss: 2.2309 - mse: 11.5711 - mean_absolute_percentage_error: 78290.1953 - mean_absolute_error: 2.2309\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
       " 88/188 [=============&gt;................] - ETA: 3s - loss: 2.2593 - mse: 11.6009 - mean_absolute_percentage_error: 76693.0312 - mean_absolute_error: 2.2593\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
       " 90/188 [=============&gt;................] - ETA: 3s - loss: 2.2773 - mse: 11.6043 - mean_absolute_percentage_error: 75071.1719 - mean_absolute_error: 2.2773\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
       " 92/188 [=============&gt;................] - ETA: 3s - loss: 2.2799 - mse: 11.5021 - mean_absolute_percentage_error: 73460.7266 - mean_absolute_error: 2.2799\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
       " 94/188 [==============&gt;...............] - ETA: 3s - loss: 2.2594 - mse: 11.3052 - mean_absolute_percentage_error: 71909.6484 - mean_absolute_error: 2.2594\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
       " 96/188 [==============&gt;...............] - ETA: 2s - loss: 2.2880 - mse: 11.9691 - mean_absolute_percentage_error: 70432.7266 - mean_absolute_error: 2.2880\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
       " 98/188 [==============&gt;...............] - ETA: 2s - loss: 2.3214 - mse: 12.3565 - mean_absolute_percentage_error: 69050.5703 - mean_absolute_error: 2.3214\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
       "100/188 [==============&gt;...............] - ETA: 2s - loss: 2.3613 - mse: 13.4598 - mean_absolute_percentage_error: 67686.5469 - mean_absolute_error: 2.3613\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
       "102/188 [===============&gt;..............] - ETA: 2s - loss: 2.3616 - mse: 13.4481 - mean_absolute_percentage_error: 66390.8203 - mean_absolute_error: 2.3616\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
       "104/188 [===============&gt;..............] - ETA: 2s - loss: 2.3271 - mse: 13.2006 - mean_absolute_percentage_error: 65140.5898 - mean_absolute_error: 2.3271\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
       "106/188 [===============&gt;..............] - ETA: 2s - loss: 2.3726 - mse: 13.7483 - mean_absolute_percentage_error: 63980.8164 - mean_absolute_error: 2.3726\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
       "108/188 [================&gt;.............] - ETA: 2s - loss: 2.3866 - mse: 13.7736 - mean_absolute_percentage_error: 62856.1016 - mean_absolute_error: 2.3866\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
       "110/188 [================&gt;.............] - ETA: 2s - loss: 2.3610 - mse: 13.5516 - mean_absolute_percentage_error: 61727.6289 - mean_absolute_error: 2.3610\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
       "112/188 [================&gt;.............] - ETA: 2s - loss: 2.3495 - mse: 13.4327 - mean_absolute_percentage_error: 60652.5000 - mean_absolute_error: 2.3495\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
       "114/188 [=================&gt;............] - ETA: 2s - loss: 2.3315 - mse: 13.2369 - mean_absolute_percentage_error: 59607.7422 - mean_absolute_error: 2.3315\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
       "116/188 [=================&gt;............] - ETA: 2s - loss: 2.3452 - mse: 13.4481 - mean_absolute_percentage_error: 58605.6094 - mean_absolute_error: 2.3452\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
       "118/188 [=================&gt;............] - ETA: 2s - loss: 2.3313 - mse: 13.3151 - mean_absolute_percentage_error: 58218.7578 - mean_absolute_error: 2.3313\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
       "120/188 [==================&gt;...........] - ETA: 2s - loss: 2.3466 - mse: 13.3024 - mean_absolute_percentage_error: 57283.6992 - mean_absolute_error: 2.3466\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
       "122/188 [==================&gt;...........] - ETA: 2s - loss: 2.3249 - mse: 13.1153 - mean_absolute_percentage_error: 56349.7188 - mean_absolute_error: 2.3249\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
       "124/188 [==================&gt;...........] - ETA: 2s - loss: 2.3327 - mse: 13.0850 - mean_absolute_percentage_error: 55494.8086 - mean_absolute_error: 2.3327\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
       "126/188 [===================&gt;..........] - ETA: 1s - loss: 2.3312 - mse: 13.1340 - mean_absolute_percentage_error: 54622.9727 - mean_absolute_error: 2.3312\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
       "128/188 [===================&gt;..........] - ETA: 1s - loss: 2.3133 - mse: 12.9590 - mean_absolute_percentage_error: 53787.1992 - mean_absolute_error: 2.3133\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
       "130/188 [===================&gt;..........] - ETA: 1s - loss: 2.2910 - mse: 12.7761 - mean_absolute_percentage_error: 52962.3516 - mean_absolute_error: 2.2910\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
       "132/188 [====================&gt;.........] - ETA: 1s - loss: 2.3122 - mse: 13.4997 - mean_absolute_percentage_error: 52175.1875 - mean_absolute_error: 2.3122\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
       "134/188 [====================&gt;.........] - ETA: 1s - loss: 2.2929 - mse: 13.3210 - mean_absolute_percentage_error: 51412.3594 - mean_absolute_error: 2.2929\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
       "136/188 [====================&gt;.........] - ETA: 1s - loss: 2.2781 - mse: 13.1655 - mean_absolute_percentage_error: 50663.0625 - mean_absolute_error: 2.2781\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
       "138/188 [=====================&gt;........] - ETA: 1s - loss: 2.2723 - mse: 13.0428 - mean_absolute_percentage_error: 50019.2852 - mean_absolute_error: 2.2723\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
       "140/188 [=====================&gt;........] - ETA: 1s - loss: 2.2725 - mse: 12.9624 - mean_absolute_percentage_error: 49336.2812 - mean_absolute_error: 2.2725\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
       "142/188 [=====================&gt;........] - ETA: 1s - loss: 2.2821 - mse: 12.9183 - mean_absolute_percentage_error: 48665.8398 - mean_absolute_error: 2.2821\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
       "144/188 [=====================&gt;........] - ETA: 1s - loss: 2.3184 - mse: 14.2201 - mean_absolute_percentage_error: 47999.5078 - mean_absolute_error: 2.3184\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
       "146/188 [======================&gt;.......] - ETA: 1s - loss: 2.3133 - mse: 14.1007 - mean_absolute_percentage_error: 47356.1875 - mean_absolute_error: 2.3133\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
       "148/188 [======================&gt;.......] - ETA: 1s - loss: 2.3026 - mse: 13.9528 - mean_absolute_percentage_error: 3515830.0000 - mean_absolute_error: 2.3026\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
       "150/188 [======================&gt;.......] - ETA: 1s - loss: 2.3413 - mse: 15.6067 - mean_absolute_percentage_error: 3468964.5000 - mean_absolute_error: 2.3413\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
       "152/188 [=======================&gt;......] - ETA: 1s - loss: 2.3557 - mse: 15.5620 - mean_absolute_percentage_error: 3423333.0000 - mean_absolute_error: 2.3557\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
       "154/188 [=======================&gt;......] - ETA: 1s - loss: 2.3469 - mse: 15.4177 - mean_absolute_percentage_error: 3378887.2500 - mean_absolute_error: 2.3469\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
       "156/188 [=======================&gt;......] - ETA: 0s - loss: 2.3338 - mse: 15.2537 - mean_absolute_percentage_error: 3335579.0000 - mean_absolute_error: 2.3338\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
       "158/188 [========================&gt;.....] - ETA: 0s - loss: 2.3158 - mse: 15.0735 - mean_absolute_percentage_error: 3293358.7500 - mean_absolute_error: 2.3158\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
       "160/188 [========================&gt;.....] - ETA: 0s - loss: 2.3227 - mse: 14.9906 - mean_absolute_percentage_error: 3252237.5000 - mean_absolute_error: 2.3227\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
       "162/188 [========================&gt;.....] - ETA: 0s - loss: 2.3124 - mse: 14.8364 - mean_absolute_percentage_error: 3212117.2500 - mean_absolute_error: 2.3124\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
       "164/188 [=========================&gt;....] - ETA: 0s - loss: 2.3066 - mse: 14.7116 - mean_absolute_percentage_error: 3172964.7500 - mean_absolute_error: 2.3066\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
       "166/188 [=========================&gt;....] - ETA: 0s - loss: 2.3280 - mse: 14.8288 - mean_absolute_percentage_error: 3134779.2500 - mean_absolute_error: 2.3280\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
       "168/188 [=========================&gt;....] - ETA: 0s - loss: 2.3289 - mse: 14.7475 - mean_absolute_percentage_error: 3097474.7500 - mean_absolute_error: 2.3289\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
       "170/188 [==========================&gt;...] - ETA: 0s - loss: 2.3443 - mse: 14.7425 - mean_absolute_percentage_error: 3061125.7500 - mean_absolute_error: 2.3443\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
       "172/188 [==========================&gt;...] - ETA: 0s - loss: 2.3512 - mse: 14.6914 - mean_absolute_percentage_error: 3025540.0000 - mean_absolute_error: 2.3512\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
       "174/188 [==========================&gt;...] - ETA: 0s - loss: 2.3419 - mse: 14.5865 - mean_absolute_percentage_error: 2990768.2500 - mean_absolute_error: 2.3419\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
       "176/188 [===========================&gt;..] - ETA: 0s - loss: 2.3382 - mse: 14.4815 - mean_absolute_percentage_error: 2956789.7500 - mean_absolute_error: 2.3382\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
       "178/188 [===========================&gt;..] - ETA: 0s - loss: 2.3445 - mse: 14.5711 - mean_absolute_percentage_error: 2923581.2500 - mean_absolute_error: 2.3445\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
       "180/188 [===========================&gt;..] - ETA: 0s - loss: 2.3259 - mse: 14.4169 - mean_absolute_percentage_error: 2891101.2500 - mean_absolute_error: 2.3259\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
       "182/188 [============================&gt;.] - ETA: 0s - loss: 2.3504 - mse: 14.9187 - mean_absolute_percentage_error: 2859418.5000 - mean_absolute_error: 2.3504\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
       "184/188 [============================&gt;.] - ETA: 0s - loss: 2.3421 - mse: 14.7976 - mean_absolute_percentage_error: 2828347.2500 - mean_absolute_error: 2.3421\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
       "186/188 [============================&gt;.] - ETA: 0s - loss: 2.3266 - mse: 14.6493 - mean_absolute_percentage_error: 2797938.7500 - mean_absolute_error: 2.3266\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
       "188/188 [==============================] - 6s 31ms/step - loss: 2.3415 - mse: 14.7411 - mean_absolute_percentage_error: 2775559.7500 - mean_absolute_error: 2.3415\n",
       "\r",
       "1/6 [====&gt;.........................] - ETA: 0s - loss: 3.7648 - mse: 26.2591 - mean_absolute_percentage_error: 3646.2302 - mean_absolute_error: 3.7648\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
       "2/6 [=========&gt;....................] - ETA: 0s - loss: 3.2210 - mse: 17.1302 - mean_absolute_percentage_error: 4608.5913 - mean_absolute_error: 3.2210\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
       "3/6 [==============&gt;...............] - ETA: 0s - loss: 3.2841 - mse: 18.6934 - mean_absolute_percentage_error: 8517.0205 - mean_absolute_error: 3.2841\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
       "4/6 [===================&gt;..........] - ETA: 0s - loss: 3.1695 - mse: 16.4626 - mean_absolute_percentage_error: 7175.2412 - mean_absolute_error: 3.1695\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
       "5/6 [========================&gt;.....] - ETA: 0s - loss: 3.1807 - mse: 16.5878 - mean_absolute_percentage_error: 6361.8057 - mean_absolute_error: 3.1807\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
       "6/6 [==============================] - ETA: 0s - loss: 3.0818 - mse: 15.1691 - mean_absolute_percentage_error: 6243.6284 - mean_absolute_error: 3.0818\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
       "6/6 [==============================] - 2s 261ms/step - loss: 3.0818 - mse: 15.1691 - mean_absolute_percentage_error: 6243.6284 - mean_absolute_error: 3.0818\n",
       "&lt;Figure size 432x288 with 1 Axes&gt;\n",
       "</div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "<div class=\"ansiout\">\r  1/188 [..............................] - ETA: 0s - loss: 2.5561 - mse: 7.4826 - mean_absolute_percentage_error: 1513.3591 - mean_absolute_error: 2.5561\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r  2/188 [..............................] - ETA: 30s - loss: 2.2032 - mse: 5.6863 - mean_absolute_percentage_error: 1172.9189 - mean_absolute_error: 2.2032WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0512s vs `on_train_batch_end` time: 0.2736s). Check your callbacks.\n\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r  4/188 [..............................] - ETA: 19s - loss: 1.8473 - mse: 5.0097 - mean_absolute_percentage_error: 1269.3275 - mean_absolute_error: 1.8473\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r  6/188 [..............................] - ETA: 15s - loss: 2.3031 - mse: 7.3971 - mean_absolute_percentage_error: 1916.6942 - mean_absolute_error: 2.3031\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r  8/188 [&gt;.............................] - ETA: 13s - loss: 2.1217 - mse: 6.3471 - mean_absolute_percentage_error: 1758.2076 - mean_absolute_error: 2.1217\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r 10/188 [&gt;.............................] - ETA: 11s - loss: 2.3007 - mse: 11.9322 - mean_absolute_percentage_error: 1477.2666 - mean_absolute_error: 2.3007\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r 12/188 [&gt;.............................] - ETA: 10s - loss: 2.2118 - mse: 11.7788 - mean_absolute_percentage_error: 1282.4899 - mean_absolute_error: 2.2118\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r 14/188 [=&gt;............................] - ETA: 9s - loss: 2.4065 - mse: 14.3146 - mean_absolute_percentage_error: 2010.0643 - mean_absolute_error: 2.4065 \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r 16/188 [=&gt;............................] - ETA: 9s - loss: 2.3837 - mse: 13.2845 - mean_absolute_percentage_error: 4027.4561 - mean_absolute_error: 2.3837\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r 18/188 [=&gt;............................] - ETA: 8s - loss: 2.2668 - mse: 12.0768 - mean_absolute_percentage_error: 4200.9839 - mean_absolute_error: 2.2668\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r 20/188 [==&gt;...........................] - ETA: 7s - loss: 2.1506 - mse: 11.1377 - mean_absolute_percentage_error: 4074.8872 - mean_absolute_error: 2.1506\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r 22/188 [==&gt;...........................] - ETA: 7s - loss: 2.1185 - mse: 10.4634 - mean_absolute_percentage_error: 3811.2463 - mean_absolute_error: 2.1185\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r 24/188 [==&gt;...........................] - ETA: 7s - loss: 2.1010 - mse: 10.1381 - mean_absolute_percentage_error: 3514.2498 - mean_absolute_error: 2.1010\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r 26/188 [===&gt;..........................] - ETA: 6s - loss: 2.0730 - mse: 9.7147 - mean_absolute_percentage_error: 3322.5374 - mean_absolute_error: 2.0730 \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r 28/188 [===&gt;..........................] - ETA: 6s - loss: 2.0414 - mse: 9.3544 - mean_absolute_percentage_error: 3202.6843 - mean_absolute_error: 2.0414\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r 30/188 [===&gt;..........................] - ETA: 6s - loss: 2.0227 - mse: 9.0191 - mean_absolute_percentage_error: 3046.1836 - mean_absolute_error: 2.0227\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r 32/188 [====&gt;.........................] - ETA: 6s - loss: 1.9502 - mse: 8.5383 - mean_absolute_percentage_error: 2906.7627 - mean_absolute_error: 1.9502\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r 34/188 [====&gt;.........................] - ETA: 6s - loss: 2.0452 - mse: 10.1293 - mean_absolute_percentage_error: 2820.4490 - mean_absolute_error: 2.0452\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r 36/188 [====&gt;.........................] - ETA: 5s - loss: 2.0591 - mse: 10.4084 - mean_absolute_percentage_error: 2716.4910 - mean_absolute_error: 2.0591\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r 38/188 [=====&gt;........................] - ETA: 5s - loss: 2.1338 - mse: 11.7573 - mean_absolute_percentage_error: 2594.5269 - mean_absolute_error: 2.1338\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r 40/188 [=====&gt;........................] - ETA: 5s - loss: 2.1150 - mse: 11.3851 - mean_absolute_percentage_error: 2534.1504 - mean_absolute_error: 2.1150\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r 42/188 [=====&gt;........................] - ETA: 5s - loss: 2.0675 - mse: 10.9518 - mean_absolute_percentage_error: 2449.7810 - mean_absolute_error: 2.0675\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r 44/188 [======&gt;.......................] - ETA: 5s - loss: 2.0135 - mse: 10.5147 - mean_absolute_percentage_error: 2367.0457 - mean_absolute_error: 2.0135\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r 46/188 [======&gt;.......................] - ETA: 5s - loss: 1.9702 - mse: 10.1272 - mean_absolute_percentage_error: 2280.7598 - mean_absolute_error: 1.9702\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r 48/188 [======&gt;.......................] - ETA: 5s - loss: 1.9847 - mse: 10.3586 - mean_absolute_percentage_error: 2203.5447 - mean_absolute_error: 1.9847\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r 50/188 [======&gt;.......................] - ETA: 4s - loss: 1.9378 - mse: 9.9906 - mean_absolute_percentage_error: 2123.7485 - mean_absolute_error: 1.9378 \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r 52/188 [=======&gt;......................] - ETA: 4s - loss: 1.9055 - mse: 9.6649 - mean_absolute_percentage_error: 2091.7456 - mean_absolute_error: 1.9055\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r 54/188 [=======&gt;......................] - ETA: 4s - loss: 1.9018 - mse: 9.5724 - mean_absolute_percentage_error: 2021.6937 - mean_absolute_error: 1.9018\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r 56/188 [=======&gt;......................] - ETA: 4s - loss: 1.9775 - mse: 9.8826 - mean_absolute_percentage_error: 2238.7991 - mean_absolute_error: 1.9775\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r 58/188 [========&gt;.....................] - ETA: 4s - loss: 2.0757 - mse: 11.3472 - mean_absolute_percentage_error: 2196.7324 - mean_absolute_error: 2.0757\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r 60/188 [========&gt;.....................] - ETA: 4s - loss: 2.0648 - mse: 11.1605 - mean_absolute_percentage_error: 2254.4817 - mean_absolute_error: 2.0648\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r 62/188 [========&gt;.....................] - ETA: 4s - loss: 2.0768 - mse: 11.0131 - mean_absolute_percentage_error: 2233.6938 - mean_absolute_error: 2.0768\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r 64/188 [=========&gt;....................] - ETA: 4s - loss: 2.1234 - mse: 11.4086 - mean_absolute_percentage_error: 2223.6699 - mean_absolute_error: 2.1234\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r 66/188 [=========&gt;....................] - ETA: 4s - loss: 2.1519 - mse: 11.4014 - mean_absolute_percentage_error: 5012.5669 - mean_absolute_error: 2.1519\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r 68/188 [=========&gt;....................] - ETA: 4s - loss: 2.1319 - mse: 11.1507 - mean_absolute_percentage_error: 5547.2334 - mean_absolute_error: 2.1319\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r 70/188 [==========&gt;...................] - ETA: 4s - loss: 2.1631 - mse: 11.1940 - mean_absolute_percentage_error: 5465.3540 - mean_absolute_error: 2.1631\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r 72/188 [==========&gt;...................] - ETA: 3s - loss: 2.1719 - mse: 11.1125 - mean_absolute_percentage_error: 5407.4878 - mean_absolute_error: 2.1719\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r 74/188 [==========&gt;...................] - ETA: 3s - loss: 2.1647 - mse: 10.9533 - mean_absolute_percentage_error: 5290.6401 - mean_absolute_error: 2.1647\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r 76/188 [===========&gt;..................] - ETA: 3s - loss: 2.2151 - mse: 11.1710 - mean_absolute_percentage_error: 5473.4917 - mean_absolute_error: 2.2151\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r 78/188 [===========&gt;..................] - ETA: 3s - loss: 2.2401 - mse: 11.2460 - mean_absolute_percentage_error: 5364.6792 - mean_absolute_error: 2.2401\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r 80/188 [===========&gt;..................] - ETA: 3s - loss: 2.2311 - mse: 11.1593 - mean_absolute_percentage_error: 5278.0010 - mean_absolute_error: 2.2311\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r 82/188 [============&gt;.................] - ETA: 3s - loss: 2.2227 - mse: 11.0943 - mean_absolute_percentage_error: 5171.6025 - mean_absolute_error: 2.2227\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r 84/188 [============&gt;.................] - ETA: 3s - loss: 2.1925 - mse: 10.8633 - mean_absolute_percentage_error: 80145.6641 - mean_absolute_error: 2.1925\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r 86/188 [============&gt;.................] - ETA: 3s - loss: 2.2309 - mse: 11.5711 - mean_absolute_percentage_error: 78290.1953 - mean_absolute_error: 2.2309\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r 88/188 [=============&gt;................] - ETA: 3s - loss: 2.2593 - mse: 11.6009 - mean_absolute_percentage_error: 76693.0312 - mean_absolute_error: 2.2593\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r 90/188 [=============&gt;................] - ETA: 3s - loss: 2.2773 - mse: 11.6043 - mean_absolute_percentage_error: 75071.1719 - mean_absolute_error: 2.2773\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r 92/188 [=============&gt;................] - ETA: 3s - loss: 2.2799 - mse: 11.5021 - mean_absolute_percentage_error: 73460.7266 - mean_absolute_error: 2.2799\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r 94/188 [==============&gt;...............] - ETA: 3s - loss: 2.2594 - mse: 11.3052 - mean_absolute_percentage_error: 71909.6484 - mean_absolute_error: 2.2594\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r 96/188 [==============&gt;...............] - ETA: 2s - loss: 2.2880 - mse: 11.9691 - mean_absolute_percentage_error: 70432.7266 - mean_absolute_error: 2.2880\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r 98/188 [==============&gt;...............] - ETA: 2s - loss: 2.3214 - mse: 12.3565 - mean_absolute_percentage_error: 69050.5703 - mean_absolute_error: 2.3214\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/188 [==============&gt;...............] - ETA: 2s - loss: 2.3613 - mse: 13.4598 - mean_absolute_percentage_error: 67686.5469 - mean_absolute_error: 2.3613\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r102/188 [===============&gt;..............] - ETA: 2s - loss: 2.3616 - mse: 13.4481 - mean_absolute_percentage_error: 66390.8203 - mean_absolute_error: 2.3616\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r104/188 [===============&gt;..............] - ETA: 2s - loss: 2.3271 - mse: 13.2006 - mean_absolute_percentage_error: 65140.5898 - mean_absolute_error: 2.3271\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r106/188 [===============&gt;..............] - ETA: 2s - loss: 2.3726 - mse: 13.7483 - mean_absolute_percentage_error: 63980.8164 - mean_absolute_error: 2.3726\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r108/188 [================&gt;.............] - ETA: 2s - loss: 2.3866 - mse: 13.7736 - mean_absolute_percentage_error: 62856.1016 - mean_absolute_error: 2.3866\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r110/188 [================&gt;.............] - ETA: 2s - loss: 2.3610 - mse: 13.5516 - mean_absolute_percentage_error: 61727.6289 - mean_absolute_error: 2.3610\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r112/188 [================&gt;.............] - ETA: 2s - loss: 2.3495 - mse: 13.4327 - mean_absolute_percentage_error: 60652.5000 - mean_absolute_error: 2.3495\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r114/188 [=================&gt;............] - ETA: 2s - loss: 2.3315 - mse: 13.2369 - mean_absolute_percentage_error: 59607.7422 - mean_absolute_error: 2.3315\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r116/188 [=================&gt;............] - ETA: 2s - loss: 2.3452 - mse: 13.4481 - mean_absolute_percentage_error: 58605.6094 - mean_absolute_error: 2.3452\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r118/188 [=================&gt;............] - ETA: 2s - loss: 2.3313 - mse: 13.3151 - mean_absolute_percentage_error: 58218.7578 - mean_absolute_error: 2.3313\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r120/188 [==================&gt;...........] - ETA: 2s - loss: 2.3466 - mse: 13.3024 - mean_absolute_percentage_error: 57283.6992 - mean_absolute_error: 2.3466\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r122/188 [==================&gt;...........] - ETA: 2s - loss: 2.3249 - mse: 13.1153 - mean_absolute_percentage_error: 56349.7188 - mean_absolute_error: 2.3249\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r124/188 [==================&gt;...........] - ETA: 2s - loss: 2.3327 - mse: 13.0850 - mean_absolute_percentage_error: 55494.8086 - mean_absolute_error: 2.3327\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r126/188 [===================&gt;..........] - ETA: 1s - loss: 2.3312 - mse: 13.1340 - mean_absolute_percentage_error: 54622.9727 - mean_absolute_error: 2.3312\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r128/188 [===================&gt;..........] - ETA: 1s - loss: 2.3133 - mse: 12.9590 - mean_absolute_percentage_error: 53787.1992 - mean_absolute_error: 2.3133\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r130/188 [===================&gt;..........] - ETA: 1s - loss: 2.2910 - mse: 12.7761 - mean_absolute_percentage_error: 52962.3516 - mean_absolute_error: 2.2910\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r132/188 [====================&gt;.........] - ETA: 1s - loss: 2.3122 - mse: 13.4997 - mean_absolute_percentage_error: 52175.1875 - mean_absolute_error: 2.3122\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r134/188 [====================&gt;.........] - ETA: 1s - loss: 2.2929 - mse: 13.3210 - mean_absolute_percentage_error: 51412.3594 - mean_absolute_error: 2.2929\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r136/188 [====================&gt;.........] - ETA: 1s - loss: 2.2781 - mse: 13.1655 - mean_absolute_percentage_error: 50663.0625 - mean_absolute_error: 2.2781\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r138/188 [=====================&gt;........] - ETA: 1s - loss: 2.2723 - mse: 13.0428 - mean_absolute_percentage_error: 50019.2852 - mean_absolute_error: 2.2723\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r140/188 [=====================&gt;........] - ETA: 1s - loss: 2.2725 - mse: 12.9624 - mean_absolute_percentage_error: 49336.2812 - mean_absolute_error: 2.2725\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r142/188 [=====================&gt;........] - ETA: 1s - loss: 2.2821 - mse: 12.9183 - mean_absolute_percentage_error: 48665.8398 - mean_absolute_error: 2.2821\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r144/188 [=====================&gt;........] - ETA: 1s - loss: 2.3184 - mse: 14.2201 - mean_absolute_percentage_error: 47999.5078 - mean_absolute_error: 2.3184\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r146/188 [======================&gt;.......] - ETA: 1s - loss: 2.3133 - mse: 14.1007 - mean_absolute_percentage_error: 47356.1875 - mean_absolute_error: 2.3133\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r148/188 [======================&gt;.......] - ETA: 1s - loss: 2.3026 - mse: 13.9528 - mean_absolute_percentage_error: 3515830.0000 - mean_absolute_error: 2.3026\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r150/188 [======================&gt;.......] - ETA: 1s - loss: 2.3413 - mse: 15.6067 - mean_absolute_percentage_error: 3468964.5000 - mean_absolute_error: 2.3413\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r152/188 [=======================&gt;......] - ETA: 1s - loss: 2.3557 - mse: 15.5620 - mean_absolute_percentage_error: 3423333.0000 - mean_absolute_error: 2.3557\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r154/188 [=======================&gt;......] - ETA: 1s - loss: 2.3469 - mse: 15.4177 - mean_absolute_percentage_error: 3378887.2500 - mean_absolute_error: 2.3469\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r156/188 [=======================&gt;......] - ETA: 0s - loss: 2.3338 - mse: 15.2537 - mean_absolute_percentage_error: 3335579.0000 - mean_absolute_error: 2.3338\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r158/188 [========================&gt;.....] - ETA: 0s - loss: 2.3158 - mse: 15.0735 - mean_absolute_percentage_error: 3293358.7500 - mean_absolute_error: 2.3158\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r160/188 [========================&gt;.....] - ETA: 0s - loss: 2.3227 - mse: 14.9906 - mean_absolute_percentage_error: 3252237.5000 - mean_absolute_error: 2.3227\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r162/188 [========================&gt;.....] - ETA: 0s - loss: 2.3124 - mse: 14.8364 - mean_absolute_percentage_error: 3212117.2500 - mean_absolute_error: 2.3124\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r164/188 [=========================&gt;....] - ETA: 0s - loss: 2.3066 - mse: 14.7116 - mean_absolute_percentage_error: 3172964.7500 - mean_absolute_error: 2.3066\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r166/188 [=========================&gt;....] - ETA: 0s - loss: 2.3280 - mse: 14.8288 - mean_absolute_percentage_error: 3134779.2500 - mean_absolute_error: 2.3280\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r168/188 [=========================&gt;....] - ETA: 0s - loss: 2.3289 - mse: 14.7475 - mean_absolute_percentage_error: 3097474.7500 - mean_absolute_error: 2.3289\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r170/188 [==========================&gt;...] - ETA: 0s - loss: 2.3443 - mse: 14.7425 - mean_absolute_percentage_error: 3061125.7500 - mean_absolute_error: 2.3443\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r172/188 [==========================&gt;...] - ETA: 0s - loss: 2.3512 - mse: 14.6914 - mean_absolute_percentage_error: 3025540.0000 - mean_absolute_error: 2.3512\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r174/188 [==========================&gt;...] - ETA: 0s - loss: 2.3419 - mse: 14.5865 - mean_absolute_percentage_error: 2990768.2500 - mean_absolute_error: 2.3419\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r176/188 [===========================&gt;..] - ETA: 0s - loss: 2.3382 - mse: 14.4815 - mean_absolute_percentage_error: 2956789.7500 - mean_absolute_error: 2.3382\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r178/188 [===========================&gt;..] - ETA: 0s - loss: 2.3445 - mse: 14.5711 - mean_absolute_percentage_error: 2923581.2500 - mean_absolute_error: 2.3445\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r180/188 [===========================&gt;..] - ETA: 0s - loss: 2.3259 - mse: 14.4169 - mean_absolute_percentage_error: 2891101.2500 - mean_absolute_error: 2.3259\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r182/188 [============================&gt;.] - ETA: 0s - loss: 2.3504 - mse: 14.9187 - mean_absolute_percentage_error: 2859418.5000 - mean_absolute_error: 2.3504\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r184/188 [============================&gt;.] - ETA: 0s - loss: 2.3421 - mse: 14.7976 - mean_absolute_percentage_error: 2828347.2500 - mean_absolute_error: 2.3421\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r186/188 [============================&gt;.] - ETA: 0s - loss: 2.3266 - mse: 14.6493 - mean_absolute_percentage_error: 2797938.7500 - mean_absolute_error: 2.3266\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r188/188 [==============================] - 6s 31ms/step - loss: 2.3415 - mse: 14.7411 - mean_absolute_percentage_error: 2775559.7500 - mean_absolute_error: 2.3415\n\r1/6 [====&gt;.........................] - ETA: 0s - loss: 3.7648 - mse: 26.2591 - mean_absolute_percentage_error: 3646.2302 - mean_absolute_error: 3.7648\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r2/6 [=========&gt;....................] - ETA: 0s - loss: 3.2210 - mse: 17.1302 - mean_absolute_percentage_error: 4608.5913 - mean_absolute_error: 3.2210\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r3/6 [==============&gt;...............] - ETA: 0s - loss: 3.2841 - mse: 18.6934 - mean_absolute_percentage_error: 8517.0205 - mean_absolute_error: 3.2841\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r4/6 [===================&gt;..........] - ETA: 0s - loss: 3.1695 - mse: 16.4626 - mean_absolute_percentage_error: 7175.2412 - mean_absolute_error: 3.1695\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r5/6 [========================&gt;.....] - ETA: 0s - loss: 3.1807 - mse: 16.5878 - mean_absolute_percentage_error: 6361.8057 - mean_absolute_error: 3.1807\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r6/6 [==============================] - ETA: 0s - loss: 3.0818 - mse: 15.1691 - mean_absolute_percentage_error: 6243.6284 - mean_absolute_error: 3.0818\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r6/6 [==============================] - 2s 261ms/step - loss: 3.0818 - mse: 15.1691 - mean_absolute_percentage_error: 6243.6284 - mean_absolute_error: 3.0818\n&lt;Figure size 432x288 with 1 Axes&gt;\n</div>",
       "datasetInfos": [],
       "removedWidgets": [],
       "type": "html"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "mlflow.tensorflow.autolog()\n",
    "\n",
    "with mlflow.start_run() as run:\n",
    "  \n",
    "  history = new_model.fit(np.array(train_images), \n",
    "                          np.array(train_yy), \n",
    "#                                   validation_split=.2, \n",
    "                                  epochs=epochs, \n",
    "                                  verbose=1,\n",
    "                                  batch_size=batch_size,\n",
    "#                                   callbacks=[tensorboard_callback, \n",
    "#                                              model_checkpoint, \n",
    "#                                              early_stopping]\n",
    "                                 )\n",
    "  \n",
    "  # Save the run information to register the model later\n",
    "  kerasURI = run.info.artifact_uri\n",
    "  \n",
    "  # Evaluate model on test dataset and log result\n",
    "  mlflow.log_param(\"eval_result\", \n",
    "                   new_model.evaluate(np.array(test_images), \n",
    "                                      np.array(test_yy))[0])\n",
    "  \n",
    "  # Plot predicted vs known values for a quick visual check of the model and log the plot as an artifact\n",
    "  keras_pred = new_model.predict(np.array(test_images))\n",
    "  plt.plot(np.array(test_yy), keras_pred, \"o\", markersize=2)\n",
    "  plt.xlabel(\"observed value\")\n",
    "  plt.ylabel(\"predicted value\")\n",
    "  plt.savefig(\"kplot.png\")\n",
    "  mlflow.log_artifact(\"kplot.png\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "1166eae6-d9e9-4de2-850f-4997f53835b8",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Part 4. Register the model in MLflow and use the model to make predictions\n",
    "To learn more about the Model Registry, see ([AWS](https://docs.databricks.com/applications/mlflow/model-registry.html)|[Azure](https://docs.microsoft.com/azure/databricks/applications/mlflow/model-registry))."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "0f303fda-c4f7-4d62-9c76-792b5bfdc13c",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\"></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "<div class=\"ansiout\"></div>",
       "datasetInfos": [],
       "removedWidgets": [],
       "type": "html"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_path = '/dbfs/FileStore/tables/blogs/models/colorframe_model.h5'\n",
    "json_path = '/dbfs/FileStore/tables/blogs/models/colorframe_model.json'\n",
    "\n",
    "# new_model.save_weights(model_path)\n",
    "# print('Saved trained model at %s ' % model_path)\n",
    "\n",
    "model_json = new_model.to_json()\n",
    "open(json_path, 'w').write(model_json)\n",
    "\n",
    "# mlflow.log_model(model_path, 'model_path')\n",
    "mlflow.log_artifact(json_path, 'json_path')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "ca3585e7-49d9-47f5-8c52-ff36d03c7e3b",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\">Registered model &#39;colorframe&#39; already exists. Creating a new version of this model...\n",
       "Created version &#39;3&#39; of model &#39;colorframe&#39;.\n",
       "</div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "<div class=\"ansiout\">Registered model &#39;colorframe&#39; already exists. Creating a new version of this model...\nCreated version &#39;3&#39; of model &#39;colorframe&#39;.\n</div>",
       "datasetInfos": [],
       "removedWidgets": [],
       "type": "html"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "model_name = \"colorframe\"\n",
    "model_uri = kerasURI+\"/model\"\n",
    "new_model_version = mlflow.register_model(model_uri, model_name)\n",
    "\n",
    "# Registering the model takes a few seconds, so add a delay before continuing with the next cell\n",
    "time.sleep(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "32f24700-ddba-4368-9497-72746056832b",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Load the model for inference and make predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "dde28619-3a96-4b76-8538-1117246560ce",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\">Out[36]: array([[2.5374541 ],\n",
       "       [3.2678769 ],\n",
       "       [3.0341623 ],\n",
       "       [3.9246533 ],\n",
       "       [5.3540707 ],\n",
       "       [2.2571735 ],\n",
       "       [2.357383  ],\n",
       "       [4.071934  ],\n",
       "       [2.6663194 ],\n",
       "       [2.3384793 ],\n",
       "       [3.8936331 ],\n",
       "       [3.0537953 ],\n",
       "       [2.6437616 ],\n",
       "       [5.248788  ],\n",
       "       [3.3744543 ],\n",
       "       [1.9989566 ],\n",
       "       [3.4469922 ],\n",
       "       [3.2478435 ],\n",
       "       [3.3308902 ],\n",
       "       [2.7365532 ],\n",
       "       [2.446532  ],\n",
       "       [4.16877   ],\n",
       "       [4.1584864 ],\n",
       "       [3.447427  ],\n",
       "       [2.271582  ],\n",
       "       [2.7618506 ],\n",
       "       [3.147385  ],\n",
       "       [3.3469748 ],\n",
       "       [4.369869  ],\n",
       "       [3.3367028 ],\n",
       "       [3.2269151 ],\n",
       "       [3.4688303 ],\n",
       "       [4.120167  ],\n",
       "       [2.078065  ],\n",
       "       [4.019703  ],\n",
       "       [5.041812  ],\n",
       "       [3.50992   ],\n",
       "       [2.4590092 ],\n",
       "       [4.162942  ],\n",
       "       [1.8680092 ],\n",
       "       [2.7311177 ],\n",
       "       [2.5004175 ],\n",
       "       [1.971567  ],\n",
       "       [4.066986  ],\n",
       "       [3.2532208 ],\n",
       "       [3.642503  ],\n",
       "       [1.4995602 ],\n",
       "       [4.7609386 ],\n",
       "       [2.3255336 ],\n",
       "       [2.3952088 ],\n",
       "       [3.187093  ],\n",
       "       [3.4802458 ],\n",
       "       [3.7456691 ],\n",
       "       [2.8016112 ],\n",
       "       [2.1244657 ],\n",
       "       [2.9116685 ],\n",
       "       [3.7208135 ],\n",
       "       [2.9225452 ],\n",
       "       [2.7336068 ],\n",
       "       [3.376431  ],\n",
       "       [3.182278  ],\n",
       "       [2.2641835 ],\n",
       "       [3.5075967 ],\n",
       "       [2.9265978 ],\n",
       "       [2.6397583 ],\n",
       "       [3.5653908 ],\n",
       "       [2.9789968 ],\n",
       "       [3.3346128 ],\n",
       "       [1.9328927 ],\n",
       "       [2.963746  ],\n",
       "       [2.76102   ],\n",
       "       [3.7848423 ],\n",
       "       [1.660465  ],\n",
       "       [4.7199183 ],\n",
       "       [4.1745787 ],\n",
       "       [1.6536111 ],\n",
       "       [3.3782952 ],\n",
       "       [2.970159  ],\n",
       "       [3.5605137 ],\n",
       "       [2.9517906 ],\n",
       "       [3.2952628 ],\n",
       "       [2.273289  ],\n",
       "       [4.1876373 ],\n",
       "       [1.4010222 ],\n",
       "       [3.7049582 ],\n",
       "       [3.52909   ],\n",
       "       [3.014873  ],\n",
       "       [3.9356582 ],\n",
       "       [2.880937  ],\n",
       "       [3.2932928 ],\n",
       "       [4.424321  ],\n",
       "       [2.8027363 ],\n",
       "       [3.5936809 ],\n",
       "       [2.848199  ],\n",
       "       [3.0179572 ],\n",
       "       [3.2322586 ],\n",
       "       [0.0882553 ],\n",
       "       [4.9161186 ],\n",
       "       [1.4682242 ],\n",
       "       [3.0375245 ],\n",
       "       [2.7371447 ],\n",
       "       [2.922221  ],\n",
       "       [1.9005984 ],\n",
       "       [3.9673944 ],\n",
       "       [1.1328233 ],\n",
       "       [2.9814308 ],\n",
       "       [2.7574532 ],\n",
       "       [4.6011615 ],\n",
       "       [4.393426  ],\n",
       "       [3.647125  ],\n",
       "       [2.4305787 ],\n",
       "       [2.0360255 ],\n",
       "       [2.0554073 ],\n",
       "       [3.584027  ],\n",
       "       [3.1583822 ],\n",
       "       [3.253896  ],\n",
       "       [2.9442368 ],\n",
       "       [2.8312666 ],\n",
       "       [3.488383  ],\n",
       "       [3.4391968 ],\n",
       "       [3.9078705 ],\n",
       "       [2.7853186 ],\n",
       "       [3.2216456 ],\n",
       "       [2.7905474 ],\n",
       "       [3.0011642 ],\n",
       "       [3.3205035 ],\n",
       "       [2.586902  ],\n",
       "       [3.9559863 ],\n",
       "       [3.0187619 ],\n",
       "       [3.047871  ],\n",
       "       [2.397868  ],\n",
       "       [3.2428887 ],\n",
       "       [3.5078952 ],\n",
       "       [2.1818392 ],\n",
       "       [2.5248778 ],\n",
       "       [2.4667773 ],\n",
       "       [3.030227  ],\n",
       "       [3.248349  ],\n",
       "       [4.819742  ],\n",
       "       [3.047447  ],\n",
       "       [3.5179374 ],\n",
       "       [2.1998146 ],\n",
       "       [0.6026546 ],\n",
       "       [3.8684669 ],\n",
       "       [3.1930377 ],\n",
       "       [1.8060614 ],\n",
       "       [3.0088873 ],\n",
       "       [1.4026772 ],\n",
       "       [3.4012291 ],\n",
       "       [2.3242316 ],\n",
       "       [4.1493683 ],\n",
       "       [3.7922447 ],\n",
       "       [2.4385438 ],\n",
       "       [3.0675828 ],\n",
       "       [2.279734  ],\n",
       "       [3.072283  ],\n",
       "       [3.7030537 ],\n",
       "       [4.359474  ],\n",
       "       [2.5870302 ],\n",
       "       [3.1755843 ],\n",
       "       [4.4895167 ],\n",
       "       [1.8151201 ],\n",
       "       [2.350835  ],\n",
       "       [3.2439404 ],\n",
       "       [2.6312222 ],\n",
       "       [4.2802467 ],\n",
       "       [3.1646845 ],\n",
       "       [2.29786   ],\n",
       "       [2.5932682 ],\n",
       "       [2.7738147 ],\n",
       "       [3.1757994 ],\n",
       "       [3.527126  ],\n",
       "       [2.1753094 ],\n",
       "       [3.2313006 ],\n",
       "       [0.87366164],\n",
       "       [1.1633948 ],\n",
       "       [2.543244  ],\n",
       "       [4.0536847 ],\n",
       "       [4.5483127 ],\n",
       "       [2.8635612 ],\n",
       "       [1.0507253 ],\n",
       "       [3.1183274 ],\n",
       "       [2.4314158 ],\n",
       "       [3.8431022 ],\n",
       "       [2.538572  ],\n",
       "       [2.2237988 ],\n",
       "       [4.3369594 ],\n",
       "       [2.5413868 ]], dtype=float32)</div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "<div class=\"ansiout\">Out[36]: array([[2.5374541 ],\n       [3.2678769 ],\n       [3.0341623 ],\n       [3.9246533 ],\n       [5.3540707 ],\n       [2.2571735 ],\n       [2.357383  ],\n       [4.071934  ],\n       [2.6663194 ],\n       [2.3384793 ],\n       [3.8936331 ],\n       [3.0537953 ],\n       [2.6437616 ],\n       [5.248788  ],\n       [3.3744543 ],\n       [1.9989566 ],\n       [3.4469922 ],\n       [3.2478435 ],\n       [3.3308902 ],\n       [2.7365532 ],\n       [2.446532  ],\n       [4.16877   ],\n       [4.1584864 ],\n       [3.447427  ],\n       [2.271582  ],\n       [2.7618506 ],\n       [3.147385  ],\n       [3.3469748 ],\n       [4.369869  ],\n       [3.3367028 ],\n       [3.2269151 ],\n       [3.4688303 ],\n       [4.120167  ],\n       [2.078065  ],\n       [4.019703  ],\n       [5.041812  ],\n       [3.50992   ],\n       [2.4590092 ],\n       [4.162942  ],\n       [1.8680092 ],\n       [2.7311177 ],\n       [2.5004175 ],\n       [1.971567  ],\n       [4.066986  ],\n       [3.2532208 ],\n       [3.642503  ],\n       [1.4995602 ],\n       [4.7609386 ],\n       [2.3255336 ],\n       [2.3952088 ],\n       [3.187093  ],\n       [3.4802458 ],\n       [3.7456691 ],\n       [2.8016112 ],\n       [2.1244657 ],\n       [2.9116685 ],\n       [3.7208135 ],\n       [2.9225452 ],\n       [2.7336068 ],\n       [3.376431  ],\n       [3.182278  ],\n       [2.2641835 ],\n       [3.5075967 ],\n       [2.9265978 ],\n       [2.6397583 ],\n       [3.5653908 ],\n       [2.9789968 ],\n       [3.3346128 ],\n       [1.9328927 ],\n       [2.963746  ],\n       [2.76102   ],\n       [3.7848423 ],\n       [1.660465  ],\n       [4.7199183 ],\n       [4.1745787 ],\n       [1.6536111 ],\n       [3.3782952 ],\n       [2.970159  ],\n       [3.5605137 ],\n       [2.9517906 ],\n       [3.2952628 ],\n       [2.273289  ],\n       [4.1876373 ],\n       [1.4010222 ],\n       [3.7049582 ],\n       [3.52909   ],\n       [3.014873  ],\n       [3.9356582 ],\n       [2.880937  ],\n       [3.2932928 ],\n       [4.424321  ],\n       [2.8027363 ],\n       [3.5936809 ],\n       [2.848199  ],\n       [3.0179572 ],\n       [3.2322586 ],\n       [0.0882553 ],\n       [4.9161186 ],\n       [1.4682242 ],\n       [3.0375245 ],\n       [2.7371447 ],\n       [2.922221  ],\n       [1.9005984 ],\n       [3.9673944 ],\n       [1.1328233 ],\n       [2.9814308 ],\n       [2.7574532 ],\n       [4.6011615 ],\n       [4.393426  ],\n       [3.647125  ],\n       [2.4305787 ],\n       [2.0360255 ],\n       [2.0554073 ],\n       [3.584027  ],\n       [3.1583822 ],\n       [3.253896  ],\n       [2.9442368 ],\n       [2.8312666 ],\n       [3.488383  ],\n       [3.4391968 ],\n       [3.9078705 ],\n       [2.7853186 ],\n       [3.2216456 ],\n       [2.7905474 ],\n       [3.0011642 ],\n       [3.3205035 ],\n       [2.586902  ],\n       [3.9559863 ],\n       [3.0187619 ],\n       [3.047871  ],\n       [2.397868  ],\n       [3.2428887 ],\n       [3.5078952 ],\n       [2.1818392 ],\n       [2.5248778 ],\n       [2.4667773 ],\n       [3.030227  ],\n       [3.248349  ],\n       [4.819742  ],\n       [3.047447  ],\n       [3.5179374 ],\n       [2.1998146 ],\n       [0.6026546 ],\n       [3.8684669 ],\n       [3.1930377 ],\n       [1.8060614 ],\n       [3.0088873 ],\n       [1.4026772 ],\n       [3.4012291 ],\n       [2.3242316 ],\n       [4.1493683 ],\n       [3.7922447 ],\n       [2.4385438 ],\n       [3.0675828 ],\n       [2.279734  ],\n       [3.072283  ],\n       [3.7030537 ],\n       [4.359474  ],\n       [2.5870302 ],\n       [3.1755843 ],\n       [4.4895167 ],\n       [1.8151201 ],\n       [2.350835  ],\n       [3.2439404 ],\n       [2.6312222 ],\n       [4.2802467 ],\n       [3.1646845 ],\n       [2.29786   ],\n       [2.5932682 ],\n       [2.7738147 ],\n       [3.1757994 ],\n       [3.527126  ],\n       [2.1753094 ],\n       [3.2313006 ],\n       [0.87366164],\n       [1.1633948 ],\n       [2.543244  ],\n       [4.0536847 ],\n       [4.5483127 ],\n       [2.8635612 ],\n       [1.0507253 ],\n       [3.1183274 ],\n       [2.4314158 ],\n       [3.8431022 ],\n       [2.538572  ],\n       [2.2237988 ],\n       [4.3369594 ],\n       [2.5413868 ]], dtype=float32)</div>",
       "datasetInfos": [],
       "removedWidgets": [],
       "type": "html"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "keras_model = mlflow.keras.load_model(f\"models:/{model_name}/{new_model_version.version}\")\n",
    "\n",
    "keras_pred = keras_model.predict(np.array(test_images))\n",
    "keras_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "b6b1ad58-8737-431a-96dc-308bc5938172",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\"></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "<div class=\"ansiout\"></div>",
       "datasetInfos": [],
       "removedWidgets": [],
       "type": "html"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# new_model.save_weights(model_path)\n",
    "new_model.save_weights('/dbfs/FileStore/tables/blogs/h5weights')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "2d0c4c7d-6e16-4081-abcf-b0c3a1439565",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\">INFO:tensorflow:Assets written to: /dbfs/FileStore/tables/blogs/h5model/assets\n",
       "</div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "<div class=\"ansiout\">INFO:tensorflow:Assets written to: /dbfs/FileStore/tables/blogs/h5model/assets\n</div>",
       "datasetInfos": [],
       "removedWidgets": [],
       "type": "html"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "new_model.save('/dbfs/FileStore/tables/blogs/h5model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "e4a9f759-3bd4-4d57-afc6-abe61f433341",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\"></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "<div class=\"ansiout\"></div>",
       "datasetInfos": [],
       "removedWidgets": [],
       "type": "html"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "mlflow.log_artifact('/dbfs/FileStore/tables/blogs/h5model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2.5374541 ],\n",
       "       [3.2678769 ],\n",
       "       [3.0341623 ],\n",
       "       [3.9246533 ],\n",
       "       [5.3540707 ],\n",
       "       [2.2571735 ],\n",
       "       [2.357383  ],\n",
       "       [4.071934  ],\n",
       "       [2.6663194 ],\n",
       "       [2.3384793 ],\n",
       "       [3.8936331 ],\n",
       "       [3.0537953 ],\n",
       "       [2.6437616 ],\n",
       "       [5.248788  ],\n",
       "       [3.3744543 ],\n",
       "       [1.9989566 ],\n",
       "       [3.4469922 ],\n",
       "       [3.2478435 ],\n",
       "       [3.3308902 ],\n",
       "       [2.7365532 ],\n",
       "       [2.446532  ],\n",
       "       [4.16877   ],\n",
       "       [4.1584864 ],\n",
       "       [3.447427  ],\n",
       "       [2.271582  ],\n",
       "       [2.7618506 ],\n",
       "       [3.147385  ],\n",
       "       [3.3469748 ],\n",
       "       [4.369869  ],\n",
       "       [3.3367028 ],\n",
       "       [3.2269151 ],\n",
       "       [3.4688303 ],\n",
       "       [4.120167  ],\n",
       "       [2.078065  ],\n",
       "       [4.019703  ],\n",
       "       [5.041812  ],\n",
       "       [3.50992   ],\n",
       "       [2.4590092 ],\n",
       "       [4.162942  ],\n",
       "       [1.8680092 ],\n",
       "       [2.7311177 ],\n",
       "       [2.5004175 ],\n",
       "       [1.971567  ],\n",
       "       [4.066986  ],\n",
       "       [3.2532208 ],\n",
       "       [3.642503  ],\n",
       "       [1.4995602 ],\n",
       "       [4.7609386 ],\n",
       "       [2.3255336 ],\n",
       "       [2.3952088 ],\n",
       "       [3.187093  ],\n",
       "       [3.4802458 ],\n",
       "       [3.7456691 ],\n",
       "       [2.8016112 ],\n",
       "       [2.1244657 ],\n",
       "       [2.9116685 ],\n",
       "       [3.7208135 ],\n",
       "       [2.9225452 ],\n",
       "       [2.7336068 ],\n",
       "       [3.376431  ],\n",
       "       [3.182278  ],\n",
       "       [2.2641835 ],\n",
       "       [3.5075967 ],\n",
       "       [2.9265978 ],\n",
       "       [2.6397583 ],\n",
       "       [3.5653908 ],\n",
       "       [2.9789968 ],\n",
       "       [3.3346128 ],\n",
       "       [1.9328927 ],\n",
       "       [2.963746  ],\n",
       "       [2.76102   ],\n",
       "       [3.7848423 ],\n",
       "       [1.660465  ],\n",
       "       [4.7199183 ],\n",
       "       [4.1745787 ],\n",
       "       [1.6536111 ],\n",
       "       [3.3782952 ],\n",
       "       [2.970159  ],\n",
       "       [3.5605137 ],\n",
       "       [2.9517906 ],\n",
       "       [3.2952628 ],\n",
       "       [2.273289  ],\n",
       "       [4.1876373 ],\n",
       "       [1.4010222 ],\n",
       "       [3.7049582 ],\n",
       "       [3.52909   ],\n",
       "       [3.014873  ],\n",
       "       [3.9356582 ],\n",
       "       [2.880937  ],\n",
       "       [3.2932928 ],\n",
       "       [4.424321  ],\n",
       "       [2.8027363 ],\n",
       "       [3.5936809 ],\n",
       "       [2.848199  ],\n",
       "       [3.0179572 ],\n",
       "       [3.2322586 ],\n",
       "       [0.0882553 ],\n",
       "       [4.9161186 ],\n",
       "       [1.4682242 ],\n",
       "       [3.0375245 ],\n",
       "       [2.7371447 ],\n",
       "       [2.922221  ],\n",
       "       [1.9005984 ],\n",
       "       [3.9673944 ],\n",
       "       [1.1328233 ],\n",
       "       [2.9814308 ],\n",
       "       [2.7574532 ],\n",
       "       [4.6011615 ],\n",
       "       [4.393426  ],\n",
       "       [3.647125  ],\n",
       "       [2.4305787 ],\n",
       "       [2.0360255 ],\n",
       "       [2.0554073 ],\n",
       "       [3.584027  ],\n",
       "       [3.1583822 ],\n",
       "       [3.253896  ],\n",
       "       [2.9442368 ],\n",
       "       [2.8312666 ],\n",
       "       [3.488383  ],\n",
       "       [3.4391968 ],\n",
       "       [3.9078705 ],\n",
       "       [2.7853186 ],\n",
       "       [3.2216456 ],\n",
       "       [2.7905474 ],\n",
       "       [3.0011642 ],\n",
       "       [3.3205035 ],\n",
       "       [2.586902  ],\n",
       "       [3.9559863 ],\n",
       "       [3.0187619 ],\n",
       "       [3.047871  ],\n",
       "       [2.397868  ],\n",
       "       [3.2428887 ],\n",
       "       [3.5078952 ],\n",
       "       [2.1818392 ],\n",
       "       [2.5248778 ],\n",
       "       [2.4667773 ],\n",
       "       [3.030227  ],\n",
       "       [3.248349  ],\n",
       "       [4.819742  ],\n",
       "       [3.047447  ],\n",
       "       [3.5179374 ],\n",
       "       [2.1998146 ],\n",
       "       [0.6026546 ],\n",
       "       [3.8684669 ],\n",
       "       [3.1930377 ],\n",
       "       [1.8060614 ],\n",
       "       [3.0088873 ],\n",
       "       [1.4026772 ],\n",
       "       [3.4012291 ],\n",
       "       [2.3242316 ],\n",
       "       [4.1493683 ],\n",
       "       [3.7922447 ],\n",
       "       [2.4385438 ],\n",
       "       [3.0675828 ],\n",
       "       [2.279734  ],\n",
       "       [3.072283  ],\n",
       "       [3.7030537 ],\n",
       "       [4.359474  ],\n",
       "       [2.5870302 ],\n",
       "       [3.1755843 ],\n",
       "       [4.4895167 ],\n",
       "       [1.8151201 ],\n",
       "       [2.350835  ],\n",
       "       [3.2439404 ],\n",
       "       [2.6312222 ],\n",
       "       [4.2802467 ],\n",
       "       [3.1646845 ],\n",
       "       [2.29786   ],\n",
       "       [2.5932682 ],\n",
       "       [2.7738147 ],\n",
       "       [3.1757994 ],\n",
       "       [3.527126  ],\n",
       "       [2.1753094 ],\n",
       "       [3.2313006 ],\n",
       "       [0.87366164],\n",
       "       [1.1633948 ],\n",
       "       [2.543244  ],\n",
       "       [4.0536847 ],\n",
       "       [4.5483127 ],\n",
       "       [2.8635612 ],\n",
       "       [1.0507253 ],\n",
       "       [3.1183274 ],\n",
       "       [2.4314158 ],\n",
       "       [3.8431022 ],\n",
       "       [2.538572  ],\n",
       "       [2.2237988 ],\n",
       "       [4.3369594 ],\n",
       "       [2.5413868 ]])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds = np.array([[2.5374541 ], [3.2678769 ], [3.0341623 ], [3.9246533 ], [5.3540707 ], [2.2571735 ], [2.357383 ], [4.071934 ], [2.6663194 ], [2.3384793 ], [3.8936331 ], [3.0537953 ], [2.6437616 ], [5.248788 ], [3.3744543 ], [1.9989566 ], [3.4469922 ], [3.2478435 ], [3.3308902 ], [2.7365532 ], [2.446532 ], [4.16877 ], [4.1584864 ], [3.447427 ], [2.271582 ], [2.7618506 ], [3.147385 ], [3.3469748 ], [4.369869 ], [3.3367028 ], [3.2269151 ], [3.4688303 ], [4.120167 ], [2.078065 ], [4.019703 ], [5.041812 ], [3.50992 ], [2.4590092 ], [4.162942 ], [1.8680092 ], [2.7311177 ], [2.5004175 ], [1.971567 ], [4.066986 ], [3.2532208 ], [3.642503 ], [1.4995602 ], [4.7609386 ], [2.3255336 ], [2.3952088 ], [3.187093 ], [3.4802458 ], [3.7456691 ], [2.8016112 ], [2.1244657 ], [2.9116685 ], [3.7208135 ], [2.9225452 ], [2.7336068 ], [3.376431 ], [3.182278 ], [2.2641835 ], [3.5075967 ], [2.9265978 ], [2.6397583 ], [3.5653908 ], [2.9789968 ], [3.3346128 ], [1.9328927 ], [2.963746 ], [2.76102 ], [3.7848423 ], [1.660465 ], [4.7199183 ], [4.1745787 ], [1.6536111 ], [3.3782952 ], [2.970159 ], [3.5605137 ], [2.9517906 ], [3.2952628 ], [2.273289 ], [4.1876373 ], [1.4010222 ], [3.7049582 ], [3.52909 ], [3.014873 ], [3.9356582 ], [2.880937 ], [3.2932928 ], [4.424321 ], [2.8027363 ], [3.5936809 ], [2.848199 ], [3.0179572 ], [3.2322586 ], [0.0882553 ], [4.9161186 ], [1.4682242 ], [3.0375245 ], [2.7371447 ], [2.922221 ], [1.9005984 ], [3.9673944 ], [1.1328233 ], [2.9814308 ], [2.7574532 ], [4.6011615 ], [4.393426 ], [3.647125 ], [2.4305787 ], [2.0360255 ], [2.0554073 ], [3.584027 ], [3.1583822 ], [3.253896 ], [2.9442368 ], [2.8312666 ], [3.488383 ], [3.4391968 ], [3.9078705 ], [2.7853186 ], [3.2216456 ], [2.7905474 ], [3.0011642 ], [3.3205035 ], [2.586902 ], [3.9559863 ], [3.0187619 ], [3.047871 ], [2.397868 ], [3.2428887 ], [3.5078952 ], [2.1818392 ], [2.5248778 ], [2.4667773 ], [3.030227 ], [3.248349 ], [4.819742 ], [3.047447 ], [3.5179374 ], [2.1998146 ], [0.6026546 ], [3.8684669 ], [3.1930377 ], [1.8060614 ], [3.0088873 ], [1.4026772 ], [3.4012291 ], [2.3242316 ], [4.1493683 ], [3.7922447 ], [2.4385438 ], [3.0675828 ], [2.279734 ], [3.072283 ], [3.7030537 ], [4.359474 ], [2.5870302 ], [3.1755843 ], [4.4895167 ], [1.8151201 ], [2.350835 ], [3.2439404 ], [2.6312222 ], [4.2802467 ], [3.1646845 ], [2.29786 ], [2.5932682 ], [2.7738147 ], [3.1757994 ], [3.527126 ], [2.1753094 ], [3.2313006 ], [0.87366164], [1.1633948 ], [2.543244 ], [4.0536847 ], [4.5483127 ], [2.8635612 ], [1.0507253 ], [3.1183274 ], [2.4314158 ], [3.8431022 ], [2.538572 ], [2.2237988 ], [4.3369594 ], [2.5413868 ]], dtype=float)\n",
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2.5374541,\n",
       " 3.2678769,\n",
       " 3.0341623,\n",
       " 3.9246533,\n",
       " 5.3540707,\n",
       " 2.2571735,\n",
       " 2.357383,\n",
       " 4.071934,\n",
       " 2.6663194,\n",
       " 2.3384793,\n",
       " 3.8936331,\n",
       " 3.0537953,\n",
       " 2.6437616,\n",
       " 5.248788,\n",
       " 3.3744543,\n",
       " 1.9989566,\n",
       " 3.4469922,\n",
       " 3.2478435,\n",
       " 3.3308902,\n",
       " 2.7365532,\n",
       " 2.446532,\n",
       " 4.16877,\n",
       " 4.1584864,\n",
       " 3.447427,\n",
       " 2.271582,\n",
       " 2.7618506,\n",
       " 3.147385,\n",
       " 3.3469748,\n",
       " 4.369869,\n",
       " 3.3367028,\n",
       " 3.2269151,\n",
       " 3.4688303,\n",
       " 4.120167,\n",
       " 2.078065,\n",
       " 4.019703,\n",
       " 5.041812,\n",
       " 3.50992,\n",
       " 2.4590092,\n",
       " 4.162942,\n",
       " 1.8680092,\n",
       " 2.7311177,\n",
       " 2.5004175,\n",
       " 1.971567,\n",
       " 4.066986,\n",
       " 3.2532208,\n",
       " 3.642503,\n",
       " 1.4995602,\n",
       " 4.7609386,\n",
       " 2.3255336,\n",
       " 2.3952088,\n",
       " 3.187093,\n",
       " 3.4802458,\n",
       " 3.7456691,\n",
       " 2.8016112,\n",
       " 2.1244657,\n",
       " 2.9116685,\n",
       " 3.7208135,\n",
       " 2.9225452,\n",
       " 2.7336068,\n",
       " 3.376431,\n",
       " 3.182278,\n",
       " 2.2641835,\n",
       " 3.5075967,\n",
       " 2.9265978,\n",
       " 2.6397583,\n",
       " 3.5653908,\n",
       " 2.9789968,\n",
       " 3.3346128,\n",
       " 1.9328927,\n",
       " 2.963746,\n",
       " 2.76102,\n",
       " 3.7848423,\n",
       " 1.660465,\n",
       " 4.7199183,\n",
       " 4.1745787,\n",
       " 1.6536111,\n",
       " 3.3782952,\n",
       " 2.970159,\n",
       " 3.5605137,\n",
       " 2.9517906,\n",
       " 3.2952628,\n",
       " 2.273289,\n",
       " 4.1876373,\n",
       " 1.4010222,\n",
       " 3.7049582,\n",
       " 3.52909,\n",
       " 3.014873,\n",
       " 3.9356582,\n",
       " 2.880937,\n",
       " 3.2932928,\n",
       " 4.424321,\n",
       " 2.8027363,\n",
       " 3.5936809,\n",
       " 2.848199,\n",
       " 3.0179572,\n",
       " 3.2322586,\n",
       " 0.0882553,\n",
       " 4.9161186,\n",
       " 1.4682242,\n",
       " 3.0375245,\n",
       " 2.7371447,\n",
       " 2.922221,\n",
       " 1.9005984,\n",
       " 3.9673944,\n",
       " 1.1328233,\n",
       " 2.9814308,\n",
       " 2.7574532,\n",
       " 4.6011615,\n",
       " 4.393426,\n",
       " 3.647125,\n",
       " 2.4305787,\n",
       " 2.0360255,\n",
       " 2.0554073,\n",
       " 3.584027,\n",
       " 3.1583822,\n",
       " 3.253896,\n",
       " 2.9442368,\n",
       " 2.8312666,\n",
       " 3.488383,\n",
       " 3.4391968,\n",
       " 3.9078705,\n",
       " 2.7853186,\n",
       " 3.2216456,\n",
       " 2.7905474,\n",
       " 3.0011642,\n",
       " 3.3205035,\n",
       " 2.586902,\n",
       " 3.9559863,\n",
       " 3.0187619,\n",
       " 3.047871,\n",
       " 2.397868,\n",
       " 3.2428887,\n",
       " 3.5078952,\n",
       " 2.1818392,\n",
       " 2.5248778,\n",
       " 2.4667773,\n",
       " 3.030227,\n",
       " 3.248349,\n",
       " 4.819742,\n",
       " 3.047447,\n",
       " 3.5179374,\n",
       " 2.1998146,\n",
       " 0.6026546,\n",
       " 3.8684669,\n",
       " 3.1930377,\n",
       " 1.8060614,\n",
       " 3.0088873,\n",
       " 1.4026772,\n",
       " 3.4012291,\n",
       " 2.3242316,\n",
       " 4.1493683,\n",
       " 3.7922447,\n",
       " 2.4385438,\n",
       " 3.0675828,\n",
       " 2.279734,\n",
       " 3.072283,\n",
       " 3.7030537,\n",
       " 4.359474,\n",
       " 2.5870302,\n",
       " 3.1755843,\n",
       " 4.4895167,\n",
       " 1.8151201,\n",
       " 2.350835,\n",
       " 3.2439404,\n",
       " 2.6312222,\n",
       " 4.2802467,\n",
       " 3.1646845,\n",
       " 2.29786,\n",
       " 2.5932682,\n",
       " 2.7738147,\n",
       " 3.1757994,\n",
       " 3.527126,\n",
       " 2.1753094,\n",
       " 3.2313006,\n",
       " 0.87366164,\n",
       " 1.1633948,\n",
       " 2.543244,\n",
       " 4.0536847,\n",
       " 4.5483127,\n",
       " 2.8635612,\n",
       " 1.0507253,\n",
       " 3.1183274,\n",
       " 2.4314158,\n",
       " 3.8431022,\n",
       " 2.538572,\n",
       " 2.2237988,\n",
       " 4.3369594,\n",
       " 2.5413868]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p = []\n",
    "for pred in preds:\n",
    "    p.append(pred[0])\n",
    "p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.1269428326595747"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "mean_absolute_error(np.array(test_yy), p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "language": "python",
   "notebookName": "ColorFrame-Housing-Keras",
   "notebookOrigID": 3683421343168663,
   "widgets": {}
  },
  "kernelspec": {
   "display_name": "blogs",
   "language": "python",
   "name": "blogs"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
